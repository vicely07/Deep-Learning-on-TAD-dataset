(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.92129, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.92129 to 1.30957, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 1.30957 to 1.16501, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 1.16501 to 0.62789, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.62789

Epoch 00006: val_loss improved from 0.62789 to 0.59144, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.59144 to 0.56907, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.56907 to 0.56002, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.56002 to 0.53519, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.53519

Epoch 00011: val_loss improved from 0.53519 to 0.52591, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.52591 to 0.52378, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.52378 to 0.50028, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.50028 to 0.47046, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.47046

Epoch 00016: val_loss did not improve from 0.47046

Epoch 00017: val_loss did not improve from 0.47046

Epoch 00018: val_loss did not improve from 0.47046

Epoch 00019: val_loss did not improve from 0.47046

Epoch 00020: val_loss improved from 0.47046 to 0.46106, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.46106 to 0.43287, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.43287

Epoch 00023: val_loss improved from 0.43287 to 0.41731, saving model to 1_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.41731

Epoch 00025: val_loss did not improve from 0.41731

Epoch 00026: val_loss did not improve from 0.41731

Epoch 00027: val_loss did not improve from 0.41731

Epoch 00028: val_loss improved from 0.41731 to 0.40182, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.40182 to 0.40080, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.40080

Epoch 00031: val_loss did not improve from 0.40080

Epoch 00032: val_loss did not improve from 0.40080

Epoch 00033: val_loss did not improve from 0.40080

Epoch 00034: val_loss did not improve from 0.40080

Epoch 00035: val_loss improved from 0.40080 to 0.39771, saving model to 1_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.39771

Epoch 00037: val_loss did not improve from 0.39771

Epoch 00038: val_loss did not improve from 0.39771

Epoch 00039: val_loss did not improve from 0.39771

Epoch 00040: val_loss did not improve from 0.39771

Epoch 00041: val_loss did not improve from 0.39771

Epoch 00042: val_loss did not improve from 0.39771

Epoch 00043: val_loss did not improve from 0.39771
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9339172274447355 0.8952991452991453 0.8049417668489758 0.9107328619816033 0.894375096316844 0.8941386648693814 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8905477193625205 0.8708133971291866 0.7488299031937322 0.8791322314049587 0.8697563656347316 0.8698480060889822 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.919070110701107 0.8560460652591171 0.7180727511046948 0.8598606168446026 0.8582140221402215 0.8559930124824483 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.81845, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.81845 to 0.57242, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.57242 to 0.54471, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.54471

Epoch 00005: val_loss improved from 0.54471 to 0.50420, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.50420

Epoch 00007: val_loss improved from 0.50420 to 0.49961, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.49961 to 0.48998, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.48998 to 0.47435, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.47435 to 0.47292, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.47292

Epoch 00012: val_loss improved from 0.47292 to 0.46071, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.46071 to 0.45411, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.45411 to 0.45031, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.45031 to 0.44788, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.44788 to 0.44511, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.44511 to 0.43036, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.43036

Epoch 00019: val_loss did not improve from 0.43036

Epoch 00020: val_loss improved from 0.43036 to 0.42558, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.42558 to 0.42216, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.42216 to 0.41961, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.41961

Epoch 00024: val_loss improved from 0.41961 to 0.41405, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.41405

Epoch 00026: val_loss did not improve from 0.41405

Epoch 00027: val_loss did not improve from 0.41405

Epoch 00028: val_loss improved from 0.41405 to 0.41349, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.41349 to 0.40963, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.40963 to 0.40806, saving model to 1_50_best_model.hdf5

Epoch 00031: val_loss improved from 0.40806 to 0.40765, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.40765 to 0.40567, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss improved from 0.40567 to 0.40346, saving model to 1_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.40346

Epoch 00035: val_loss improved from 0.40346 to 0.40003, saving model to 1_50_best_model.hdf5

Epoch 00036: val_loss improved from 0.40003 to 0.39997, saving model to 1_50_best_model.hdf5

Epoch 00037: val_loss improved from 0.39997 to 0.39415, saving model to 1_50_best_model.hdf5

Epoch 00038: val_loss improved from 0.39415 to 0.39312, saving model to 1_50_best_model.hdf5

Epoch 00039: val_loss improved from 0.39312 to 0.38913, saving model to 1_50_best_model.hdf5

Epoch 00040: val_loss improved from 0.38913 to 0.38663, saving model to 1_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.38663

Epoch 00042: val_loss did not improve from 0.38663

Epoch 00043: val_loss improved from 0.38663 to 0.38570, saving model to 1_50_best_model.hdf5

Epoch 00044: val_loss improved from 0.38570 to 0.38280, saving model to 1_50_best_model.hdf5

Epoch 00045: val_loss improved from 0.38280 to 0.37406, saving model to 1_50_best_model.hdf5

Epoch 00046: val_loss did not improve from 0.37406

Epoch 00047: val_loss improved from 0.37406 to 0.37208, saving model to 1_50_best_model.hdf5

Epoch 00048: val_loss improved from 0.37208 to 0.35756, saving model to 1_50_best_model.hdf5

Epoch 00049: val_loss improved from 0.35756 to 0.35366, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.35366

Epoch 00051: val_loss improved from 0.35366 to 0.34546, saving model to 1_50_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.34546

Epoch 00053: val_loss did not improve from 0.34546

Epoch 00054: val_loss did not improve from 0.34546

Epoch 00055: val_loss did not improve from 0.34546

Epoch 00056: val_loss did not improve from 0.34546

Epoch 00057: val_loss improved from 0.34546 to 0.33969, saving model to 1_50_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.33969

Epoch 00059: val_loss did not improve from 0.33969

Epoch 00060: val_loss improved from 0.33969 to 0.33677, saving model to 1_50_best_model.hdf5

Epoch 00061: val_loss improved from 0.33677 to 0.33245, saving model to 1_50_best_model.hdf5

Epoch 00062: val_loss did not improve from 0.33245

Epoch 00063: val_loss did not improve from 0.33245

Epoch 00064: val_loss did not improve from 0.33245

Epoch 00065: val_loss did not improve from 0.33245

Epoch 00066: val_loss improved from 0.33245 to 0.32762, saving model to 1_50_best_model.hdf5

Epoch 00067: val_loss did not improve from 0.32762

Epoch 00068: val_loss did not improve from 0.32762

Epoch 00069: val_loss did not improve from 0.32762

Epoch 00070: val_loss did not improve from 0.32762

Epoch 00071: val_loss did not improve from 0.32762

Epoch 00072: val_loss improved from 0.32762 to 0.31783, saving model to 1_50_best_model.hdf5

Epoch 00073: val_loss did not improve from 0.31783

Epoch 00074: val_loss improved from 0.31783 to 0.31467, saving model to 1_50_best_model.hdf5

Epoch 00075: val_loss improved from 0.31467 to 0.31343, saving model to 1_50_best_model.hdf5

Epoch 00076: val_loss did not improve from 0.31343

Epoch 00077: val_loss did not improve from 0.31343

Epoch 00078: val_loss improved from 0.31343 to 0.30769, saving model to 1_50_best_model.hdf5

Epoch 00079: val_loss did not improve from 0.30769

Epoch 00080: val_loss improved from 0.30769 to 0.30480, saving model to 1_50_best_model.hdf5

Epoch 00081: val_loss improved from 0.30480 to 0.30478, saving model to 1_50_best_model.hdf5

Epoch 00082: val_loss did not improve from 0.30478

Epoch 00083: val_loss did not improve from 0.30478

Epoch 00084: val_loss improved from 0.30478 to 0.29857, saving model to 1_50_best_model.hdf5

Epoch 00085: val_loss did not improve from 0.29857

Epoch 00086: val_loss improved from 0.29857 to 0.29500, saving model to 1_50_best_model.hdf5

Epoch 00087: val_loss did not improve from 0.29500

Epoch 00088: val_loss did not improve from 0.29500

Epoch 00089: val_loss did not improve from 0.29500

Epoch 00090: val_loss improved from 0.29500 to 0.29427, saving model to 1_50_best_model.hdf5

Epoch 00091: val_loss did not improve from 0.29427

Epoch 00092: val_loss did not improve from 0.29427

Epoch 00093: val_loss improved from 0.29427 to 0.29358, saving model to 1_50_best_model.hdf5

Epoch 00094: val_loss did not improve from 0.29358

Epoch 00095: val_loss improved from 0.29358 to 0.28715, saving model to 1_50_best_model.hdf5

Epoch 00096: val_loss did not improve from 0.28715

Epoch 00097: val_loss improved from 0.28715 to 0.28174, saving model to 1_50_best_model.hdf5

Epoch 00098: val_loss improved from 0.28174 to 0.27940, saving model to 1_50_best_model.hdf5

Epoch 00099: val_loss did not improve from 0.27940

Epoch 00100: val_loss did not improve from 0.27940
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9524398420876181 0.9316604378003204 0.8708124955691863 0.9398761653146495 0.9309817524990249 0.931259748600789 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9539528432732316 0.8846153846153846 0.7781610064445794 0.8943668661537 0.8838650023116043 0.8837447601304145 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9418007380073801 0.8886756238003839 0.7839876238009132 0.8930161132377816 0.8909741697416974 0.8886259767064721 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.02849, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss did not improve from 3.02849

Epoch 00003: val_loss improved from 3.02849 to 2.68614, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 2.68614

Epoch 00005: val_loss did not improve from 2.68614

Epoch 00006: val_loss did not improve from 2.68614

Epoch 00007: val_loss did not improve from 2.68614

Epoch 00008: val_loss did not improve from 2.68614

Epoch 00009: val_loss did not improve from 2.68614

Epoch 00010: val_loss did not improve from 2.68614

Epoch 00011: val_loss did not improve from 2.68614
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8469665040561405 0.8216764548852109 0.6875876427415758 0.86953125 0.819848975188781 0.8151091171324538 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8391123439667129 0.8076923076923077 0.6655218381394474 0.8620689655172413 0.8058252427184466 0.7995180722891566 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8173431734317343 0.800383877159309 0.6596931331432826 0.8531073446327684 0.8081180811808117 0.7951858235809973 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.20188, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.20188

Epoch 00003: val_loss improved from 2.20188 to 1.22592, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 1.22592 to 0.51605, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.51605

Epoch 00006: val_loss improved from 0.51605 to 0.50136, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.50136

Epoch 00008: val_loss did not improve from 0.50136

Epoch 00009: val_loss improved from 0.50136 to 0.49495, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.49495 to 0.48135, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.48135 to 0.47112, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.47112 to 0.46108, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.46108 to 0.45261, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.45261 to 0.44330, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.44330 to 0.43827, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.43827 to 0.43044, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.43044 to 0.42809, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.42809 to 0.42047, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.42047 to 0.41570, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.41570 to 0.40843, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.40843 to 0.40576, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.40576

Epoch 00023: val_loss did not improve from 0.40576

Epoch 00024: val_loss improved from 0.40576 to 0.39578, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss improved from 0.39578 to 0.38893, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.38893 to 0.38433, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.38433 to 0.38415, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.38415

Epoch 00029: val_loss improved from 0.38415 to 0.38072, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.38072 to 0.37294, saving model to 1_50_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.37294

Epoch 00032: val_loss improved from 0.37294 to 0.36291, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.36291

Epoch 00034: val_loss did not improve from 0.36291

Epoch 00035: val_loss improved from 0.36291 to 0.35838, saving model to 1_50_best_model.hdf5

Epoch 00036: val_loss improved from 0.35838 to 0.35317, saving model to 1_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.35317

Epoch 00038: val_loss did not improve from 0.35317

Epoch 00039: val_loss improved from 0.35317 to 0.34468, saving model to 1_50_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.34468

Epoch 00041: val_loss improved from 0.34468 to 0.34263, saving model to 1_50_best_model.hdf5

Epoch 00042: val_loss did not improve from 0.34263

Epoch 00043: val_loss did not improve from 0.34263

Epoch 00044: val_loss improved from 0.34263 to 0.32896, saving model to 1_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.32896

Epoch 00046: val_loss improved from 0.32896 to 0.32585, saving model to 1_50_best_model.hdf5

Epoch 00047: val_loss improved from 0.32585 to 0.31910, saving model to 1_50_best_model.hdf5

Epoch 00048: val_loss did not improve from 0.31910

Epoch 00049: val_loss improved from 0.31910 to 0.31786, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss improved from 0.31786 to 0.31711, saving model to 1_50_best_model.hdf5

Epoch 00051: val_loss improved from 0.31711 to 0.30736, saving model to 1_50_best_model.hdf5

Epoch 00052: val_loss improved from 0.30736 to 0.30607, saving model to 1_50_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.30607

Epoch 00054: val_loss improved from 0.30607 to 0.30337, saving model to 1_50_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.30337

Epoch 00056: val_loss did not improve from 0.30337

Epoch 00057: val_loss improved from 0.30337 to 0.29762, saving model to 1_50_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.29762

Epoch 00059: val_loss improved from 0.29762 to 0.29757, saving model to 1_50_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.29757

Epoch 00061: val_loss improved from 0.29757 to 0.29425, saving model to 1_50_best_model.hdf5

Epoch 00062: val_loss improved from 0.29425 to 0.29201, saving model to 1_50_best_model.hdf5

Epoch 00063: val_loss did not improve from 0.29201

Epoch 00064: val_loss improved from 0.29201 to 0.28977, saving model to 1_50_best_model.hdf5

Epoch 00065: val_loss improved from 0.28977 to 0.28908, saving model to 1_50_best_model.hdf5

Epoch 00066: val_loss improved from 0.28908 to 0.28892, saving model to 1_50_best_model.hdf5

Epoch 00067: val_loss improved from 0.28892 to 0.28527, saving model to 1_50_best_model.hdf5

Epoch 00068: val_loss did not improve from 0.28527

Epoch 00069: val_loss did not improve from 0.28527

Epoch 00070: val_loss improved from 0.28527 to 0.28401, saving model to 1_50_best_model.hdf5

Epoch 00071: val_loss improved from 0.28401 to 0.28113, saving model to 1_50_best_model.hdf5

Epoch 00072: val_loss improved from 0.28113 to 0.27685, saving model to 1_50_best_model.hdf5

Epoch 00073: val_loss did not improve from 0.27685

Epoch 00074: val_loss did not improve from 0.27685

Epoch 00075: val_loss did not improve from 0.27685

Epoch 00076: val_loss did not improve from 0.27685

Epoch 00077: val_loss did not improve from 0.27685

Epoch 00078: val_loss did not improve from 0.27685

Epoch 00079: val_loss did not improve from 0.27685

Epoch 00080: val_loss improved from 0.27685 to 0.26747, saving model to 1_50_best_model.hdf5

Epoch 00081: val_loss did not improve from 0.26747

Epoch 00082: val_loss did not improve from 0.26747

Epoch 00083: val_loss improved from 0.26747 to 0.26561, saving model to 1_50_best_model.hdf5

Epoch 00084: val_loss did not improve from 0.26561

Epoch 00085: val_loss improved from 0.26561 to 0.26116, saving model to 1_50_best_model.hdf5

Epoch 00086: val_loss did not improve from 0.26116

Epoch 00087: val_loss did not improve from 0.26116

Epoch 00088: val_loss did not improve from 0.26116

Epoch 00089: val_loss did not improve from 0.26116

Epoch 00090: val_loss improved from 0.26116 to 0.25680, saving model to 1_50_best_model.hdf5

Epoch 00091: val_loss did not improve from 0.25680

Epoch 00092: val_loss did not improve from 0.25680

Epoch 00093: val_loss did not improve from 0.25680

Epoch 00094: val_loss did not improve from 0.25680

Epoch 00095: val_loss did not improve from 0.25680

Epoch 00096: val_loss did not improve from 0.25680

Epoch 00097: val_loss did not improve from 0.25680

Epoch 00098: val_loss did not improve from 0.25680
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.950441420299176 0.9284570208222104 0.8627160449935666 0.9348909072363785 0.927853837539997 0.928116035340806 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9402681460933888 0.9038461538461539 0.8112632057020173 0.9079008882655446 0.9033749422098936 0.9035250463821891 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9324280442804428 0.8944337811900192 0.7951496606035505 0.8984875444839857 0.8966642066420665 0.8943948758204622 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_9 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.58898, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.58898 to 0.62995, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62995 to 0.58391, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.58391 to 0.54634, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.54634 to 0.51924, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.51924 to 0.49796, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.49796 to 0.48156, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.48156 to 0.47319, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.47319 to 0.47060, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.47060 to 0.46061, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.46061 to 0.44974, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.44974 to 0.43655, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.43655 to 0.42879, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.42879 to 0.42810, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.42810

Epoch 00016: val_loss improved from 0.42810 to 0.42357, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.42357

Epoch 00018: val_loss improved from 0.42357 to 0.41732, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.41732 to 0.41491, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.41491 to 0.40503, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.40503

Epoch 00022: val_loss did not improve from 0.40503

Epoch 00023: val_loss did not improve from 0.40503

Epoch 00024: val_loss improved from 0.40503 to 0.39538, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss improved from 0.39538 to 0.39133, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.39133 to 0.38139, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.38139

Epoch 00028: val_loss improved from 0.38139 to 0.37152, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.37152 to 0.37049, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.37049

Epoch 00031: val_loss improved from 0.37049 to 0.36025, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.36025 to 0.35461, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.35461

Epoch 00034: val_loss did not improve from 0.35461

Epoch 00035: val_loss did not improve from 0.35461

Epoch 00036: val_loss did not improve from 0.35461

Epoch 00037: val_loss improved from 0.35461 to 0.34248, saving model to 1_50_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.34248

Epoch 00039: val_loss did not improve from 0.34248

Epoch 00040: val_loss did not improve from 0.34248

Epoch 00041: val_loss improved from 0.34248 to 0.33470, saving model to 1_50_best_model.hdf5

Epoch 00042: val_loss improved from 0.33470 to 0.32627, saving model to 1_50_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.32627

Epoch 00044: val_loss did not improve from 0.32627

Epoch 00045: val_loss did not improve from 0.32627

Epoch 00046: val_loss did not improve from 0.32627

Epoch 00047: val_loss did not improve from 0.32627

Epoch 00048: val_loss did not improve from 0.32627

Epoch 00049: val_loss improved from 0.32627 to 0.32560, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.32560

Epoch 00051: val_loss did not improve from 0.32560

Epoch 00052: val_loss did not improve from 0.32560

Epoch 00053: val_loss did not improve from 0.32560

Epoch 00054: val_loss improved from 0.32560 to 0.31530, saving model to 1_50_best_model.hdf5

Epoch 00055: val_loss improved from 0.31530 to 0.31075, saving model to 1_50_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.31075

Epoch 00057: val_loss did not improve from 0.31075

Epoch 00058: val_loss did not improve from 0.31075

Epoch 00059: val_loss improved from 0.31075 to 0.30792, saving model to 1_50_best_model.hdf5

Epoch 00060: val_loss improved from 0.30792 to 0.30769, saving model to 1_50_best_model.hdf5

Epoch 00061: val_loss did not improve from 0.30769

Epoch 00062: val_loss improved from 0.30769 to 0.30291, saving model to 1_50_best_model.hdf5

Epoch 00063: val_loss did not improve from 0.30291

Epoch 00064: val_loss did not improve from 0.30291

Epoch 00065: val_loss improved from 0.30291 to 0.28946, saving model to 1_50_best_model.hdf5

Epoch 00066: val_loss did not improve from 0.28946

Epoch 00067: val_loss did not improve from 0.28946

Epoch 00068: val_loss improved from 0.28946 to 0.28904, saving model to 1_50_best_model.hdf5

Epoch 00069: val_loss did not improve from 0.28904

Epoch 00070: val_loss did not improve from 0.28904

Epoch 00071: val_loss did not improve from 0.28904

Epoch 00072: val_loss did not improve from 0.28904

Epoch 00073: val_loss improved from 0.28904 to 0.28718, saving model to 1_50_best_model.hdf5

Epoch 00074: val_loss did not improve from 0.28718

Epoch 00075: val_loss improved from 0.28718 to 0.27965, saving model to 1_50_best_model.hdf5

Epoch 00076: val_loss did not improve from 0.27965

Epoch 00077: val_loss did not improve from 0.27965

Epoch 00078: val_loss did not improve from 0.27965

Epoch 00079: val_loss did not improve from 0.27965

Epoch 00080: val_loss did not improve from 0.27965

Epoch 00081: val_loss improved from 0.27965 to 0.26750, saving model to 1_50_best_model.hdf5

Epoch 00082: val_loss did not improve from 0.26750

Epoch 00083: val_loss did not improve from 0.26750

Epoch 00084: val_loss did not improve from 0.26750

Epoch 00085: val_loss did not improve from 0.26750

Epoch 00086: val_loss improved from 0.26750 to 0.26126, saving model to 1_50_best_model.hdf5

Epoch 00087: val_loss did not improve from 0.26126

Epoch 00088: val_loss did not improve from 0.26126

Epoch 00089: val_loss did not improve from 0.26126

Epoch 00090: val_loss did not improve from 0.26126

Epoch 00091: val_loss improved from 0.26126 to 0.25499, saving model to 1_50_best_model.hdf5

Epoch 00092: val_loss did not improve from 0.25499

Epoch 00093: val_loss did not improve from 0.25499

Epoch 00094: val_loss did not improve from 0.25499

Epoch 00095: val_loss did not improve from 0.25499

Epoch 00096: val_loss did not improve from 0.25499

Epoch 00097: val_loss did not improve from 0.25499

Epoch 00098: val_loss did not improve from 0.25499

Epoch 00099: val_loss did not improve from 0.25499
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9602892779682123 0.9530165509877202 0.9094397622262261 0.956882439619644 0.9525675586298752 0.9528795332551157 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9454461396208969 0.9134615384615384 0.8366425755185789 0.924004939678921 0.9127138233934351 0.9128085700978108 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9387158671586716 0.8944337811900192 0.7943797353734662 0.8978716786634675 0.8965092250922508 0.8944088850565817 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.59868, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 2.59868 to 0.89354, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.89354

Epoch 00004: val_loss improved from 0.89354 to 0.55024, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.55024 to 0.51295, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.51295 to 0.50588, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.50588

Epoch 00008: val_loss improved from 0.50588 to 0.48129, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.48129

Epoch 00010: val_loss improved from 0.48129 to 0.45397, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.45397

Epoch 00012: val_loss did not improve from 0.45397

Epoch 00013: val_loss did not improve from 0.45397

Epoch 00014: val_loss did not improve from 0.45397

Epoch 00015: val_loss improved from 0.45397 to 0.44917, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.44917 to 0.44278, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.44278 to 0.43386, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.43386 to 0.42353, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.42353

Epoch 00020: val_loss improved from 0.42353 to 0.42168, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.42168 to 0.40491, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.40491

Epoch 00023: val_loss did not improve from 0.40491

Epoch 00024: val_loss did not improve from 0.40491

Epoch 00025: val_loss improved from 0.40491 to 0.39805, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.39805 to 0.38616, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.38616

Epoch 00028: val_loss did not improve from 0.38616

Epoch 00029: val_loss improved from 0.38616 to 0.38605, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.38605

Epoch 00031: val_loss improved from 0.38605 to 0.37230, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.37230 to 0.36660, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss improved from 0.36660 to 0.35918, saving model to 1_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.35918

Epoch 00035: val_loss did not improve from 0.35918

Epoch 00036: val_loss improved from 0.35918 to 0.35581, saving model to 1_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.35581

Epoch 00038: val_loss improved from 0.35581 to 0.35540, saving model to 1_50_best_model.hdf5

Epoch 00039: val_loss improved from 0.35540 to 0.35035, saving model to 1_50_best_model.hdf5

Epoch 00040: val_loss improved from 0.35035 to 0.33851, saving model to 1_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.33851

Epoch 00042: val_loss improved from 0.33851 to 0.33414, saving model to 1_50_best_model.hdf5

Epoch 00043: val_loss improved from 0.33414 to 0.33135, saving model to 1_50_best_model.hdf5

Epoch 00044: val_loss improved from 0.33135 to 0.33021, saving model to 1_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.33021

Epoch 00046: val_loss did not improve from 0.33021

Epoch 00047: val_loss did not improve from 0.33021

Epoch 00048: val_loss did not improve from 0.33021

Epoch 00049: val_loss did not improve from 0.33021

Epoch 00050: val_loss improved from 0.33021 to 0.32963, saving model to 1_50_best_model.hdf5

Epoch 00051: val_loss improved from 0.32963 to 0.32761, saving model to 1_50_best_model.hdf5

Epoch 00052: val_loss improved from 0.32761 to 0.32451, saving model to 1_50_best_model.hdf5

Epoch 00053: val_loss improved from 0.32451 to 0.32054, saving model to 1_50_best_model.hdf5

Epoch 00054: val_loss did not improve from 0.32054

Epoch 00055: val_loss improved from 0.32054 to 0.31976, saving model to 1_50_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.31976

Epoch 00057: val_loss improved from 0.31976 to 0.30803, saving model to 1_50_best_model.hdf5

Epoch 00058: val_loss improved from 0.30803 to 0.29951, saving model to 1_50_best_model.hdf5

Epoch 00059: val_loss did not improve from 0.29951

Epoch 00060: val_loss did not improve from 0.29951

Epoch 00061: val_loss improved from 0.29951 to 0.29768, saving model to 1_50_best_model.hdf5

Epoch 00062: val_loss improved from 0.29768 to 0.29492, saving model to 1_50_best_model.hdf5

Epoch 00063: val_loss improved from 0.29492 to 0.29413, saving model to 1_50_best_model.hdf5

Epoch 00064: val_loss did not improve from 0.29413

Epoch 00065: val_loss did not improve from 0.29413

Epoch 00066: val_loss did not improve from 0.29413

Epoch 00067: val_loss did not improve from 0.29413

Epoch 00068: val_loss did not improve from 0.29413

Epoch 00069: val_loss did not improve from 0.29413

Epoch 00070: val_loss did not improve from 0.29413

Epoch 00071: val_loss did not improve from 0.29413
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9523794047952999 0.9049652963160705 0.8217071611834615 0.9177315390037981 0.9040888679068855 0.904089309591702 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9381414701803051 0.8942307692307693 0.7954280236106104 0.9018978377868001 0.8935737401756819 0.8936011904761905 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9288634686346864 0.8714011516314779 0.7628592111900572 0.8873405583122774 0.8756088560885609 0.8707842084806308 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.24750, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 3.24750 to 3.13180, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 3.13180

Epoch 00004: val_loss improved from 3.13180 to 3.02236, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 3.02236 to 2.68089, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 2.68089 to 2.01789, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 2.01789 to 1.58077, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 1.58077 to 0.98540, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.98540

Epoch 00010: val_loss improved from 0.98540 to 0.56059, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.56059 to 0.50116, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.50116

Epoch 00013: val_loss did not improve from 0.50116

Epoch 00014: val_loss improved from 0.50116 to 0.50111, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.50111 to 0.49686, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.49686 to 0.49482, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.49482 to 0.46912, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.46912

Epoch 00019: val_loss did not improve from 0.46912

Epoch 00020: val_loss improved from 0.46912 to 0.45540, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.45540

Epoch 00022: val_loss did not improve from 0.45540

Epoch 00023: val_loss did not improve from 0.45540

Epoch 00024: val_loss did not improve from 0.45540

Epoch 00025: val_loss improved from 0.45540 to 0.43911, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.43911

Epoch 00027: val_loss did not improve from 0.43911

Epoch 00028: val_loss did not improve from 0.43911

Epoch 00029: val_loss did not improve from 0.43911

Epoch 00030: val_loss did not improve from 0.43911

Epoch 00031: val_loss did not improve from 0.43911

Epoch 00032: val_loss did not improve from 0.43911

Epoch 00033: val_loss improved from 0.43911 to 0.42641, saving model to 1_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.42641

Epoch 00035: val_loss did not improve from 0.42641

Epoch 00036: val_loss improved from 0.42641 to 0.42424, saving model to 1_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.42424

Epoch 00038: val_loss improved from 0.42424 to 0.42023, saving model to 1_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.42023

Epoch 00040: val_loss did not improve from 0.42023

Epoch 00041: val_loss did not improve from 0.42023

Epoch 00042: val_loss improved from 0.42023 to 0.40628, saving model to 1_50_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.40628

Epoch 00044: val_loss did not improve from 0.40628

Epoch 00045: val_loss did not improve from 0.40628

Epoch 00046: val_loss did not improve from 0.40628

Epoch 00047: val_loss did not improve from 0.40628

Epoch 00048: val_loss improved from 0.40628 to 0.40431, saving model to 1_50_best_model.hdf5

Epoch 00049: val_loss improved from 0.40431 to 0.39012, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss improved from 0.39012 to 0.38716, saving model to 1_50_best_model.hdf5

Epoch 00051: val_loss did not improve from 0.38716

Epoch 00052: val_loss improved from 0.38716 to 0.38638, saving model to 1_50_best_model.hdf5

Epoch 00053: val_loss improved from 0.38638 to 0.38129, saving model to 1_50_best_model.hdf5

Epoch 00054: val_loss did not improve from 0.38129

Epoch 00055: val_loss did not improve from 0.38129

Epoch 00056: val_loss did not improve from 0.38129

Epoch 00057: val_loss improved from 0.38129 to 0.37985, saving model to 1_50_best_model.hdf5

Epoch 00058: val_loss improved from 0.37985 to 0.37702, saving model to 1_50_best_model.hdf5

Epoch 00059: val_loss improved from 0.37702 to 0.37404, saving model to 1_50_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.37404

Epoch 00061: val_loss improved from 0.37404 to 0.37316, saving model to 1_50_best_model.hdf5

Epoch 00062: val_loss improved from 0.37316 to 0.37162, saving model to 1_50_best_model.hdf5

Epoch 00063: val_loss improved from 0.37162 to 0.36659, saving model to 1_50_best_model.hdf5

Epoch 00064: val_loss improved from 0.36659 to 0.36632, saving model to 1_50_best_model.hdf5

Epoch 00065: val_loss did not improve from 0.36632

Epoch 00066: val_loss improved from 0.36632 to 0.36451, saving model to 1_50_best_model.hdf5

Epoch 00067: val_loss improved from 0.36451 to 0.36358, saving model to 1_50_best_model.hdf5

Epoch 00068: val_loss improved from 0.36358 to 0.35978, saving model to 1_50_best_model.hdf5

Epoch 00069: val_loss improved from 0.35978 to 0.35830, saving model to 1_50_best_model.hdf5

Epoch 00070: val_loss improved from 0.35830 to 0.35770, saving model to 1_50_best_model.hdf5

Epoch 00071: val_loss did not improve from 0.35770

Epoch 00072: val_loss improved from 0.35770 to 0.35762, saving model to 1_50_best_model.hdf5

Epoch 00073: val_loss improved from 0.35762 to 0.35470, saving model to 1_50_best_model.hdf5

Epoch 00074: val_loss improved from 0.35470 to 0.34848, saving model to 1_50_best_model.hdf5

Epoch 00075: val_loss did not improve from 0.34848

Epoch 00076: val_loss did not improve from 0.34848

Epoch 00077: val_loss improved from 0.34848 to 0.33727, saving model to 1_50_best_model.hdf5

Epoch 00078: val_loss did not improve from 0.33727

Epoch 00079: val_loss did not improve from 0.33727

Epoch 00080: val_loss improved from 0.33727 to 0.33525, saving model to 1_50_best_model.hdf5

Epoch 00081: val_loss improved from 0.33525 to 0.33516, saving model to 1_50_best_model.hdf5

Epoch 00082: val_loss improved from 0.33516 to 0.33188, saving model to 1_50_best_model.hdf5

Epoch 00083: val_loss improved from 0.33188 to 0.32943, saving model to 1_50_best_model.hdf5

Epoch 00084: val_loss did not improve from 0.32943

Epoch 00085: val_loss did not improve from 0.32943

Epoch 00086: val_loss did not improve from 0.32943

Epoch 00087: val_loss did not improve from 0.32943

Epoch 00088: val_loss did not improve from 0.32943

Epoch 00089: val_loss improved from 0.32943 to 0.32332, saving model to 1_50_best_model.hdf5

Epoch 00090: val_loss did not improve from 0.32332

Epoch 00091: val_loss improved from 0.32332 to 0.32173, saving model to 1_50_best_model.hdf5

Epoch 00092: val_loss did not improve from 0.32173

Epoch 00093: val_loss did not improve from 0.32173

Epoch 00094: val_loss improved from 0.32173 to 0.31892, saving model to 1_50_best_model.hdf5

Epoch 00095: val_loss did not improve from 0.31892

Epoch 00096: val_loss did not improve from 0.31892

Epoch 00097: val_loss did not improve from 0.31892

Epoch 00098: val_loss improved from 0.31892 to 0.31890, saving model to 1_50_best_model.hdf5

Epoch 00099: val_loss did not improve from 0.31890

Epoch 00100: val_loss improved from 0.31890 to 0.30676, saving model to 1_50_best_model.hdf5
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9454034588376425 0.9247197010144154 0.8538687562271879 0.9297000080860354 0.9241865482551868 0.9244298393583605 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9309292649098474 0.9086538461538461 0.8256961858266963 0.9178030303030302 0.9079519186315302 0.9080395578824898 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9294981549815499 0.8867562380038387 0.7769723010671659 0.8886181023277797 0.8883542435424354 0.8867545692002197 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_15 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.12180, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.12180 to 0.55972, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.55972 to 0.54200, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.54200

Epoch 00005: val_loss improved from 0.54200 to 0.49092, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.49092 to 0.48335, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.48335 to 0.46612, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.46612

Epoch 00009: val_loss improved from 0.46612 to 0.45167, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.45167 to 0.44793, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.44793

Epoch 00012: val_loss improved from 0.44793 to 0.42630, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.42630

Epoch 00014: val_loss did not improve from 0.42630

Epoch 00015: val_loss did not improve from 0.42630

Epoch 00016: val_loss improved from 0.42630 to 0.42098, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.42098 to 0.42020, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.42020 to 0.41645, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.41645 to 0.41288, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.41288 to 0.39806, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.39806

Epoch 00022: val_loss improved from 0.39806 to 0.39692, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss improved from 0.39692 to 0.39011, saving model to 1_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.39011

Epoch 00025: val_loss did not improve from 0.39011

Epoch 00026: val_loss improved from 0.39011 to 0.39010, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.39010 to 0.38166, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.38166

Epoch 00029: val_loss improved from 0.38166 to 0.37815, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.37815 to 0.37637, saving model to 1_50_best_model.hdf5

Epoch 00031: val_loss improved from 0.37637 to 0.37485, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.37485 to 0.37421, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss improved from 0.37421 to 0.36854, saving model to 1_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.36854

Epoch 00035: val_loss did not improve from 0.36854

Epoch 00036: val_loss did not improve from 0.36854

Epoch 00037: val_loss improved from 0.36854 to 0.35024, saving model to 1_50_best_model.hdf5

Epoch 00038: val_loss improved from 0.35024 to 0.34845, saving model to 1_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.34845

Epoch 00040: val_loss did not improve from 0.34845

Epoch 00041: val_loss improved from 0.34845 to 0.34448, saving model to 1_50_best_model.hdf5

Epoch 00042: val_loss improved from 0.34448 to 0.34429, saving model to 1_50_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.34429

Epoch 00044: val_loss improved from 0.34429 to 0.34192, saving model to 1_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.34192

Epoch 00046: val_loss improved from 0.34192 to 0.34129, saving model to 1_50_best_model.hdf5

Epoch 00047: val_loss improved from 0.34129 to 0.33963, saving model to 1_50_best_model.hdf5

Epoch 00048: val_loss improved from 0.33963 to 0.33328, saving model to 1_50_best_model.hdf5

Epoch 00049: val_loss improved from 0.33328 to 0.32510, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss improved from 0.32510 to 0.32449, saving model to 1_50_best_model.hdf5

Epoch 00051: val_loss improved from 0.32449 to 0.32334, saving model to 1_50_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.32334

Epoch 00053: val_loss improved from 0.32334 to 0.32242, saving model to 1_50_best_model.hdf5

Epoch 00054: val_loss improved from 0.32242 to 0.31541, saving model to 1_50_best_model.hdf5

Epoch 00055: val_loss improved from 0.31541 to 0.31237, saving model to 1_50_best_model.hdf5

Epoch 00056: val_loss improved from 0.31237 to 0.31084, saving model to 1_50_best_model.hdf5

Epoch 00057: val_loss did not improve from 0.31084

Epoch 00058: val_loss improved from 0.31084 to 0.30995, saving model to 1_50_best_model.hdf5

Epoch 00059: val_loss improved from 0.30995 to 0.30594, saving model to 1_50_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.30594

Epoch 00061: val_loss did not improve from 0.30594

Epoch 00062: val_loss did not improve from 0.30594

Epoch 00063: val_loss did not improve from 0.30594

Epoch 00064: val_loss improved from 0.30594 to 0.29641, saving model to 1_50_best_model.hdf5

Epoch 00065: val_loss did not improve from 0.29641

Epoch 00066: val_loss did not improve from 0.29641

Epoch 00067: val_loss did not improve from 0.29641

Epoch 00068: val_loss did not improve from 0.29641

Epoch 00069: val_loss improved from 0.29641 to 0.29503, saving model to 1_50_best_model.hdf5

Epoch 00070: val_loss improved from 0.29503 to 0.29271, saving model to 1_50_best_model.hdf5

Epoch 00071: val_loss improved from 0.29271 to 0.29243, saving model to 1_50_best_model.hdf5

Epoch 00072: val_loss improved from 0.29243 to 0.29190, saving model to 1_50_best_model.hdf5

Epoch 00073: val_loss improved from 0.29190 to 0.28311, saving model to 1_50_best_model.hdf5

Epoch 00074: val_loss did not improve from 0.28311

Epoch 00075: val_loss improved from 0.28311 to 0.28078, saving model to 1_50_best_model.hdf5

Epoch 00076: val_loss did not improve from 0.28078

Epoch 00077: val_loss did not improve from 0.28078

Epoch 00078: val_loss improved from 0.28078 to 0.27296, saving model to 1_50_best_model.hdf5

Epoch 00079: val_loss did not improve from 0.27296

Epoch 00080: val_loss did not improve from 0.27296

Epoch 00081: val_loss did not improve from 0.27296

Epoch 00082: val_loss did not improve from 0.27296

Epoch 00083: val_loss did not improve from 0.27296

Epoch 00084: val_loss did not improve from 0.27296

Epoch 00085: val_loss did not improve from 0.27296

Epoch 00086: val_loss improved from 0.27296 to 0.26721, saving model to 1_50_best_model.hdf5

Epoch 00087: val_loss did not improve from 0.26721

Epoch 00088: val_loss did not improve from 0.26721

Epoch 00089: val_loss did not improve from 0.26721

Epoch 00090: val_loss did not improve from 0.26721

Epoch 00091: val_loss improved from 0.26721 to 0.26095, saving model to 1_50_best_model.hdf5

Epoch 00092: val_loss improved from 0.26095 to 0.25991, saving model to 1_50_best_model.hdf5

Epoch 00093: val_loss improved from 0.25991 to 0.25802, saving model to 1_50_best_model.hdf5

Epoch 00094: val_loss did not improve from 0.25802

Epoch 00095: val_loss did not improve from 0.25802

Epoch 00096: val_loss did not improve from 0.25802

Epoch 00097: val_loss improved from 0.25802 to 0.25730, saving model to 1_50_best_model.hdf5

Epoch 00098: val_loss did not improve from 0.25730

Epoch 00099: val_loss did not improve from 0.25730

Epoch 00100: val_loss did not improve from 0.25730
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9650068077478329 0.9466097170315003 0.897084266909198 0.9509697692057644 0.9461275660191895 0.9464349039660478 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9376329172445677 0.9086538461538461 0.8202213870728639 0.9120007465472191 0.9082293111419324 0.9083976543124029 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9491070110701108 0.9078694817658349 0.8217275862553963 0.9116849436870185 0.9100442804428044 0.9078419811320755 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.96700, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.96700 to 1.84516, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 1.84516 to 0.76264, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.76264 to 0.62039, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62039 to 0.54217, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.54217 to 0.53721, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.53721 to 0.53601, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.53601 to 0.52627, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.52627 to 0.50156, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.50156 to 0.48533, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.48533

Epoch 00012: val_loss improved from 0.48533 to 0.46440, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.46440 to 0.46103, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.46103 to 0.45089, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.45089 to 0.43441, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.43441

Epoch 00017: val_loss did not improve from 0.43441

Epoch 00018: val_loss did not improve from 0.43441

Epoch 00019: val_loss improved from 0.43441 to 0.42172, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.42172 to 0.41032, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.41032

Epoch 00022: val_loss improved from 0.41032 to 0.40993, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.40993

Epoch 00024: val_loss improved from 0.40993 to 0.39395, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.39395

Epoch 00026: val_loss improved from 0.39395 to 0.38644, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.38644

Epoch 00028: val_loss did not improve from 0.38644

Epoch 00029: val_loss improved from 0.38644 to 0.38540, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.38540 to 0.37644, saving model to 1_50_best_model.hdf5

Epoch 00031: val_loss improved from 0.37644 to 0.37196, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.37196 to 0.36368, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.36368

Epoch 00034: val_loss did not improve from 0.36368

Epoch 00035: val_loss improved from 0.36368 to 0.35871, saving model to 1_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.35871

Epoch 00037: val_loss did not improve from 0.35871

Epoch 00038: val_loss did not improve from 0.35871

Epoch 00039: val_loss improved from 0.35871 to 0.35776, saving model to 1_50_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.35776

Epoch 00041: val_loss did not improve from 0.35776

Epoch 00042: val_loss improved from 0.35776 to 0.34564, saving model to 1_50_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.34564

Epoch 00044: val_loss did not improve from 0.34564

Epoch 00045: val_loss did not improve from 0.34564

Epoch 00046: val_loss did not improve from 0.34564

Epoch 00047: val_loss did not improve from 0.34564

Epoch 00048: val_loss improved from 0.34564 to 0.34060, saving model to 1_50_best_model.hdf5

Epoch 00049: val_loss improved from 0.34060 to 0.33255, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.33255

Epoch 00051: val_loss improved from 0.33255 to 0.33099, saving model to 1_50_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.33099

Epoch 00053: val_loss improved from 0.33099 to 0.32708, saving model to 1_50_best_model.hdf5

Epoch 00054: val_loss improved from 0.32708 to 0.31497, saving model to 1_50_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.31497

Epoch 00056: val_loss did not improve from 0.31497

Epoch 00057: val_loss did not improve from 0.31497

Epoch 00058: val_loss did not improve from 0.31497

Epoch 00059: val_loss did not improve from 0.31497

Epoch 00060: val_loss did not improve from 0.31497

Epoch 00061: val_loss did not improve from 0.31497

Epoch 00062: val_loss did not improve from 0.31497
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9181450996759193 0.8483715963694608 0.728357900575158 0.8823615186003655 0.8468610238761514 0.8445145192896797 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9339343504392048 0.8798076923076923 0.7820808688600516 0.9038461538461539 0.8786407766990292 0.8777477371576348 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8920738007380075 0.836852207293666 0.7117296565533145 0.8693591986007314 0.8428634686346863 0.8346593688046267 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 20,451
Trainable params: 20,451
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.00429, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.00429 to 0.60767, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.60767 to 0.57377, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.57377 to 0.53990, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.53990 to 0.51456, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.51456 to 0.50166, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.50166 to 0.48828, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.48828 to 0.47846, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.47846 to 0.47005, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.47005 to 0.45947, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.45947 to 0.45501, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.45501 to 0.44870, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.44870 to 0.44418, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.44418 to 0.43655, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.43655 to 0.43403, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.43403 to 0.43187, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.43187 to 0.43161, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.43161 to 0.42138, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.42138

Epoch 00020: val_loss improved from 0.42138 to 0.40834, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.40834

Epoch 00022: val_loss did not improve from 0.40834

Epoch 00023: val_loss did not improve from 0.40834

Epoch 00024: val_loss did not improve from 0.40834

Epoch 00025: val_loss improved from 0.40834 to 0.40697, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.40697 to 0.40344, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.40344 to 0.40135, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss improved from 0.40135 to 0.39830, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.39830 to 0.38976, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.38976 to 0.38784, saving model to 1_50_best_model.hdf5

Epoch 00031: val_loss improved from 0.38784 to 0.38219, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.38219 to 0.37789, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.37789

Epoch 00034: val_loss did not improve from 0.37789

Epoch 00035: val_loss did not improve from 0.37789

Epoch 00036: val_loss did not improve from 0.37789

Epoch 00037: val_loss did not improve from 0.37789

Epoch 00038: val_loss did not improve from 0.37789

Epoch 00039: val_loss did not improve from 0.37789

Epoch 00040: val_loss improved from 0.37789 to 0.37543, saving model to 1_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.37543

Epoch 00042: val_loss did not improve from 0.37543

Epoch 00043: val_loss did not improve from 0.37543

Epoch 00044: val_loss improved from 0.37543 to 0.36843, saving model to 1_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.36843

Epoch 00046: val_loss improved from 0.36843 to 0.35594, saving model to 1_50_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.35594

Epoch 00048: val_loss did not improve from 0.35594

Epoch 00049: val_loss improved from 0.35594 to 0.35431, saving model to 1_50_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.35431

Epoch 00051: val_loss did not improve from 0.35431

Epoch 00052: val_loss did not improve from 0.35431

Epoch 00053: val_loss did not improve from 0.35431

Epoch 00054: val_loss improved from 0.35431 to 0.35285, saving model to 1_50_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.35285

Epoch 00056: val_loss improved from 0.35285 to 0.34395, saving model to 1_50_best_model.hdf5

Epoch 00057: val_loss did not improve from 0.34395

Epoch 00058: val_loss improved from 0.34395 to 0.33750, saving model to 1_50_best_model.hdf5

Epoch 00059: val_loss improved from 0.33750 to 0.33311, saving model to 1_50_best_model.hdf5

Epoch 00060: val_loss improved from 0.33311 to 0.32824, saving model to 1_50_best_model.hdf5

Epoch 00061: val_loss did not improve from 0.32824

Epoch 00062: val_loss improved from 0.32824 to 0.32419, saving model to 1_50_best_model.hdf5

Epoch 00063: val_loss did not improve from 0.32419

Epoch 00064: val_loss improved from 0.32419 to 0.31954, saving model to 1_50_best_model.hdf5

Epoch 00065: val_loss did not improve from 0.31954

Epoch 00066: val_loss improved from 0.31954 to 0.31718, saving model to 1_50_best_model.hdf5

Epoch 00067: val_loss did not improve from 0.31718

Epoch 00068: val_loss improved from 0.31718 to 0.31321, saving model to 1_50_best_model.hdf5

Epoch 00069: val_loss did not improve from 0.31321

Epoch 00070: val_loss did not improve from 0.31321

Epoch 00071: val_loss did not improve from 0.31321

Epoch 00072: val_loss did not improve from 0.31321

Epoch 00073: val_loss did not improve from 0.31321

Epoch 00074: val_loss did not improve from 0.31321

Epoch 00075: val_loss did not improve from 0.31321

Epoch 00076: val_loss did not improve from 0.31321
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9495747723338602 0.9231179925253604 0.8545576242800247 0.9322189939440613 0.9223950956847773 0.9226150307804604 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9184466019417474 0.8894230769230769 0.7918123956129907 0.9034178187403994 0.8885344429033749 0.8882843331854378 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9333579335793358 0.8714011516314779 0.7614904140411137 0.8861111111111111 0.8754538745387455 0.8708511386129456 None
average testing metrics
[0.91822583 0.87082534 0.75860621 0.88454572 0.87428044 0.86994998]
std testing metrics
[0.03669077 0.03065073 0.04607774 0.01742252 0.02894255 0.03208456]
End of this run.
########################################################################################################
(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_2 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.22117, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.22117 to 0.97556, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.97556 to 0.92094, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.92094 to 0.72019, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.72019 to 0.65444, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.65444 to 0.62337, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.62337 to 0.57526, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.57526

Epoch 00009: val_loss did not improve from 0.57526

Epoch 00010: val_loss improved from 0.57526 to 0.53988, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.53988 to 0.49737, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.49737 to 0.47845, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.47845 to 0.45089, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.45089

Epoch 00015: val_loss improved from 0.45089 to 0.44702, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.44702 to 0.40629, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.40629

Epoch 00018: val_loss did not improve from 0.40629

Epoch 00019: val_loss improved from 0.40629 to 0.38238, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.38238

Epoch 00021: val_loss improved from 0.38238 to 0.37812, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.37812 to 0.34904, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.34904

Epoch 00024: val_loss did not improve from 0.34904

Epoch 00025: val_loss did not improve from 0.34904

Epoch 00026: val_loss did not improve from 0.34904

Epoch 00027: val_loss did not improve from 0.34904

Epoch 00028: val_loss did not improve from 0.34904

Epoch 00029: val_loss did not improve from 0.34904

Epoch 00030: val_loss improved from 0.34904 to 0.33305, saving model to 2_50_best_model.hdf5

Epoch 00031: val_loss improved from 0.33305 to 0.32776, saving model to 2_50_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.32776

Epoch 00033: val_loss did not improve from 0.32776

Epoch 00034: val_loss did not improve from 0.32776

Epoch 00035: val_loss did not improve from 0.32776

Epoch 00036: val_loss did not improve from 0.32776

Epoch 00037: val_loss did not improve from 0.32776

Epoch 00038: val_loss did not improve from 0.32776

Epoch 00039: val_loss did not improve from 0.32776
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9203746511189876 0.8894230769230769 0.7934494427715446 0.9051412149581665 0.8884830739199672 0.8881592295967742 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9127129510899432 0.8708133971291866 0.7563521400960821 0.8872191280967927 0.8693442022348415 0.8690871128639369 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9019630996309964 0.8522072936660269 0.7295725130765285 0.8727384805054708 0.8570036900369004 0.851145618819688 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_4 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.77444, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.77444 to 0.56000, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.56000 to 0.50099, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.50099

Epoch 00005: val_loss improved from 0.50099 to 0.48122, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.48122 to 0.44440, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.44440 to 0.42799, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.42799 to 0.42038, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.42038 to 0.41618, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.41618 to 0.41362, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.41362 to 0.41250, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.41250 to 0.41176, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.41176 to 0.39274, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.39274

Epoch 00015: val_loss did not improve from 0.39274

Epoch 00016: val_loss did not improve from 0.39274

Epoch 00017: val_loss did not improve from 0.39274

Epoch 00018: val_loss did not improve from 0.39274

Epoch 00019: val_loss did not improve from 0.39274

Epoch 00020: val_loss did not improve from 0.39274

Epoch 00021: val_loss did not improve from 0.39274
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8342313402710784 0.8254137746930059 0.6776513690580335 0.8543730556504948 0.8239604215558156 0.821305375709743 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8381877022653721 0.8317307692307693 0.6942125835589162 0.8647875816993464 0.8302820157189089 0.8273858921161825 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8344059040590406 0.8080614203454894 0.671350616275611 0.8571428571428572 0.8154981549815499 0.8035444947209652 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                20400     
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_8 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.98092, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.98092 to 0.85753, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.85753 to 0.64574, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.64574

Epoch 00005: val_loss improved from 0.64574 to 0.57426, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.57426 to 0.55372, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.55372 to 0.49496, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.49496 to 0.45279, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.45279 to 0.43332, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.43332 to 0.42194, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.42194 to 0.41451, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.41451 to 0.41027, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.41027 to 0.39898, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.39898 to 0.39319, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.39319 to 0.38969, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.38969 to 0.37802, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.37802

Epoch 00018: val_loss did not improve from 0.37802

Epoch 00019: val_loss did not improve from 0.37802

Epoch 00020: val_loss improved from 0.37802 to 0.37445, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.37445

Epoch 00022: val_loss did not improve from 0.37445

Epoch 00023: val_loss did not improve from 0.37445

Epoch 00024: val_loss did not improve from 0.37445

Epoch 00025: val_loss did not improve from 0.37445

Epoch 00026: val_loss improved from 0.37445 to 0.36985, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.36985

Epoch 00028: val_loss improved from 0.36985 to 0.36400, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.36400 to 0.35123, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.35123

Epoch 00031: val_loss did not improve from 0.35123

Epoch 00032: val_loss improved from 0.35123 to 0.34656, saving model to 2_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.34656

Epoch 00034: val_loss improved from 0.34656 to 0.33031, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.33031

Epoch 00036: val_loss did not improve from 0.33031

Epoch 00037: val_loss did not improve from 0.33031

Epoch 00038: val_loss improved from 0.33031 to 0.32211, saving model to 2_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.32211

Epoch 00040: val_loss did not improve from 0.32211

Epoch 00041: val_loss did not improve from 0.32211

Epoch 00042: val_loss did not improve from 0.32211

Epoch 00043: val_loss improved from 0.32211 to 0.31566, saving model to 2_50_best_model.hdf5

Epoch 00044: val_loss improved from 0.31566 to 0.30635, saving model to 2_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.30635

Epoch 00046: val_loss improved from 0.30635 to 0.30629, saving model to 2_50_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.30629

Epoch 00048: val_loss did not improve from 0.30629

Epoch 00049: val_loss did not improve from 0.30629

Epoch 00050: val_loss improved from 0.30629 to 0.29700, saving model to 2_50_best_model.hdf5

Epoch 00051: val_loss did not improve from 0.29700

Epoch 00052: val_loss improved from 0.29700 to 0.29663, saving model to 2_50_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.29663

Epoch 00054: val_loss did not improve from 0.29663

Epoch 00055: val_loss did not improve from 0.29663

Epoch 00056: val_loss did not improve from 0.29663

Epoch 00057: val_loss did not improve from 0.29663

Epoch 00058: val_loss did not improve from 0.29663

Epoch 00059: val_loss did not improve from 0.29663

Epoch 00060: val_loss did not improve from 0.29663
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9296703772883498 0.9044313934863855 0.8220411626707737 0.9186749411361028 0.9035061611828377 0.9034587514055722 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9194637078132223 0.8846153846153846 0.7866172360812108 0.9032759793914649 0.8835876098012021 0.8830584707646177 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9173874538745387 0.8733205374280231 0.7634247182140536 0.8863361456348846 0.8771439114391144 0.8728704525288375 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_10 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.14066, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 2.14066 to 0.97789, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.97789 to 0.59545, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.59545 to 0.49844, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.49844 to 0.48199, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.48199 to 0.45083, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.45083 to 0.41712, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.41712

Epoch 00009: val_loss improved from 0.41712 to 0.40744, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.40744 to 0.40064, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.40064 to 0.38317, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.38317 to 0.35043, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.35043

Epoch 00014: val_loss did not improve from 0.35043

Epoch 00015: val_loss did not improve from 0.35043

Epoch 00016: val_loss did not improve from 0.35043

Epoch 00017: val_loss did not improve from 0.35043

Epoch 00018: val_loss did not improve from 0.35043

Epoch 00019: val_loss improved from 0.35043 to 0.34079, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.34079

Epoch 00021: val_loss improved from 0.34079 to 0.33655, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.33655 to 0.33619, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss improved from 0.33619 to 0.33292, saving model to 2_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.33292

Epoch 00025: val_loss improved from 0.33292 to 0.33181, saving model to 2_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.33181 to 0.33124, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.33124 to 0.32564, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.32564

Epoch 00029: val_loss did not improve from 0.32564

Epoch 00030: val_loss did not improve from 0.32564

Epoch 00031: val_loss did not improve from 0.32564

Epoch 00032: val_loss improved from 0.32564 to 0.32123, saving model to 2_50_best_model.hdf5

Epoch 00033: val_loss improved from 0.32123 to 0.31668, saving model to 2_50_best_model.hdf5

Epoch 00034: val_loss improved from 0.31668 to 0.30752, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss improved from 0.30752 to 0.30240, saving model to 2_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.30240

Epoch 00037: val_loss improved from 0.30240 to 0.29883, saving model to 2_50_best_model.hdf5

Epoch 00038: val_loss improved from 0.29883 to 0.29310, saving model to 2_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.29310

Epoch 00040: val_loss did not improve from 0.29310

Epoch 00041: val_loss improved from 0.29310 to 0.29170, saving model to 2_50_best_model.hdf5

Epoch 00042: val_loss did not improve from 0.29170

Epoch 00043: val_loss did not improve from 0.29170

Epoch 00044: val_loss did not improve from 0.29170

Epoch 00045: val_loss improved from 0.29170 to 0.28618, saving model to 2_50_best_model.hdf5

Epoch 00046: val_loss did not improve from 0.28618

Epoch 00047: val_loss improved from 0.28618 to 0.28616, saving model to 2_50_best_model.hdf5

Epoch 00048: val_loss did not improve from 0.28616

Epoch 00049: val_loss did not improve from 0.28616

Epoch 00050: val_loss did not improve from 0.28616

Epoch 00051: val_loss did not improve from 0.28616

Epoch 00052: val_loss did not improve from 0.28616

Epoch 00053: val_loss improved from 0.28616 to 0.28595, saving model to 2_50_best_model.hdf5

Epoch 00054: val_loss improved from 0.28595 to 0.28311, saving model to 2_50_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.28311

Epoch 00056: val_loss did not improve from 0.28311

Epoch 00057: val_loss did not improve from 0.28311

Epoch 00058: val_loss did not improve from 0.28311

Epoch 00059: val_loss improved from 0.28311 to 0.27898, saving model to 2_50_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.27898

Epoch 00061: val_loss did not improve from 0.27898

Epoch 00062: val_loss did not improve from 0.27898

Epoch 00063: val_loss did not improve from 0.27898

Epoch 00064: val_loss did not improve from 0.27898

Epoch 00065: val_loss did not improve from 0.27898

Epoch 00066: val_loss did not improve from 0.27898

Epoch 00067: val_loss did not improve from 0.27898
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9235570881540627 0.9049652963160705 0.8196660998022821 0.9155808979752642 0.9041646996038506 0.9042220066971108 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9222838650023115 0.8846153846153846 0.7741361023574934 0.8901098901098901 0.8840499306518723 0.8840902758428533 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.883970479704797 0.8560460652591171 0.7390121382570648 0.8782086967279025 0.8610036900369004 0.8549150654413813 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_14 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.74640, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.74640 to 0.61943, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.61943 to 0.60664, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.60664 to 0.49067, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.49067 to 0.47372, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.47372

Epoch 00007: val_loss improved from 0.47372 to 0.42724, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.42724 to 0.41700, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.41700 to 0.40963, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.40963 to 0.40537, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.40537 to 0.40267, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.40267 to 0.40205, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.40205 to 0.39605, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.39605 to 0.39361, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.39361 to 0.38995, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.38995 to 0.38991, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.38991 to 0.38680, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.38680

Epoch 00019: val_loss did not improve from 0.38680

Epoch 00020: val_loss did not improve from 0.38680

Epoch 00021: val_loss improved from 0.38680 to 0.38480, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.38480

Epoch 00023: val_loss did not improve from 0.38480

Epoch 00024: val_loss improved from 0.38480 to 0.37994, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.37994

Epoch 00026: val_loss improved from 0.37994 to 0.37342, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.37342 to 0.37160, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.37160

Epoch 00029: val_loss did not improve from 0.37160

Epoch 00030: val_loss improved from 0.37160 to 0.36454, saving model to 2_50_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.36454

Epoch 00032: val_loss did not improve from 0.36454

Epoch 00033: val_loss did not improve from 0.36454

Epoch 00034: val_loss improved from 0.36454 to 0.36377, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss improved from 0.36377 to 0.35304, saving model to 2_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.35304

Epoch 00037: val_loss did not improve from 0.35304

Epoch 00038: val_loss did not improve from 0.35304

Epoch 00039: val_loss did not improve from 0.35304

Epoch 00040: val_loss improved from 0.35304 to 0.34059, saving model to 2_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.34059

Epoch 00042: val_loss did not improve from 0.34059

Epoch 00043: val_loss did not improve from 0.34059

Epoch 00044: val_loss did not improve from 0.34059

Epoch 00045: val_loss improved from 0.34059 to 0.33562, saving model to 2_50_best_model.hdf5

Epoch 00046: val_loss improved from 0.33562 to 0.33498, saving model to 2_50_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.33498

Epoch 00048: val_loss did not improve from 0.33498

Epoch 00049: val_loss improved from 0.33498 to 0.33167, saving model to 2_50_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.33167

Epoch 00051: val_loss improved from 0.33167 to 0.33123, saving model to 2_50_best_model.hdf5

Epoch 00052: val_loss improved from 0.33123 to 0.32787, saving model to 2_50_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.32787

Epoch 00054: val_loss improved from 0.32787 to 0.31143, saving model to 2_50_best_model.hdf5

Epoch 00055: val_loss improved from 0.31143 to 0.31136, saving model to 2_50_best_model.hdf5

Epoch 00056: val_loss improved from 0.31136 to 0.31093, saving model to 2_50_best_model.hdf5

Epoch 00057: val_loss improved from 0.31093 to 0.30939, saving model to 2_50_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.30939

Epoch 00059: val_loss improved from 0.30939 to 0.30317, saving model to 2_50_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.30317

Epoch 00061: val_loss did not improve from 0.30317

Epoch 00062: val_loss did not improve from 0.30317

Epoch 00063: val_loss did not improve from 0.30317

Epoch 00064: val_loss did not improve from 0.30317

Epoch 00065: val_loss did not improve from 0.30317

Epoch 00066: val_loss improved from 0.30317 to 0.29624, saving model to 2_50_best_model.hdf5

Epoch 00067: val_loss improved from 0.29624 to 0.29344, saving model to 2_50_best_model.hdf5

Epoch 00068: val_loss did not improve from 0.29344

Epoch 00069: val_loss improved from 0.29344 to 0.29244, saving model to 2_50_best_model.hdf5

Epoch 00070: val_loss did not improve from 0.29244

Epoch 00071: val_loss improved from 0.29244 to 0.29004, saving model to 2_50_best_model.hdf5

Epoch 00072: val_loss did not improve from 0.29004

Epoch 00073: val_loss improved from 0.29004 to 0.28812, saving model to 2_50_best_model.hdf5

Epoch 00074: val_loss did not improve from 0.28812

Epoch 00075: val_loss improved from 0.28812 to 0.28621, saving model to 2_50_best_model.hdf5

Epoch 00076: val_loss did not improve from 0.28621

Epoch 00077: val_loss did not improve from 0.28621

Epoch 00078: val_loss did not improve from 0.28621

Epoch 00079: val_loss did not improve from 0.28621

Epoch 00080: val_loss did not improve from 0.28621

Epoch 00081: val_loss did not improve from 0.28621

Epoch 00082: val_loss did not improve from 0.28621

Epoch 00083: val_loss did not improve from 0.28621
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9354506911517523 0.9172450613988254 0.8408692724422139 0.9243017084189866 0.9166028083955382 0.9168064378116553 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9194637078132224 0.8846153846153846 0.7741361023574934 0.8901098901098901 0.8840499306518723 0.8840902758428533 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9106273062730628 0.8618042226487524 0.738857101467301 0.873446455505279 0.8654538745387454 0.8613747228381374 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_16 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.72258, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 2.72258 to 1.78579, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 1.78579 to 1.05621, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 1.05621 to 0.55713, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.55713

Epoch 00006: val_loss improved from 0.55713 to 0.53270, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.53270 to 0.47609, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.47609 to 0.46077, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.46077 to 0.44275, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.44275 to 0.43219, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.43219

Epoch 00012: val_loss improved from 0.43219 to 0.42505, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.42505 to 0.41357, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.41357

Epoch 00015: val_loss improved from 0.41357 to 0.40833, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.40833 to 0.40821, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.40821

Epoch 00018: val_loss improved from 0.40821 to 0.40720, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.40720

Epoch 00020: val_loss improved from 0.40720 to 0.40216, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.40216 to 0.39881, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.39881 to 0.39712, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.39712

Epoch 00024: val_loss did not improve from 0.39712

Epoch 00025: val_loss did not improve from 0.39712

Epoch 00026: val_loss did not improve from 0.39712

Epoch 00027: val_loss did not improve from 0.39712

Epoch 00028: val_loss improved from 0.39712 to 0.39687, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss improved from 0.39687 to 0.39623, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.39623

Epoch 00031: val_loss did not improve from 0.39623

Epoch 00032: val_loss did not improve from 0.39623

Epoch 00033: val_loss did not improve from 0.39623

Epoch 00034: val_loss improved from 0.39623 to 0.39595, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.39595

Epoch 00036: val_loss did not improve from 0.39595

Epoch 00037: val_loss did not improve from 0.39595

Epoch 00038: val_loss improved from 0.39595 to 0.39447, saving model to 2_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.39447

Epoch 00040: val_loss did not improve from 0.39447

Epoch 00041: val_loss did not improve from 0.39447

Epoch 00042: val_loss improved from 0.39447 to 0.38487, saving model to 2_50_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.38487

Epoch 00044: val_loss did not improve from 0.38487

Epoch 00045: val_loss did not improve from 0.38487

Epoch 00046: val_loss improved from 0.38487 to 0.36099, saving model to 2_50_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.36099

Epoch 00048: val_loss did not improve from 0.36099

Epoch 00049: val_loss did not improve from 0.36099

Epoch 00050: val_loss did not improve from 0.36099

Epoch 00051: val_loss did not improve from 0.36099

Epoch 00052: val_loss did not improve from 0.36099

Epoch 00053: val_loss did not improve from 0.36099

Epoch 00054: val_loss did not improve from 0.36099
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8802817062017785 0.8531767218366257 0.7199820116402084 0.867996620599093 0.8521595498904146 0.8514140867205748 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8615811373092926 0.8413461538461539 0.6993821988078095 0.859375 0.8402681460933887 0.8390206149299936 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8724132841328412 0.8349328214971209 0.6997131933276443 0.8597412528480914 0.8402435424354243 0.8333358131230472 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_20 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.98034, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.98034 to 0.50860, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.50860

Epoch 00004: val_loss improved from 0.50860 to 0.44149, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.44149

Epoch 00006: val_loss improved from 0.44149 to 0.43182, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.43182 to 0.42895, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.42895

Epoch 00009: val_loss did not improve from 0.42895

Epoch 00010: val_loss did not improve from 0.42895

Epoch 00011: val_loss did not improve from 0.42895

Epoch 00012: val_loss did not improve from 0.42895

Epoch 00013: val_loss did not improve from 0.42895

Epoch 00014: val_loss did not improve from 0.42895

Epoch 00015: val_loss did not improve from 0.42895
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8221934860002144 0.8216764548852109 0.6875876427415758 0.86953125 0.819848975188781 0.8151091171324538 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8009708737864077 0.7932692307692307 0.642866514157432 0.8547297297297297 0.7912621359223301 0.7831179223550522 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8173431734317343 0.8042226487523992 0.6655142813178699 0.8551136363636364 0.8118081180811808 0.7993733011174872 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_22 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_23 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_23 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.13710, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 2.13710 to 0.75761, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.75761 to 0.65017, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.65017 to 0.60273, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60273

Epoch 00006: val_loss improved from 0.60273 to 0.59397, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.59397 to 0.49992, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.49992 to 0.49270, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.49270 to 0.46509, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.46509 to 0.43494, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.43494 to 0.41730, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.41730 to 0.40537, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.40537 to 0.39434, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.39434 to 0.38733, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.38733

Epoch 00016: val_loss improved from 0.38733 to 0.38287, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.38287 to 0.38028, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.38028 to 0.37748, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.37748 to 0.37461, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.37461 to 0.37044, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.37044

Epoch 00022: val_loss improved from 0.37044 to 0.36938, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.36938

Epoch 00024: val_loss did not improve from 0.36938

Epoch 00025: val_loss did not improve from 0.36938

Epoch 00026: val_loss did not improve from 0.36938

Epoch 00027: val_loss improved from 0.36938 to 0.35658, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss improved from 0.35658 to 0.35550, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.35550

Epoch 00030: val_loss did not improve from 0.35550

Epoch 00031: val_loss improved from 0.35550 to 0.35371, saving model to 2_50_best_model.hdf5

Epoch 00032: val_loss improved from 0.35371 to 0.35261, saving model to 2_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.35261

Epoch 00034: val_loss did not improve from 0.35261

Epoch 00035: val_loss did not improve from 0.35261

Epoch 00036: val_loss did not improve from 0.35261

Epoch 00037: val_loss improved from 0.35261 to 0.35057, saving model to 2_50_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.35057

Epoch 00039: val_loss did not improve from 0.35057

Epoch 00040: val_loss did not improve from 0.35057

Epoch 00041: val_loss did not improve from 0.35057

Epoch 00042: val_loss did not improve from 0.35057

Epoch 00043: val_loss improved from 0.35057 to 0.34660, saving model to 2_50_best_model.hdf5

Epoch 00044: val_loss did not improve from 0.34660

Epoch 00045: val_loss did not improve from 0.34660

Epoch 00046: val_loss improved from 0.34660 to 0.34461, saving model to 2_50_best_model.hdf5

Epoch 00047: val_loss improved from 0.34461 to 0.33850, saving model to 2_50_best_model.hdf5

Epoch 00048: val_loss improved from 0.33850 to 0.31983, saving model to 2_50_best_model.hdf5

Epoch 00049: val_loss did not improve from 0.31983

Epoch 00050: val_loss did not improve from 0.31983

Epoch 00051: val_loss did not improve from 0.31983

Epoch 00052: val_loss improved from 0.31983 to 0.31679, saving model to 2_50_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.31679

Epoch 00054: val_loss did not improve from 0.31679

Epoch 00055: val_loss improved from 0.31679 to 0.31351, saving model to 2_50_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.31351

Epoch 00057: val_loss improved from 0.31351 to 0.31248, saving model to 2_50_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.31248

Epoch 00059: val_loss did not improve from 0.31248

Epoch 00060: val_loss did not improve from 0.31248

Epoch 00061: val_loss did not improve from 0.31248

Epoch 00062: val_loss did not improve from 0.31248

Epoch 00063: val_loss did not improve from 0.31248

Epoch 00064: val_loss did not improve from 0.31248

Epoch 00065: val_loss improved from 0.31248 to 0.27878, saving model to 2_50_best_model.hdf5

Epoch 00066: val_loss improved from 0.27878 to 0.27815, saving model to 2_50_best_model.hdf5

Epoch 00067: val_loss did not improve from 0.27815

Epoch 00068: val_loss did not improve from 0.27815

Epoch 00069: val_loss improved from 0.27815 to 0.27372, saving model to 2_50_best_model.hdf5

Epoch 00070: val_loss did not improve from 0.27372

Epoch 00071: val_loss did not improve from 0.27372

Epoch 00072: val_loss did not improve from 0.27372

Epoch 00073: val_loss did not improve from 0.27372

Epoch 00074: val_loss did not improve from 0.27372

Epoch 00075: val_loss did not improve from 0.27372

Epoch 00076: val_loss did not improve from 0.27372

Epoch 00077: val_loss did not improve from 0.27372
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8969401625193 0.8889482114255206 0.791611795246735 0.9037860392916397 0.8879834698303879 0.8877313187155198 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9185390661118816 0.9038461538461539 0.8171487191605791 0.9141255818371806 0.9030975496994914 0.9031206334420121 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8663321033210332 0.8426103646833013 0.7208507846065392 0.8728674333375458 0.8483985239852398 0.8407036749791195 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_25 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_26 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_26 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.34036, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 1.34036 to 0.90383, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.90383 to 0.55783, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.55783 to 0.50607, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.50607 to 0.45867, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.45867 to 0.43721, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.43721 to 0.40109, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.40109 to 0.38639, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.38639 to 0.37624, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.37624

Epoch 00011: val_loss improved from 0.37624 to 0.35863, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.35863 to 0.35428, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.35428 to 0.34675, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.34675

Epoch 00015: val_loss did not improve from 0.34675

Epoch 00016: val_loss did not improve from 0.34675

Epoch 00017: val_loss did not improve from 0.34675

Epoch 00018: val_loss did not improve from 0.34675

Epoch 00019: val_loss did not improve from 0.34675

Epoch 00020: val_loss did not improve from 0.34675

Epoch 00021: val_loss did not improve from 0.34675
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8437958268619817 0.816871329418046 0.6799636022738192 0.8669511249030256 0.8149946062567421 0.8097652265193207 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8835876098012021 0.8557692307692307 0.7424557636312744 0.8888888888888888 0.854368932038835 0.8522727272727273 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8136531365313653 0.8042226487523992 0.6655142813178699 0.8551136363636364 0.8118081180811808 0.7993733011174872 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 50)                20400     
_________________________________________________________________
activation_28 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_29 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_29 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 23,001
Trainable params: 23,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66897, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66897 to 0.56701, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.56701 to 0.50071, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.50071 to 0.46825, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.46825

Epoch 00006: val_loss improved from 0.46825 to 0.44955, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.44955 to 0.43054, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.43054 to 0.42535, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.42535 to 0.41640, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.41640 to 0.40666, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.40666

Epoch 00012: val_loss did not improve from 0.40666

Epoch 00013: val_loss did not improve from 0.40666

Epoch 00014: val_loss did not improve from 0.40666

Epoch 00015: val_loss improved from 0.40666 to 0.40296, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.40296

Epoch 00017: val_loss did not improve from 0.40296

Epoch 00018: val_loss did not improve from 0.40296

Epoch 00019: val_loss did not improve from 0.40296

Epoch 00020: val_loss did not improve from 0.40296

Epoch 00021: val_loss did not improve from 0.40296

Epoch 00022: val_loss did not improve from 0.40296

Epoch 00023: val_loss did not improve from 0.40296
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8289807079601615 0.8275493860117459 0.6957840506058965 0.8714777928021635 0.8258037589715169 0.821744402064301 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8155339805825242 0.8173076923076923 0.6807140220947664 0.8671328671328671 0.8155339805825244 0.8102918586789555 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8154981549815499 0.8023032629558541 0.662601854515699 0.8541076487252124 0.8099630996309963 0.7972816252828492 None
average testing metrics
[0.86335941 0.83397313 0.70564115 0.86648162 0.83983247 0.83139181]
std testing metrics
[0.03856989 0.02581199 0.03555784 0.01097445 0.02433163 0.0276457 ]
End of this run.
########################################################################################################
(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.44551, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 1.44551 to 1.14308, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 1.14308 to 0.85557, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.85557 to 0.73036, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.73036 to 0.59490, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.59490 to 0.53141, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.53141

Epoch 00008: val_loss improved from 0.53141 to 0.50638, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.50638 to 0.49713, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.49713

Epoch 00011: val_loss improved from 0.49713 to 0.47956, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.47956 to 0.46850, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.46850

Epoch 00014: val_loss improved from 0.46850 to 0.44462, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.44462 to 0.43458, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.43458

Epoch 00017: val_loss did not improve from 0.43458

Epoch 00018: val_loss did not improve from 0.43458

Epoch 00019: val_loss improved from 0.43458 to 0.41039, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.41039

Epoch 00021: val_loss improved from 0.41039 to 0.40612, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.40612

Epoch 00023: val_loss did not improve from 0.40612

Epoch 00024: val_loss did not improve from 0.40612

Epoch 00025: val_loss did not improve from 0.40612

Epoch 00026: val_loss improved from 0.40612 to 0.37983, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.37983

Epoch 00028: val_loss did not improve from 0.37983

Epoch 00029: val_loss did not improve from 0.37983

Epoch 00030: val_loss did not improve from 0.37983

Epoch 00031: val_loss did not improve from 0.37983

Epoch 00032: val_loss did not improve from 0.37983

Epoch 00033: val_loss did not improve from 0.37983

Epoch 00034: val_loss did not improve from 0.37983
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9410443885093291 0.905448717948718 0.8162349586937219 0.9113807917677679 0.9048800534237427 0.9050115315537426 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9226964645539476 0.861244019138756 0.7260583474837454 0.8656168710516536 0.860459791170544 0.8606186041163619 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9299040590405905 0.8541266794625719 0.718016468751638 0.861038961038961 0.856988929889299 0.8539324184742512 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_3 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.97692, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.97692 to 1.98057, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 1.98057 to 1.73347, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 1.73347 to 0.69106, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.69106 to 0.49304, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.49304 to 0.48922, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.48922 to 0.42771, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.42771

Epoch 00009: val_loss did not improve from 0.42771

Epoch 00010: val_loss did not improve from 0.42771

Epoch 00011: val_loss did not improve from 0.42771

Epoch 00012: val_loss did not improve from 0.42771

Epoch 00013: val_loss did not improve from 0.42771

Epoch 00014: val_loss improved from 0.42771 to 0.42504, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.42504

Epoch 00016: val_loss did not improve from 0.42504

Epoch 00017: val_loss improved from 0.42504 to 0.39751, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.39751

Epoch 00019: val_loss did not improve from 0.39751

Epoch 00020: val_loss did not improve from 0.39751

Epoch 00021: val_loss did not improve from 0.39751

Epoch 00022: val_loss did not improve from 0.39751

Epoch 00023: val_loss did not improve from 0.39751

Epoch 00024: val_loss did not improve from 0.39751

Epoch 00025: val_loss did not improve from 0.39751
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9046276720695325 0.8627869727709557 0.7409467794876172 0.8794307832531525 0.8617274574601285 0.8610062702396782 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9147480351363846 0.8076923076923077 0.6263738416617731 0.8197590361445783 0.8067498844197873 0.8055165965404394 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9327675276752768 0.8560460652591171 0.7316223785715272 0.871480105939298 0.8602287822878228 0.8553554572544375 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.03561, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.03561

Epoch 00003: val_loss did not improve from 2.03561

Epoch 00004: val_loss did not improve from 2.03561

Epoch 00005: val_loss improved from 2.03561 to 0.90872, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.90872 to 0.60328, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.60328 to 0.51960, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.51960 to 0.49740, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.49740

Epoch 00010: val_loss did not improve from 0.49740

Epoch 00011: val_loss did not improve from 0.49740

Epoch 00012: val_loss did not improve from 0.49740

Epoch 00013: val_loss did not improve from 0.49740

Epoch 00014: val_loss did not improve from 0.49740

Epoch 00015: val_loss did not improve from 0.49740

Epoch 00016: val_loss improved from 0.49740 to 0.45786, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.45786

Epoch 00018: val_loss did not improve from 0.45786

Epoch 00019: val_loss did not improve from 0.45786

Epoch 00020: val_loss improved from 0.45786 to 0.44512, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss improved from 0.44512 to 0.43442, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss improved from 0.43442 to 0.42234, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.42234

Epoch 00024: val_loss did not improve from 0.42234

Epoch 00025: val_loss did not improve from 0.42234

Epoch 00026: val_loss did not improve from 0.42234

Epoch 00027: val_loss improved from 0.42234 to 0.41887, saving model to 1_100_best_model.hdf5

Epoch 00028: val_loss improved from 0.41887 to 0.39607, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.39607

Epoch 00030: val_loss did not improve from 0.39607

Epoch 00031: val_loss did not improve from 0.39607

Epoch 00032: val_loss improved from 0.39607 to 0.36683, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.36683

Epoch 00034: val_loss did not improve from 0.36683

Epoch 00035: val_loss did not improve from 0.36683

Epoch 00036: val_loss did not improve from 0.36683

Epoch 00037: val_loss did not improve from 0.36683

Epoch 00038: val_loss did not improve from 0.36683

Epoch 00039: val_loss improved from 0.36683 to 0.35217, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.35217

Epoch 00041: val_loss did not improve from 0.35217

Epoch 00042: val_loss did not improve from 0.35217

Epoch 00043: val_loss improved from 0.35217 to 0.34652, saving model to 1_100_best_model.hdf5

Epoch 00044: val_loss did not improve from 0.34652

Epoch 00045: val_loss did not improve from 0.34652

Epoch 00046: val_loss did not improve from 0.34652

Epoch 00047: val_loss did not improve from 0.34652

Epoch 00048: val_loss did not improve from 0.34652

Epoch 00049: val_loss improved from 0.34652 to 0.33787, saving model to 1_100_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.33787

Epoch 00051: val_loss did not improve from 0.33787

Epoch 00052: val_loss improved from 0.33787 to 0.31073, saving model to 1_100_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.31073

Epoch 00054: val_loss did not improve from 0.31073

Epoch 00055: val_loss improved from 0.31073 to 0.29856, saving model to 1_100_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.29856

Epoch 00057: val_loss did not improve from 0.29856

Epoch 00058: val_loss did not improve from 0.29856

Epoch 00059: val_loss did not improve from 0.29856

Epoch 00060: val_loss did not improve from 0.29856

Epoch 00061: val_loss did not improve from 0.29856

Epoch 00062: val_loss improved from 0.29856 to 0.29397, saving model to 1_100_best_model.hdf5

Epoch 00063: val_loss did not improve from 0.29397

Epoch 00064: val_loss did not improve from 0.29397

Epoch 00065: val_loss did not improve from 0.29397

Epoch 00066: val_loss improved from 0.29397 to 0.28912, saving model to 1_100_best_model.hdf5

Epoch 00067: val_loss did not improve from 0.28912

Epoch 00068: val_loss did not improve from 0.28912

Epoch 00069: val_loss did not improve from 0.28912

Epoch 00070: val_loss did not improve from 0.28912

Epoch 00071: val_loss improved from 0.28912 to 0.28647, saving model to 1_100_best_model.hdf5

Epoch 00072: val_loss improved from 0.28647 to 0.28456, saving model to 1_100_best_model.hdf5

Epoch 00073: val_loss did not improve from 0.28456

Epoch 00074: val_loss did not improve from 0.28456

Epoch 00075: val_loss did not improve from 0.28456

Epoch 00076: val_loss did not improve from 0.28456

Epoch 00077: val_loss improved from 0.28456 to 0.28126, saving model to 1_100_best_model.hdf5

Epoch 00078: val_loss did not improve from 0.28126

Epoch 00079: val_loss improved from 0.28126 to 0.26236, saving model to 1_100_best_model.hdf5

Epoch 00080: val_loss did not improve from 0.26236

Epoch 00081: val_loss did not improve from 0.26236

Epoch 00082: val_loss did not improve from 0.26236

Epoch 00083: val_loss did not improve from 0.26236

Epoch 00084: val_loss did not improve from 0.26236

Epoch 00085: val_loss did not improve from 0.26236

Epoch 00086: val_loss did not improve from 0.26236

Epoch 00087: val_loss did not improve from 0.26236
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9692545231041505 0.9343299519487454 0.8751236833262698 0.9414577752190285 0.9337002903270684 0.933992097239879 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9467406380027739 0.9182692307692307 0.8395425703697105 0.92170586039567 0.9178455848358761 0.9180400064900447 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9469667896678966 0.8944337811900192 0.7943797353734662 0.8978716786634675 0.8965092250922508 0.8944088850565817 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.66077, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.66077 to 2.59959, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 2.59959 to 1.80814, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 1.80814 to 0.74079, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.74079 to 0.57287, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.57287 to 0.43549, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.43549

Epoch 00008: val_loss improved from 0.43549 to 0.43480, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.43480 to 0.43244, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.43244

Epoch 00011: val_loss improved from 0.43244 to 0.42677, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.42677 to 0.39193, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.39193

Epoch 00014: val_loss improved from 0.39193 to 0.39113, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.39113

Epoch 00016: val_loss improved from 0.39113 to 0.37443, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.37443

Epoch 00018: val_loss did not improve from 0.37443

Epoch 00019: val_loss did not improve from 0.37443

Epoch 00020: val_loss did not improve from 0.37443

Epoch 00021: val_loss did not improve from 0.37443

Epoch 00022: val_loss improved from 0.37443 to 0.36087, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.36087

Epoch 00024: val_loss improved from 0.36087 to 0.35439, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.35439

Epoch 00026: val_loss improved from 0.35439 to 0.32889, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.32889

Epoch 00028: val_loss improved from 0.32889 to 0.32729, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.32729

Epoch 00030: val_loss did not improve from 0.32729

Epoch 00031: val_loss improved from 0.32729 to 0.31581, saving model to 1_100_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.31581

Epoch 00033: val_loss did not improve from 0.31581

Epoch 00034: val_loss did not improve from 0.31581

Epoch 00035: val_loss did not improve from 0.31581

Epoch 00036: val_loss improved from 0.31581 to 0.30912, saving model to 1_100_best_model.hdf5

Epoch 00037: val_loss improved from 0.30912 to 0.30739, saving model to 1_100_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.30739

Epoch 00039: val_loss improved from 0.30739 to 0.29880, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.29880

Epoch 00041: val_loss did not improve from 0.29880

Epoch 00042: val_loss improved from 0.29880 to 0.28998, saving model to 1_100_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.28998

Epoch 00044: val_loss did not improve from 0.28998

Epoch 00045: val_loss did not improve from 0.28998

Epoch 00046: val_loss did not improve from 0.28998

Epoch 00047: val_loss improved from 0.28998 to 0.28599, saving model to 1_100_best_model.hdf5

Epoch 00048: val_loss did not improve from 0.28599

Epoch 00049: val_loss did not improve from 0.28599

Epoch 00050: val_loss did not improve from 0.28599

Epoch 00051: val_loss did not improve from 0.28599

Epoch 00052: val_loss did not improve from 0.28599

Epoch 00053: val_loss did not improve from 0.28599

Epoch 00054: val_loss did not improve from 0.28599

Epoch 00055: val_loss did not improve from 0.28599
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9476094200072525 0.9060331019754405 0.820754208112176 0.9155424681623242 0.9052759475541141 0.9053681950233674 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9392048081368469 0.8798076923076923 0.7722149446030546 0.8934331797235023 0.8789181692094313 0.8785699273754758 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9251955719557196 0.8675623800383877 0.7536920002007351 0.8821569520340011 0.8716088560885609 0.8669959487207948 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_9 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.64639, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 1.64639 to 0.71569, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.71569 to 0.52014, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.52014 to 0.49860, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.49860 to 0.49560, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.49560 to 0.47400, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.47400 to 0.47168, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.47168

Epoch 00009: val_loss did not improve from 0.47168

Epoch 00010: val_loss improved from 0.47168 to 0.46689, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.46689 to 0.44897, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.44897 to 0.44573, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.44573 to 0.43304, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.43304

Epoch 00015: val_loss improved from 0.43304 to 0.43170, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.43170 to 0.41749, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.41749

Epoch 00018: val_loss improved from 0.41749 to 0.41290, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.41290

Epoch 00020: val_loss improved from 0.41290 to 0.40061, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss improved from 0.40061 to 0.39610, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss improved from 0.39610 to 0.38960, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss improved from 0.38960 to 0.37831, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.37831

Epoch 00025: val_loss did not improve from 0.37831

Epoch 00026: val_loss did not improve from 0.37831

Epoch 00027: val_loss improved from 0.37831 to 0.37576, saving model to 1_100_best_model.hdf5

Epoch 00028: val_loss improved from 0.37576 to 0.37198, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss improved from 0.37198 to 0.36630, saving model to 1_100_best_model.hdf5

Epoch 00030: val_loss improved from 0.36630 to 0.35664, saving model to 1_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.35664

Epoch 00032: val_loss did not improve from 0.35664

Epoch 00033: val_loss did not improve from 0.35664

Epoch 00034: val_loss did not improve from 0.35664

Epoch 00035: val_loss improved from 0.35664 to 0.34947, saving model to 1_100_best_model.hdf5

Epoch 00036: val_loss improved from 0.34947 to 0.34888, saving model to 1_100_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.34888

Epoch 00038: val_loss did not improve from 0.34888

Epoch 00039: val_loss improved from 0.34888 to 0.34092, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss improved from 0.34092 to 0.33657, saving model to 1_100_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.33657

Epoch 00042: val_loss improved from 0.33657 to 0.33273, saving model to 1_100_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.33273

Epoch 00044: val_loss improved from 0.33273 to 0.32471, saving model to 1_100_best_model.hdf5

Epoch 00045: val_loss improved from 0.32471 to 0.32178, saving model to 1_100_best_model.hdf5

Epoch 00046: val_loss improved from 0.32178 to 0.30689, saving model to 1_100_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.30689

Epoch 00048: val_loss did not improve from 0.30689

Epoch 00049: val_loss did not improve from 0.30689

Epoch 00050: val_loss did not improve from 0.30689

Epoch 00051: val_loss did not improve from 0.30689

Epoch 00052: val_loss did not improve from 0.30689

Epoch 00053: val_loss improved from 0.30689 to 0.30684, saving model to 1_100_best_model.hdf5

Epoch 00054: val_loss improved from 0.30684 to 0.30016, saving model to 1_100_best_model.hdf5

Epoch 00055: val_loss improved from 0.30016 to 0.30012, saving model to 1_100_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.30012

Epoch 00057: val_loss improved from 0.30012 to 0.29833, saving model to 1_100_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.29833

Epoch 00059: val_loss did not improve from 0.29833

Epoch 00060: val_loss improved from 0.29833 to 0.29079, saving model to 1_100_best_model.hdf5

Epoch 00061: val_loss improved from 0.29079 to 0.28759, saving model to 1_100_best_model.hdf5

Epoch 00062: val_loss did not improve from 0.28759

Epoch 00063: val_loss improved from 0.28759 to 0.28381, saving model to 1_100_best_model.hdf5

Epoch 00064: val_loss did not improve from 0.28381

Epoch 00065: val_loss improved from 0.28381 to 0.28130, saving model to 1_100_best_model.hdf5

Epoch 00066: val_loss did not improve from 0.28130

Epoch 00067: val_loss did not improve from 0.28130

Epoch 00068: val_loss did not improve from 0.28130

Epoch 00069: val_loss improved from 0.28130 to 0.27898, saving model to 1_100_best_model.hdf5

Epoch 00070: val_loss did not improve from 0.27898

Epoch 00071: val_loss did not improve from 0.27898

Epoch 00072: val_loss did not improve from 0.27898

Epoch 00073: val_loss did not improve from 0.27898

Epoch 00074: val_loss improved from 0.27898 to 0.27818, saving model to 1_100_best_model.hdf5

Epoch 00075: val_loss did not improve from 0.27818

Epoch 00076: val_loss improved from 0.27818 to 0.27525, saving model to 1_100_best_model.hdf5

Epoch 00077: val_loss improved from 0.27525 to 0.27519, saving model to 1_100_best_model.hdf5

Epoch 00078: val_loss improved from 0.27519 to 0.27475, saving model to 1_100_best_model.hdf5

Epoch 00079: val_loss did not improve from 0.27475

Epoch 00080: val_loss improved from 0.27475 to 0.27134, saving model to 1_100_best_model.hdf5

Epoch 00081: val_loss did not improve from 0.27134

Epoch 00082: val_loss did not improve from 0.27134

Epoch 00083: val_loss did not improve from 0.27134

Epoch 00084: val_loss did not improve from 0.27134

Epoch 00085: val_loss did not improve from 0.27134

Epoch 00086: val_loss improved from 0.27134 to 0.26757, saving model to 1_100_best_model.hdf5

Epoch 00087: val_loss did not improve from 0.26757

Epoch 00088: val_loss did not improve from 0.26757

Epoch 00089: val_loss did not improve from 0.26757

Epoch 00090: val_loss did not improve from 0.26757

Epoch 00091: val_loss did not improve from 0.26757

Epoch 00092: val_loss improved from 0.26757 to 0.26593, saving model to 1_100_best_model.hdf5

Epoch 00093: val_loss did not improve from 0.26593

Epoch 00094: val_loss did not improve from 0.26593

Epoch 00095: val_loss improved from 0.26593 to 0.26508, saving model to 1_100_best_model.hdf5

Epoch 00096: val_loss did not improve from 0.26508

Epoch 00097: val_loss improved from 0.26508 to 0.26294, saving model to 1_100_best_model.hdf5

Epoch 00098: val_loss improved from 0.26294 to 0.26275, saving model to 1_100_best_model.hdf5

Epoch 00099: val_loss did not improve from 0.26275

Epoch 00100: val_loss did not improve from 0.26275
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9504750599241455 0.9321943406300054 0.8720164379828318 0.9405530291917266 0.9315102937252406 0.9317911689333551 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9309292649098474 0.9086538461538461 0.82354702533569 0.9155367231638418 0.9080443828016643 0.9081763052115523 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9192915129151293 0.8771593090211133 0.7738739836365528 0.8926584587323301 0.8812988929889298 0.8766024217662907 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.14727, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 3.14727 to 3.05030, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 3.05030 to 2.67571, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 2.67571

Epoch 00005: val_loss did not improve from 2.67571

Epoch 00006: val_loss did not improve from 2.67571

Epoch 00007: val_loss improved from 2.67571 to 2.64924, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 2.64924

Epoch 00009: val_loss improved from 2.64924 to 1.64006, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 1.64006

Epoch 00011: val_loss did not improve from 1.64006

Epoch 00012: val_loss did not improve from 1.64006

Epoch 00013: val_loss did not improve from 1.64006

Epoch 00014: val_loss did not improve from 1.64006

Epoch 00015: val_loss improved from 1.64006 to 1.02625, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 1.02625 to 0.59938, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.59938 to 0.52446, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss improved from 0.52446 to 0.48054, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss improved from 0.48054 to 0.44721, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.44721

Epoch 00021: val_loss did not improve from 0.44721

Epoch 00022: val_loss did not improve from 0.44721

Epoch 00023: val_loss improved from 0.44721 to 0.43493, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.43493

Epoch 00025: val_loss improved from 0.43493 to 0.38575, saving model to 1_100_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.38575

Epoch 00027: val_loss did not improve from 0.38575

Epoch 00028: val_loss improved from 0.38575 to 0.37463, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.37463

Epoch 00030: val_loss did not improve from 0.37463

Epoch 00031: val_loss did not improve from 0.37463

Epoch 00032: val_loss improved from 0.37463 to 0.36176, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.36176

Epoch 00034: val_loss did not improve from 0.36176

Epoch 00035: val_loss did not improve from 0.36176

Epoch 00036: val_loss did not improve from 0.36176

Epoch 00037: val_loss did not improve from 0.36176

Epoch 00038: val_loss did not improve from 0.36176

Epoch 00039: val_loss did not improve from 0.36176

Epoch 00040: val_loss did not improve from 0.36176
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9459690606676382 0.9108382274426055 0.8240287348138436 0.9136011794637255 0.9104336432740135 0.9106225881620098 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9203421174294959 0.8701923076923077 0.7442804564013478 0.8746251874062968 0.869671752196024 0.869683257918552 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9396088560885609 0.8809980806142035 0.7657354066785081 0.88307130825379 0.8826642066420665 0.8809941348109287 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.59000, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.59000 to 2.09614, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 2.09614 to 1.46407, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 1.46407 to 0.76212, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.76212 to 0.56402, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.56402 to 0.51748, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.51748 to 0.46403, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.46403

Epoch 00009: val_loss did not improve from 0.46403

Epoch 00010: val_loss did not improve from 0.46403

Epoch 00011: val_loss improved from 0.46403 to 0.46240, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.46240 to 0.43544, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.43544 to 0.43290, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.43290

Epoch 00015: val_loss improved from 0.43290 to 0.41742, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.41742 to 0.41712, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.41712 to 0.41068, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.41068

Epoch 00019: val_loss improved from 0.41068 to 0.40655, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.40655

Epoch 00021: val_loss improved from 0.40655 to 0.38583, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss improved from 0.38583 to 0.38566, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss improved from 0.38566 to 0.38223, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.38223

Epoch 00025: val_loss did not improve from 0.38223

Epoch 00026: val_loss did not improve from 0.38223

Epoch 00027: val_loss did not improve from 0.38223

Epoch 00028: val_loss improved from 0.38223 to 0.36844, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.36844

Epoch 00030: val_loss improved from 0.36844 to 0.35945, saving model to 1_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.35945

Epoch 00032: val_loss did not improve from 0.35945

Epoch 00033: val_loss did not improve from 0.35945

Epoch 00034: val_loss did not improve from 0.35945

Epoch 00035: val_loss did not improve from 0.35945

Epoch 00036: val_loss did not improve from 0.35945

Epoch 00037: val_loss did not improve from 0.35945

Epoch 00038: val_loss did not improve from 0.35945
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9487115453473548 0.9017618793379605 0.8128962422618399 0.911999250120098 0.9009717860474239 0.901012189937844 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9112806287563568 0.8942307692307693 0.80020865283633 0.906934481109517 0.8933888118354137 0.8932437476670398 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9113948339483394 0.8598848368522073 0.7394315867261597 0.8754452190325428 0.8640738007380073 0.8592126450609858 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_15 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.55081, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 1.55081

Epoch 00003: val_loss did not improve from 1.55081

Epoch 00004: val_loss improved from 1.55081 to 0.63604, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.63604

Epoch 00006: val_loss improved from 0.63604 to 0.49943, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.49943 to 0.48321, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.48321 to 0.47320, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.47320

Epoch 00010: val_loss improved from 0.47320 to 0.46601, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.46601 to 0.45905, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.45905 to 0.44889, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.44889 to 0.44040, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.44040

Epoch 00015: val_loss improved from 0.44040 to 0.42874, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.42874 to 0.42372, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.42372 to 0.41627, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.41627

Epoch 00019: val_loss improved from 0.41627 to 0.40920, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss improved from 0.40920 to 0.40109, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss improved from 0.40109 to 0.39557, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss improved from 0.39557 to 0.39363, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.39363

Epoch 00024: val_loss improved from 0.39363 to 0.39332, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss improved from 0.39332 to 0.38725, saving model to 1_100_best_model.hdf5

Epoch 00026: val_loss improved from 0.38725 to 0.38537, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.38537

Epoch 00028: val_loss improved from 0.38537 to 0.37801, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss improved from 0.37801 to 0.37534, saving model to 1_100_best_model.hdf5

Epoch 00030: val_loss improved from 0.37534 to 0.37328, saving model to 1_100_best_model.hdf5

Epoch 00031: val_loss improved from 0.37328 to 0.36719, saving model to 1_100_best_model.hdf5

Epoch 00032: val_loss improved from 0.36719 to 0.36331, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss improved from 0.36331 to 0.36100, saving model to 1_100_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.36100

Epoch 00035: val_loss did not improve from 0.36100

Epoch 00036: val_loss improved from 0.36100 to 0.35782, saving model to 1_100_best_model.hdf5

Epoch 00037: val_loss improved from 0.35782 to 0.35548, saving model to 1_100_best_model.hdf5

Epoch 00038: val_loss improved from 0.35548 to 0.35064, saving model to 1_100_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.35064

Epoch 00040: val_loss improved from 0.35064 to 0.34665, saving model to 1_100_best_model.hdf5

Epoch 00041: val_loss improved from 0.34665 to 0.34181, saving model to 1_100_best_model.hdf5

Epoch 00042: val_loss improved from 0.34181 to 0.34060, saving model to 1_100_best_model.hdf5

Epoch 00043: val_loss improved from 0.34060 to 0.33834, saving model to 1_100_best_model.hdf5

Epoch 00044: val_loss improved from 0.33834 to 0.33827, saving model to 1_100_best_model.hdf5

Epoch 00045: val_loss improved from 0.33827 to 0.33400, saving model to 1_100_best_model.hdf5

Epoch 00046: val_loss did not improve from 0.33400

Epoch 00047: val_loss improved from 0.33400 to 0.33002, saving model to 1_100_best_model.hdf5

Epoch 00048: val_loss did not improve from 0.33002

Epoch 00049: val_loss did not improve from 0.33002

Epoch 00050: val_loss improved from 0.33002 to 0.32566, saving model to 1_100_best_model.hdf5

Epoch 00051: val_loss did not improve from 0.32566

Epoch 00052: val_loss did not improve from 0.32566

Epoch 00053: val_loss did not improve from 0.32566

Epoch 00054: val_loss did not improve from 0.32566

Epoch 00055: val_loss did not improve from 0.32566

Epoch 00056: val_loss did not improve from 0.32566

Epoch 00057: val_loss improved from 0.32566 to 0.32257, saving model to 1_100_best_model.hdf5

Epoch 00058: val_loss did not improve from 0.32257

Epoch 00059: val_loss improved from 0.32257 to 0.31927, saving model to 1_100_best_model.hdf5

Epoch 00060: val_loss did not improve from 0.31927

Epoch 00061: val_loss did not improve from 0.31927

Epoch 00062: val_loss did not improve from 0.31927

Epoch 00063: val_loss improved from 0.31927 to 0.31436, saving model to 1_100_best_model.hdf5

Epoch 00064: val_loss did not improve from 0.31436

Epoch 00065: val_loss did not improve from 0.31436

Epoch 00066: val_loss did not improve from 0.31436

Epoch 00067: val_loss did not improve from 0.31436

Epoch 00068: val_loss improved from 0.31436 to 0.31011, saving model to 1_100_best_model.hdf5

Epoch 00069: val_loss did not improve from 0.31011

Epoch 00070: val_loss improved from 0.31011 to 0.30686, saving model to 1_100_best_model.hdf5

Epoch 00071: val_loss improved from 0.30686 to 0.29755, saving model to 1_100_best_model.hdf5

Epoch 00072: val_loss improved from 0.29755 to 0.29730, saving model to 1_100_best_model.hdf5

Epoch 00073: val_loss did not improve from 0.29730

Epoch 00074: val_loss did not improve from 0.29730

Epoch 00075: val_loss improved from 0.29730 to 0.28597, saving model to 1_100_best_model.hdf5

Epoch 00076: val_loss did not improve from 0.28597

Epoch 00077: val_loss did not improve from 0.28597

Epoch 00078: val_loss did not improve from 0.28597

Epoch 00079: val_loss did not improve from 0.28597

Epoch 00080: val_loss improved from 0.28597 to 0.28470, saving model to 1_100_best_model.hdf5

Epoch 00081: val_loss did not improve from 0.28470

Epoch 00082: val_loss did not improve from 0.28470

Epoch 00083: val_loss did not improve from 0.28470

Epoch 00084: val_loss did not improve from 0.28470

Epoch 00085: val_loss did not improve from 0.28470

Epoch 00086: val_loss did not improve from 0.28470

Epoch 00087: val_loss improved from 0.28470 to 0.27992, saving model to 1_100_best_model.hdf5

Epoch 00088: val_loss did not improve from 0.27992

Epoch 00089: val_loss did not improve from 0.27992

Epoch 00090: val_loss did not improve from 0.27992

Epoch 00091: val_loss did not improve from 0.27992

Epoch 00092: val_loss did not improve from 0.27992

Epoch 00093: val_loss did not improve from 0.27992

Epoch 00094: val_loss did not improve from 0.27992

Epoch 00095: val_loss did not improve from 0.27992
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9622705948626021 0.9348638547784304 0.8756359882158191 0.9414037869515226 0.9342613308519834 0.934553405310286 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9350901525658807 0.8942307692307693 0.79351979193139 0.8998778998778998 0.8936662043458159 0.8937494195226154 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9472915129151291 0.8963531669865643 0.7978634280301502 0.8995100216123397 0.8983542435424354 0.896334453484259 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.08922, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.08922 to 1.14833, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 1.14833

Epoch 00004: val_loss improved from 1.14833 to 0.62861, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.62861

Epoch 00006: val_loss did not improve from 0.62861

Epoch 00007: val_loss improved from 0.62861 to 0.57745, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.57745 to 0.50058, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.50058 to 0.49915, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.49915 to 0.48171, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.48171 to 0.46751, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.46751 to 0.44977, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.44977

Epoch 00014: val_loss improved from 0.44977 to 0.41342, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.41342

Epoch 00016: val_loss did not improve from 0.41342

Epoch 00017: val_loss did not improve from 0.41342

Epoch 00018: val_loss improved from 0.41342 to 0.40781, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss improved from 0.40781 to 0.40338, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss improved from 0.40338 to 0.37545, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.37545

Epoch 00022: val_loss did not improve from 0.37545

Epoch 00023: val_loss improved from 0.37545 to 0.37195, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.37195 to 0.34993, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.34993

Epoch 00026: val_loss improved from 0.34993 to 0.34573, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.34573

Epoch 00028: val_loss did not improve from 0.34573

Epoch 00029: val_loss did not improve from 0.34573

Epoch 00030: val_loss improved from 0.34573 to 0.34449, saving model to 1_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.34449

Epoch 00032: val_loss improved from 0.34449 to 0.33677, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.33677

Epoch 00034: val_loss improved from 0.33677 to 0.32255, saving model to 1_100_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.32255

Epoch 00036: val_loss did not improve from 0.32255

Epoch 00037: val_loss did not improve from 0.32255

Epoch 00038: val_loss did not improve from 0.32255

Epoch 00039: val_loss improved from 0.32255 to 0.30474, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss improved from 0.30474 to 0.30190, saving model to 1_100_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.30190

Epoch 00042: val_loss did not improve from 0.30190

Epoch 00043: val_loss did not improve from 0.30190

Epoch 00044: val_loss improved from 0.30190 to 0.29402, saving model to 1_100_best_model.hdf5

Epoch 00045: val_loss improved from 0.29402 to 0.29096, saving model to 1_100_best_model.hdf5

Epoch 00046: val_loss improved from 0.29096 to 0.28149, saving model to 1_100_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.28149

Epoch 00048: val_loss did not improve from 0.28149

Epoch 00049: val_loss improved from 0.28149 to 0.27572, saving model to 1_100_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.27572

Epoch 00051: val_loss did not improve from 0.27572

Epoch 00052: val_loss improved from 0.27572 to 0.27053, saving model to 1_100_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.27053

Epoch 00054: val_loss did not improve from 0.27053

Epoch 00055: val_loss improved from 0.27053 to 0.26452, saving model to 1_100_best_model.hdf5

Epoch 00056: val_loss did not improve from 0.26452

Epoch 00057: val_loss did not improve from 0.26452

Epoch 00058: val_loss did not improve from 0.26452

Epoch 00059: val_loss did not improve from 0.26452

Epoch 00060: val_loss did not improve from 0.26452

Epoch 00061: val_loss did not improve from 0.26452

Epoch 00062: val_loss did not improve from 0.26452

Epoch 00063: val_loss did not improve from 0.26452
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9619313477972318 0.9279231179925254 0.862424032879294 0.9351782167868716 0.9272819639155154 0.9275410909972481 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9408229311141932 0.9086538461538461 0.8256961858266963 0.9178030303030302 0.9079519186315302 0.9080395578824898 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9475719557195572 0.8963531669865643 0.7971636977186549 0.8989648033126294 0.8981992619926199 0.8963436201255637 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 40,901
Trainable params: 40,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.06400, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 3.06400

Epoch 00003: val_loss did not improve from 3.06400

Epoch 00004: val_loss did not improve from 3.06400

Epoch 00005: val_loss improved from 3.06400 to 2.74241, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 2.74241

Epoch 00007: val_loss did not improve from 2.74241

Epoch 00008: val_loss improved from 2.74241 to 2.65933, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 2.65933 to 2.37135, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 2.37135

Epoch 00011: val_loss did not improve from 2.37135

Epoch 00012: val_loss did not improve from 2.37135

Epoch 00013: val_loss did not improve from 2.37135

Epoch 00014: val_loss did not improve from 2.37135

Epoch 00015: val_loss did not improve from 2.37135

Epoch 00016: val_loss improved from 2.37135 to 1.02484, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 1.02484

Epoch 00018: val_loss did not improve from 1.02484

Epoch 00019: val_loss did not improve from 1.02484

Epoch 00020: val_loss improved from 1.02484 to 0.98481, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.98481

Epoch 00022: val_loss improved from 0.98481 to 0.80108, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss improved from 0.80108 to 0.72869, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.72869 to 0.58639, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss improved from 0.58639 to 0.53229, saving model to 1_100_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.53229

Epoch 00027: val_loss improved from 0.53229 to 0.50809, saving model to 1_100_best_model.hdf5

Epoch 00028: val_loss improved from 0.50809 to 0.47204, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.47204

Epoch 00030: val_loss did not improve from 0.47204

Epoch 00031: val_loss improved from 0.47204 to 0.46434, saving model to 1_100_best_model.hdf5

Epoch 00032: val_loss improved from 0.46434 to 0.45523, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss improved from 0.45523 to 0.43579, saving model to 1_100_best_model.hdf5

Epoch 00034: val_loss improved from 0.43579 to 0.42948, saving model to 1_100_best_model.hdf5

Epoch 00035: val_loss improved from 0.42948 to 0.41953, saving model to 1_100_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.41953

Epoch 00037: val_loss did not improve from 0.41953

Epoch 00038: val_loss did not improve from 0.41953

Epoch 00039: val_loss improved from 0.41953 to 0.41772, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.41772

Epoch 00041: val_loss improved from 0.41772 to 0.40815, saving model to 1_100_best_model.hdf5

Epoch 00042: val_loss improved from 0.40815 to 0.40360, saving model to 1_100_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.40360

Epoch 00044: val_loss did not improve from 0.40360

Epoch 00045: val_loss improved from 0.40360 to 0.38972, saving model to 1_100_best_model.hdf5

Epoch 00046: val_loss did not improve from 0.38972

Epoch 00047: val_loss did not improve from 0.38972

Epoch 00048: val_loss did not improve from 0.38972

Epoch 00049: val_loss improved from 0.38972 to 0.38469, saving model to 1_100_best_model.hdf5

Epoch 00050: val_loss did not improve from 0.38469

Epoch 00051: val_loss improved from 0.38469 to 0.37727, saving model to 1_100_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.37727

Epoch 00053: val_loss did not improve from 0.37727

Epoch 00054: val_loss improved from 0.37727 to 0.36638, saving model to 1_100_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.36638

Epoch 00056: val_loss did not improve from 0.36638

Epoch 00057: val_loss did not improve from 0.36638

Epoch 00058: val_loss did not improve from 0.36638

Epoch 00059: val_loss did not improve from 0.36638

Epoch 00060: val_loss did not improve from 0.36638

Epoch 00061: val_loss did not improve from 0.36638

Epoch 00062: val_loss did not improve from 0.36638
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9488677700463657 0.9087026161238655 0.8223767284043434 0.9142752470709161 0.908124482576955 0.908300701481038 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9197411003236245 0.8653846153846154 0.7353687232097003 0.8705738705738706 0.8648173832639852 0.8647719884833287 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9303025830258304 0.8790786948176583 0.7628609404965622 0.8818873172752559 0.8809741697416975 0.8790626554411305 None
average testing metrics
[0.93302952 0.87619962 0.76346396 0.88440848 0.87909004 0.87592426]
std testing metrics
[0.01178074 0.01552806 0.0267228  0.01223149 0.01478704 0.01573827]
End of this run.
########################################################################################################
(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_2 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.25559, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 1.25559 to 1.17738, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 1.17738

Epoch 00004: val_loss improved from 1.17738 to 0.68742, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.68742 to 0.68613, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.68613 to 0.54184, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.54184 to 0.51991, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.51991 to 0.48241, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.48241

Epoch 00010: val_loss improved from 0.48241 to 0.45403, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.45403 to 0.42436, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.42436 to 0.41564, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.41564 to 0.38506, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss improved from 0.38506 to 0.36809, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.36809 to 0.36058, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.36058 to 0.34402, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.34402

Epoch 00018: val_loss did not improve from 0.34402

Epoch 00019: val_loss did not improve from 0.34402

Epoch 00020: val_loss did not improve from 0.34402

Epoch 00021: val_loss improved from 0.34402 to 0.34387, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.34387

Epoch 00023: val_loss did not improve from 0.34387

Epoch 00024: val_loss improved from 0.34387 to 0.32248, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss improved from 0.32248 to 0.30413, saving model to 2_100_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.30413

Epoch 00027: val_loss improved from 0.30413 to 0.29572, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss improved from 0.29572 to 0.29477, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss improved from 0.29477 to 0.29302, saving model to 2_100_best_model.hdf5

Epoch 00030: val_loss improved from 0.29302 to 0.27666, saving model to 2_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.27666

Epoch 00032: val_loss improved from 0.27666 to 0.27401, saving model to 2_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.27401

Epoch 00034: val_loss did not improve from 0.27401

Epoch 00035: val_loss did not improve from 0.27401

Epoch 00036: val_loss did not improve from 0.27401

Epoch 00037: val_loss did not improve from 0.27401

Epoch 00038: val_loss did not improve from 0.27401

Epoch 00039: val_loss did not improve from 0.27401

Epoch 00040: val_loss did not improve from 0.27401
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9500870418885521 0.9193376068376068 0.84286458697356 0.9240384615384616 0.9188421431139877 0.9190426206783966 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9288331196189777 0.9090909090909091 0.8224541006435109 0.9141583054626533 0.9083165414911156 0.9086811544210648 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9340073800738008 0.8790786948176583 0.7687846682903207 0.8867398774839385 0.8820590405904059 0.8789002401850643 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_4 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.72880, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.72880 to 0.60423, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60423 to 0.53586, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.53586 to 0.44829, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.44829 to 0.42554, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.42554

Epoch 00007: val_loss improved from 0.42554 to 0.41295, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.41295 to 0.40190, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.40190

Epoch 00010: val_loss improved from 0.40190 to 0.38939, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.38939

Epoch 00012: val_loss did not improve from 0.38939

Epoch 00013: val_loss improved from 0.38939 to 0.37487, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.37487

Epoch 00015: val_loss did not improve from 0.37487

Epoch 00016: val_loss did not improve from 0.37487

Epoch 00017: val_loss did not improve from 0.37487

Epoch 00018: val_loss did not improve from 0.37487

Epoch 00019: val_loss improved from 0.37487 to 0.37052, saving model to 2_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.37052

Epoch 00021: val_loss improved from 0.37052 to 0.36577, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.36577

Epoch 00023: val_loss did not improve from 0.36577

Epoch 00024: val_loss did not improve from 0.36577

Epoch 00025: val_loss did not improve from 0.36577

Epoch 00026: val_loss did not improve from 0.36577

Epoch 00027: val_loss improved from 0.36577 to 0.36164, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss improved from 0.36164 to 0.36125, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss improved from 0.36125 to 0.34089, saving model to 2_100_best_model.hdf5

Epoch 00030: val_loss improved from 0.34089 to 0.33566, saving model to 2_100_best_model.hdf5

Epoch 00031: val_loss improved from 0.33566 to 0.33398, saving model to 2_100_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.33398

Epoch 00033: val_loss did not improve from 0.33398

Epoch 00034: val_loss did not improve from 0.33398

Epoch 00035: val_loss did not improve from 0.33398

Epoch 00036: val_loss did not improve from 0.33398

Epoch 00037: val_loss did not improve from 0.33398

Epoch 00038: val_loss did not improve from 0.33398

Epoch 00039: val_loss did not improve from 0.33398
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9087967049132099 0.8739989321943407 0.7715142404767273 0.8992402682268447 0.8727293253145589 0.8716947527058502 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.916551086453999 0.8509615384615384 0.7302224017407734 0.8813029447357805 0.8496070272769303 0.8475758220457177 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.880760147601476 0.8330134357005758 0.6902841268243195 0.8526660502388658 0.8377785977859779 0.831813881004063 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               40800     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_8 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.54567, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 1.54567 to 1.10914, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 1.10914 to 0.58219, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.58219 to 0.54704, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.54704 to 0.51365, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.51365 to 0.44587, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.44587

Epoch 00008: val_loss improved from 0.44587 to 0.41805, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.41805 to 0.41436, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.41436 to 0.40576, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.40576

Epoch 00012: val_loss did not improve from 0.40576

Epoch 00013: val_loss did not improve from 0.40576

Epoch 00014: val_loss did not improve from 0.40576

Epoch 00015: val_loss improved from 0.40576 to 0.40314, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.40314

Epoch 00017: val_loss did not improve from 0.40314

Epoch 00018: val_loss did not improve from 0.40314

Epoch 00019: val_loss improved from 0.40314 to 0.39952, saving model to 2_100_best_model.hdf5

Epoch 00020: val_loss improved from 0.39952 to 0.39749, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.39749

Epoch 00022: val_loss improved from 0.39749 to 0.38092, saving model to 2_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.38092

Epoch 00024: val_loss did not improve from 0.38092

Epoch 00025: val_loss did not improve from 0.38092

Epoch 00026: val_loss did not improve from 0.38092

Epoch 00027: val_loss did not improve from 0.38092

Epoch 00028: val_loss improved from 0.38092 to 0.36292, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.36292

Epoch 00030: val_loss did not improve from 0.36292

Epoch 00031: val_loss did not improve from 0.36292

Epoch 00032: val_loss improved from 0.36292 to 0.35392, saving model to 2_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.35392

Epoch 00034: val_loss improved from 0.35392 to 0.33733, saving model to 2_100_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.33733

Epoch 00036: val_loss did not improve from 0.33733

Epoch 00037: val_loss did not improve from 0.33733

Epoch 00038: val_loss did not improve from 0.33733

Epoch 00039: val_loss did not improve from 0.33733

Epoch 00040: val_loss did not improve from 0.33733

Epoch 00041: val_loss improved from 0.33733 to 0.31739, saving model to 2_100_best_model.hdf5

Epoch 00042: val_loss did not improve from 0.31739

Epoch 00043: val_loss did not improve from 0.31739

Epoch 00044: val_loss improved from 0.31739 to 0.29717, saving model to 2_100_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.29717

Epoch 00046: val_loss improved from 0.29717 to 0.28757, saving model to 2_100_best_model.hdf5

Epoch 00047: val_loss improved from 0.28757 to 0.28539, saving model to 2_100_best_model.hdf5

Epoch 00048: val_loss improved from 0.28539 to 0.27134, saving model to 2_100_best_model.hdf5

Epoch 00049: val_loss did not improve from 0.27134

Epoch 00050: val_loss did not improve from 0.27134

Epoch 00051: val_loss did not improve from 0.27134

Epoch 00052: val_loss did not improve from 0.27134

Epoch 00053: val_loss did not improve from 0.27134

Epoch 00054: val_loss did not improve from 0.27134

Epoch 00055: val_loss did not improve from 0.27134

Epoch 00056: val_loss did not improve from 0.27134
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9335691528060008 0.9049652963160705 0.8193912469191197 0.9152911057213493 0.9041755327034171 0.9042400533094359 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9357374017568192 0.8942307692307693 0.80020865283633 0.906934481109517 0.8933888118354137 0.8932437476670398 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9120221402214022 0.8464491362763915 0.700776208251703 0.8517928879631007 0.848988929889299 0.8463217509291487 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_10 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.90821, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.90821 to 0.64721, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.64721 to 0.63421, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.63421 to 0.48764, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.48764 to 0.42117, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.42117 to 0.38685, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.38685 to 0.37767, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.37767 to 0.37616, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.37616 to 0.37552, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.37552 to 0.37527, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.37527 to 0.37224, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.37224 to 0.37170, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.37170 to 0.37104, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.37104

Epoch 00015: val_loss improved from 0.37104 to 0.36165, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.36165

Epoch 00017: val_loss did not improve from 0.36165

Epoch 00018: val_loss did not improve from 0.36165

Epoch 00019: val_loss did not improve from 0.36165

Epoch 00020: val_loss did not improve from 0.36165

Epoch 00021: val_loss improved from 0.36165 to 0.36067, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.36067

Epoch 00023: val_loss did not improve from 0.36067

Epoch 00024: val_loss improved from 0.36067 to 0.35392, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.35392

Epoch 00026: val_loss did not improve from 0.35392

Epoch 00027: val_loss did not improve from 0.35392

Epoch 00028: val_loss did not improve from 0.35392

Epoch 00029: val_loss did not improve from 0.35392

Epoch 00030: val_loss did not improve from 0.35392

Epoch 00031: val_loss did not improve from 0.35392

Epoch 00032: val_loss did not improve from 0.35392
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.863400316098442 0.8376935397757608 0.7054515725279116 0.8700719252880778 0.8361927014557405 0.8336220297579391 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8566805362921868 0.8557692307692307 0.7381689090530463 0.8843107769423559 0.8544613962089691 0.8527051269946181 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8265682656826568 0.8080614203454894 0.671350616275611 0.8571428571428572 0.8154981549815499 0.8035444947209652 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_14 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.03117, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 1.03117

Epoch 00003: val_loss did not improve from 1.03117

Epoch 00004: val_loss improved from 1.03117 to 0.55965, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.55965 to 0.54255, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.54255 to 0.53727, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.53727 to 0.46047, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.46047 to 0.44183, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.44183 to 0.41012, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.41012 to 0.39883, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.39883 to 0.39326, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.39326

Epoch 00013: val_loss improved from 0.39326 to 0.38058, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.38058

Epoch 00015: val_loss did not improve from 0.38058

Epoch 00016: val_loss did not improve from 0.38058

Epoch 00017: val_loss did not improve from 0.38058

Epoch 00018: val_loss did not improve from 0.38058

Epoch 00019: val_loss did not improve from 0.38058

Epoch 00020: val_loss did not improve from 0.38058

Epoch 00021: val_loss did not improve from 0.38058
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8436053923748662 0.8318206086492258 0.702631527091929 0.8738738389693044 0.8301187535777736 0.8264326998857683 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8396671289875173 0.8317307692307693 0.703665851855809 0.875 0.8300970873786409 0.8262322472848789 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8433431734317343 0.8099808061420346 0.6742747068329724 0.8581661891117478 0.8173431734317342 0.8056241214665527 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_16 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.72523, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.72523 to 1.60664, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 1.60664 to 0.88997, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.88997

Epoch 00005: val_loss improved from 0.88997 to 0.54519, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.54519 to 0.52704, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.52704 to 0.47155, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.47155 to 0.45284, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.45284

Epoch 00010: val_loss did not improve from 0.45284

Epoch 00011: val_loss improved from 0.45284 to 0.44596, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.44596 to 0.42712, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.42712

Epoch 00014: val_loss improved from 0.42712 to 0.41760, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.41760 to 0.40758, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.40758 to 0.38030, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.38030 to 0.36858, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.36858

Epoch 00019: val_loss improved from 0.36858 to 0.35861, saving model to 2_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.35861

Epoch 00021: val_loss did not improve from 0.35861

Epoch 00022: val_loss did not improve from 0.35861

Epoch 00023: val_loss did not improve from 0.35861

Epoch 00024: val_loss did not improve from 0.35861

Epoch 00025: val_loss did not improve from 0.35861

Epoch 00026: val_loss improved from 0.35861 to 0.35403, saving model to 2_100_best_model.hdf5

Epoch 00027: val_loss improved from 0.35403 to 0.32930, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.32930

Epoch 00029: val_loss did not improve from 0.32930

Epoch 00030: val_loss did not improve from 0.32930

Epoch 00031: val_loss did not improve from 0.32930

Epoch 00032: val_loss did not improve from 0.32930

Epoch 00033: val_loss did not improve from 0.32930

Epoch 00034: val_loss improved from 0.32930 to 0.32470, saving model to 2_100_best_model.hdf5

Epoch 00035: val_loss improved from 0.32470 to 0.31404, saving model to 2_100_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.31404

Epoch 00037: val_loss did not improve from 0.31404

Epoch 00038: val_loss improved from 0.31404 to 0.31397, saving model to 2_100_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.31397

Epoch 00040: val_loss did not improve from 0.31397

Epoch 00041: val_loss did not improve from 0.31397

Epoch 00042: val_loss did not improve from 0.31397

Epoch 00043: val_loss improved from 0.31397 to 0.31244, saving model to 2_100_best_model.hdf5

Epoch 00044: val_loss improved from 0.31244 to 0.30565, saving model to 2_100_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.30565

Epoch 00046: val_loss improved from 0.30565 to 0.29895, saving model to 2_100_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.29895

Epoch 00048: val_loss did not improve from 0.29895

Epoch 00049: val_loss did not improve from 0.29895

Epoch 00050: val_loss improved from 0.29895 to 0.29749, saving model to 2_100_best_model.hdf5

Epoch 00051: val_loss improved from 0.29749 to 0.29470, saving model to 2_100_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.29470

Epoch 00053: val_loss did not improve from 0.29470

Epoch 00054: val_loss did not improve from 0.29470

Epoch 00055: val_loss did not improve from 0.29470

Epoch 00056: val_loss improved from 0.29470 to 0.29300, saving model to 2_100_best_model.hdf5

Epoch 00057: val_loss did not improve from 0.29300

Epoch 00058: val_loss did not improve from 0.29300

Epoch 00059: val_loss did not improve from 0.29300

Epoch 00060: val_loss did not improve from 0.29300

Epoch 00061: val_loss did not improve from 0.29300

Epoch 00062: val_loss did not improve from 0.29300

Epoch 00063: val_loss did not improve from 0.29300

Epoch 00064: val_loss improved from 0.29300 to 0.29041, saving model to 2_100_best_model.hdf5

Epoch 00065: val_loss did not improve from 0.29041

Epoch 00066: val_loss did not improve from 0.29041

Epoch 00067: val_loss did not improve from 0.29041

Epoch 00068: val_loss improved from 0.29041 to 0.28998, saving model to 2_100_best_model.hdf5

Epoch 00069: val_loss did not improve from 0.28998

Epoch 00070: val_loss did not improve from 0.28998

Epoch 00071: val_loss did not improve from 0.28998

Epoch 00072: val_loss did not improve from 0.28998

Epoch 00073: val_loss did not improve from 0.28998

Epoch 00074: val_loss did not improve from 0.28998

Epoch 00075: val_loss did not improve from 0.28998

Epoch 00076: val_loss did not improve from 0.28998
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9363390053162011 0.9081687132941805 0.8276125766545273 0.9204017692157402 0.9073142807620116 0.9073599915341579 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9154415164123901 0.8798076923076923 0.7696008011601442 0.8906786122760199 0.8790106333795654 0.8787963545672797 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9158081180811808 0.8675623800383877 0.7550500030354247 0.8833754452190326 0.8717638376383764 0.8669270206740824 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_20 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.12909, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.12909 to 0.55022, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.55022

Epoch 00004: val_loss improved from 0.55022 to 0.50555, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.50555 to 0.44520, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.44520

Epoch 00007: val_loss improved from 0.44520 to 0.43523, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.43523 to 0.43237, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.43237

Epoch 00010: val_loss improved from 0.43237 to 0.43065, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.43065

Epoch 00012: val_loss did not improve from 0.43065

Epoch 00013: val_loss did not improve from 0.43065

Epoch 00014: val_loss improved from 0.43065 to 0.42832, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.42832

Epoch 00016: val_loss improved from 0.42832 to 0.41662, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.41662

Epoch 00018: val_loss did not improve from 0.41662

Epoch 00019: val_loss did not improve from 0.41662

Epoch 00020: val_loss did not improve from 0.41662

Epoch 00021: val_loss did not improve from 0.41662

Epoch 00022: val_loss did not improve from 0.41662

Epoch 00023: val_loss did not improve from 0.41662

Epoch 00024: val_loss did not improve from 0.41662
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8309700071384424 0.8275493860117459 0.6952153764336604 0.8708584816271432 0.8258145920710833 0.8218151743930387 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8087840961627368 0.8028846153846154 0.6522737436276929 0.8532986111111112 0.8010633379565418 0.7949161917129597 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8184944649446495 0.8080614203454894 0.671350616275611 0.8571428571428572 0.8154981549815499 0.8035444947209652 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_22 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_23 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.22729, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 2.22729 to 0.95790, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.95790 to 0.79098, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.79098 to 0.64866, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.64866 to 0.51041, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.51041 to 0.45958, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.45958 to 0.42708, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.42708 to 0.39115, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.39115 to 0.37395, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.37395

Epoch 00011: val_loss improved from 0.37395 to 0.37333, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.37333 to 0.36878, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.36878

Epoch 00014: val_loss did not improve from 0.36878

Epoch 00015: val_loss improved from 0.36878 to 0.36148, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.36148

Epoch 00017: val_loss improved from 0.36148 to 0.35858, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss improved from 0.35858 to 0.35334, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.35334

Epoch 00020: val_loss improved from 0.35334 to 0.35322, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.35322

Epoch 00022: val_loss did not improve from 0.35322

Epoch 00023: val_loss improved from 0.35322 to 0.32568, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.32568

Epoch 00025: val_loss did not improve from 0.32568

Epoch 00026: val_loss did not improve from 0.32568

Epoch 00027: val_loss did not improve from 0.32568

Epoch 00028: val_loss did not improve from 0.32568

Epoch 00029: val_loss did not improve from 0.32568

Epoch 00030: val_loss did not improve from 0.32568

Epoch 00031: val_loss improved from 0.32568 to 0.31036, saving model to 2_100_best_model.hdf5

Epoch 00032: val_loss improved from 0.31036 to 0.30373, saving model to 2_100_best_model.hdf5

Epoch 00033: val_loss improved from 0.30373 to 0.30191, saving model to 2_100_best_model.hdf5

Epoch 00034: val_loss improved from 0.30191 to 0.29367, saving model to 2_100_best_model.hdf5

Epoch 00035: val_loss improved from 0.29367 to 0.28904, saving model to 2_100_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.28904

Epoch 00037: val_loss improved from 0.28904 to 0.28833, saving model to 2_100_best_model.hdf5

Epoch 00038: val_loss improved from 0.28833 to 0.28558, saving model to 2_100_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.28558

Epoch 00040: val_loss did not improve from 0.28558

Epoch 00041: val_loss improved from 0.28558 to 0.27972, saving model to 2_100_best_model.hdf5

Epoch 00042: val_loss improved from 0.27972 to 0.27817, saving model to 2_100_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.27817

Epoch 00044: val_loss did not improve from 0.27817

Epoch 00045: val_loss did not improve from 0.27817

Epoch 00046: val_loss did not improve from 0.27817

Epoch 00047: val_loss improved from 0.27817 to 0.27399, saving model to 2_100_best_model.hdf5

Epoch 00048: val_loss improved from 0.27399 to 0.27257, saving model to 2_100_best_model.hdf5

Epoch 00049: val_loss did not improve from 0.27257

Epoch 00050: val_loss improved from 0.27257 to 0.26891, saving model to 2_100_best_model.hdf5

Epoch 00051: val_loss did not improve from 0.26891

Epoch 00052: val_loss did not improve from 0.26891

Epoch 00053: val_loss improved from 0.26891 to 0.26745, saving model to 2_100_best_model.hdf5

Epoch 00054: val_loss did not improve from 0.26745

Epoch 00055: val_loss did not improve from 0.26745

Epoch 00056: val_loss did not improve from 0.26745

Epoch 00057: val_loss did not improve from 0.26745

Epoch 00058: val_loss did not improve from 0.26745

Epoch 00059: val_loss did not improve from 0.26745

Epoch 00060: val_loss did not improve from 0.26745

Epoch 00061: val_loss did not improve from 0.26745
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9408090842951986 0.9145755472504005 0.8375300717906733 0.923747723132969 0.913840938169229 0.9140016988452444 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9256588072122052 0.8942307692307693 0.79351979193139 0.8998778998778998 0.8936662043458159 0.8937494195226154 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.918479704797048 0.8771593090211133 0.7654267009550727 0.8852291080935575 0.8802140221402214 0.876959409594096 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_25 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_26 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.41870, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 1.41870

Epoch 00003: val_loss improved from 1.41870 to 1.04021, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 1.04021 to 0.59406, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.59406 to 0.52243, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.52243 to 0.49016, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.49016 to 0.46651, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.46651 to 0.44214, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.44214

Epoch 00010: val_loss improved from 0.44214 to 0.38504, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.38504 to 0.35592, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.35592 to 0.34889, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.34889 to 0.34019, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss improved from 0.34019 to 0.33892, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.33892 to 0.32535, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.32535 to 0.32417, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.32417 to 0.31192, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.31192

Epoch 00019: val_loss did not improve from 0.31192

Epoch 00020: val_loss improved from 0.31192 to 0.31159, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss improved from 0.31159 to 0.30009, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.30009

Epoch 00023: val_loss improved from 0.30009 to 0.29286, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.29286 to 0.28857, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.28857

Epoch 00026: val_loss improved from 0.28857 to 0.28385, saving model to 2_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.28385

Epoch 00028: val_loss did not improve from 0.28385

Epoch 00029: val_loss did not improve from 0.28385

Epoch 00030: val_loss did not improve from 0.28385

Epoch 00031: val_loss did not improve from 0.28385

Epoch 00032: val_loss did not improve from 0.28385

Epoch 00033: val_loss did not improve from 0.28385

Epoch 00034: val_loss did not improve from 0.28385
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9287963172022778 0.8761345435130806 0.7725970293477995 0.8979885787877248 0.8749518212150861 0.8741534661838267 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9129912159038372 0.8942307692307693 0.8063371812547545 0.9133858267716535 0.8932038834951457 0.8928035982008995 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.879070110701107 0.8349328214971209 0.7126915086029308 0.8720238095238095 0.8413284132841328 0.8323229147955213 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 100)               40800     
_________________________________________________________________
activation_28 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_29 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 51,001
Trainable params: 51,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.95773, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 1.95773 to 0.78449, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.78449 to 0.64802, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.64802 to 0.54041, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.54041 to 0.46721, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.46721

Epoch 00007: val_loss did not improve from 0.46721

Epoch 00008: val_loss improved from 0.46721 to 0.43466, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.43466 to 0.42744, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.42744 to 0.41610, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.41610 to 0.41419, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.41419

Epoch 00013: val_loss did not improve from 0.41419

Epoch 00014: val_loss did not improve from 0.41419

Epoch 00015: val_loss did not improve from 0.41419

Epoch 00016: val_loss improved from 0.41419 to 0.40212, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.40212

Epoch 00018: val_loss improved from 0.40212 to 0.39398, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss improved from 0.39398 to 0.39322, saving model to 2_100_best_model.hdf5

Epoch 00020: val_loss improved from 0.39322 to 0.39294, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.39294

Epoch 00022: val_loss improved from 0.39294 to 0.38653, saving model to 2_100_best_model.hdf5

Epoch 00023: val_loss improved from 0.38653 to 0.37704, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.37704 to 0.37349, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.37349

Epoch 00026: val_loss did not improve from 0.37349

Epoch 00027: val_loss improved from 0.37349 to 0.36055, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.36055

Epoch 00029: val_loss did not improve from 0.36055

Epoch 00030: val_loss did not improve from 0.36055

Epoch 00031: val_loss did not improve from 0.36055

Epoch 00032: val_loss did not improve from 0.36055

Epoch 00033: val_loss did not improve from 0.36055

Epoch 00034: val_loss did not improve from 0.36055

Epoch 00035: val_loss improved from 0.36055 to 0.35833, saving model to 2_100_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.35833

Epoch 00037: val_loss did not improve from 0.35833

Epoch 00038: val_loss improved from 0.35833 to 0.34529, saving model to 2_100_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.34529

Epoch 00040: val_loss improved from 0.34529 to 0.33932, saving model to 2_100_best_model.hdf5

Epoch 00041: val_loss improved from 0.33932 to 0.33239, saving model to 2_100_best_model.hdf5

Epoch 00042: val_loss improved from 0.33239 to 0.32804, saving model to 2_100_best_model.hdf5

Epoch 00043: val_loss improved from 0.32804 to 0.32605, saving model to 2_100_best_model.hdf5

Epoch 00044: val_loss improved from 0.32605 to 0.32480, saving model to 2_100_best_model.hdf5

Epoch 00045: val_loss improved from 0.32480 to 0.31610, saving model to 2_100_best_model.hdf5

Epoch 00046: val_loss improved from 0.31610 to 0.31233, saving model to 2_100_best_model.hdf5

Epoch 00047: val_loss improved from 0.31233 to 0.31212, saving model to 2_100_best_model.hdf5

Epoch 00048: val_loss did not improve from 0.31212

Epoch 00049: val_loss did not improve from 0.31212

Epoch 00050: val_loss did not improve from 0.31212

Epoch 00051: val_loss did not improve from 0.31212

Epoch 00052: val_loss improved from 0.31212 to 0.30651, saving model to 2_100_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.30651

Epoch 00054: val_loss did not improve from 0.30651

Epoch 00055: val_loss improved from 0.30651 to 0.30281, saving model to 2_100_best_model.hdf5

Epoch 00056: val_loss improved from 0.30281 to 0.29694, saving model to 2_100_best_model.hdf5

Epoch 00057: val_loss did not improve from 0.29694

Epoch 00058: val_loss improved from 0.29694 to 0.29471, saving model to 2_100_best_model.hdf5

Epoch 00059: val_loss did not improve from 0.29471

Epoch 00060: val_loss did not improve from 0.29471

Epoch 00061: val_loss did not improve from 0.29471

Epoch 00062: val_loss did not improve from 0.29471

Epoch 00063: val_loss did not improve from 0.29471

Epoch 00064: val_loss improved from 0.29471 to 0.28898, saving model to 2_100_best_model.hdf5

Epoch 00065: val_loss did not improve from 0.28898

Epoch 00066: val_loss improved from 0.28898 to 0.28740, saving model to 2_100_best_model.hdf5

Epoch 00067: val_loss improved from 0.28740 to 0.28698, saving model to 2_100_best_model.hdf5

Epoch 00068: val_loss did not improve from 0.28698

Epoch 00069: val_loss did not improve from 0.28698

Epoch 00070: val_loss did not improve from 0.28698

Epoch 00071: val_loss improved from 0.28698 to 0.28384, saving model to 2_100_best_model.hdf5

Epoch 00072: val_loss improved from 0.28384 to 0.28237, saving model to 2_100_best_model.hdf5

Epoch 00073: val_loss did not improve from 0.28237

Epoch 00074: val_loss did not improve from 0.28237

Epoch 00075: val_loss did not improve from 0.28237

Epoch 00076: val_loss did not improve from 0.28237

Epoch 00077: val_loss improved from 0.28237 to 0.27956, saving model to 2_100_best_model.hdf5

Epoch 00078: val_loss improved from 0.27956 to 0.27914, saving model to 2_100_best_model.hdf5

Epoch 00079: val_loss did not improve from 0.27914

Epoch 00080: val_loss improved from 0.27914 to 0.27901, saving model to 2_100_best_model.hdf5

Epoch 00081: val_loss did not improve from 0.27901

Epoch 00082: val_loss improved from 0.27901 to 0.27664, saving model to 2_100_best_model.hdf5

Epoch 00083: val_loss did not improve from 0.27664

Epoch 00084: val_loss improved from 0.27664 to 0.27459, saving model to 2_100_best_model.hdf5

Epoch 00085: val_loss did not improve from 0.27459

Epoch 00086: val_loss did not improve from 0.27459

Epoch 00087: val_loss did not improve from 0.27459

Epoch 00088: val_loss did not improve from 0.27459

Epoch 00089: val_loss did not improve from 0.27459

Epoch 00090: val_loss improved from 0.27459 to 0.27134, saving model to 2_100_best_model.hdf5

Epoch 00091: val_loss did not improve from 0.27134

Epoch 00092: val_loss did not improve from 0.27134

Epoch 00093: val_loss did not improve from 0.27134

Epoch 00094: val_loss did not improve from 0.27134

Epoch 00095: val_loss improved from 0.27134 to 0.27061, saving model to 2_100_best_model.hdf5

Epoch 00096: val_loss did not improve from 0.27061

Epoch 00097: val_loss did not improve from 0.27061

Epoch 00098: val_loss did not improve from 0.27061

Epoch 00099: val_loss did not improve from 0.27061

Epoch 00100: val_loss did not improve from 0.27061
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9521005950222478 0.9279231179925254 0.8619693646228692 0.9346974453206748 0.9273036301146484 0.9275633432214982 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.922792417938049 0.9086538461538461 0.8256961858266963 0.9178030303030302 0.9079519186315302 0.9080395578824898 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9321771217712177 0.8387715930902111 0.6775052629630302 0.8402424134131451 0.837269372693727 0.8379543232915667 None
average testing metrics
[0.88607306 0.8403071  0.70874944 0.86445215 0.84477417 0.83839127]
std testing metrics
[0.04128172 0.02593374 0.03787138 0.01541263 0.02444609 0.02754672]
End of this run.
########################################################################################################
(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.31717, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.31717 to 1.54677, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 1.54677 to 1.01524, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 1.01524

Epoch 00005: val_loss improved from 1.01524 to 0.94114, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.94114 to 0.93328, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.93328 to 0.85608, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss improved from 0.85608 to 0.71276, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.71276

Epoch 00010: val_loss did not improve from 0.71276

Epoch 00011: val_loss improved from 0.71276 to 0.66592, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.66592

Epoch 00013: val_loss did not improve from 0.66592

Epoch 00014: val_loss improved from 0.66592 to 0.58418, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58418

Epoch 00016: val_loss did not improve from 0.58418

Epoch 00017: val_loss improved from 0.58418 to 0.40263, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.40263

Epoch 00019: val_loss improved from 0.40263 to 0.38340, saving model to 1_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.38340

Epoch 00021: val_loss did not improve from 0.38340

Epoch 00022: val_loss did not improve from 0.38340

Epoch 00023: val_loss did not improve from 0.38340

Epoch 00024: val_loss did not improve from 0.38340

Epoch 00025: val_loss did not improve from 0.38340

Epoch 00026: val_loss did not improve from 0.38340

Epoch 00027: val_loss did not improve from 0.38340
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9454895178735525 0.9011752136752137 0.8026115485455693 0.9015843621399178 0.9010273796681564 0.9011180749888861 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9294742626854735 0.8899521531100478 0.7814062278781577 0.8919616519174041 0.8894486169628137 0.8896996397512678 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9540664206642067 0.9040307101727447 0.8089643294686016 0.9041601579769518 0.9048044280442804 0.9040020636792454 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_3 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.92093, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 1.92093

Epoch 00003: val_loss did not improve from 1.92093

Epoch 00004: val_loss did not improve from 1.92093

Epoch 00005: val_loss did not improve from 1.92093

Epoch 00006: val_loss did not improve from 1.92093

Epoch 00007: val_loss did not improve from 1.92093

Epoch 00008: val_loss did not improve from 1.92093

Epoch 00009: val_loss did not improve from 1.92093
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8674843946349929 0.8238120662039509 0.690393219717742 0.8700443963382194 0.8220173055914759 0.8175498565406822 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8862690707350902 0.8076923076923077 0.6599684518975926 0.855944055944056 0.8059177068885807 0.8003072196620584 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8864354243542436 0.8195777351247601 0.6867725083954698 0.8612417916299128 0.8264132841328413 0.8161636636636637 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_5 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.75028, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.75028 to 2.63113, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 2.63113 to 2.59112, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 2.59112 to 2.19492, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 2.19492

Epoch 00006: val_loss improved from 2.19492 to 1.61310, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 1.61310

Epoch 00008: val_loss did not improve from 1.61310

Epoch 00009: val_loss improved from 1.61310 to 1.17152, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 1.17152 to 0.91906, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.91906 to 0.80573, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.80573 to 0.60302, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss improved from 0.60302 to 0.59220, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.59220 to 0.55385, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.55385 to 0.45115, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.45115

Epoch 00017: val_loss did not improve from 0.45115

Epoch 00018: val_loss did not improve from 0.45115

Epoch 00019: val_loss did not improve from 0.45115

Epoch 00020: val_loss improved from 0.45115 to 0.44505, saving model to 1_200_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.44505

Epoch 00022: val_loss did not improve from 0.44505

Epoch 00023: val_loss did not improve from 0.44505

Epoch 00024: val_loss did not improve from 0.44505

Epoch 00025: val_loss did not improve from 0.44505

Epoch 00026: val_loss improved from 0.44505 to 0.42663, saving model to 1_200_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.42663

Epoch 00028: val_loss improved from 0.42663 to 0.42644, saving model to 1_200_best_model.hdf5

Epoch 00029: val_loss improved from 0.42644 to 0.41794, saving model to 1_200_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.41794

Epoch 00031: val_loss improved from 0.41794 to 0.41203, saving model to 1_200_best_model.hdf5

Epoch 00032: val_loss improved from 0.41203 to 0.40020, saving model to 1_200_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.40020

Epoch 00034: val_loss did not improve from 0.40020

Epoch 00035: val_loss did not improve from 0.40020

Epoch 00036: val_loss did not improve from 0.40020

Epoch 00037: val_loss improved from 0.40020 to 0.39373, saving model to 1_200_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.39373

Epoch 00039: val_loss improved from 0.39373 to 0.38336, saving model to 1_200_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.38336

Epoch 00041: val_loss did not improve from 0.38336

Epoch 00042: val_loss did not improve from 0.38336

Epoch 00043: val_loss did not improve from 0.38336

Epoch 00044: val_loss did not improve from 0.38336

Epoch 00045: val_loss did not improve from 0.38336

Epoch 00046: val_loss improved from 0.38336 to 0.36423, saving model to 1_200_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.36423

Epoch 00048: val_loss did not improve from 0.36423

Epoch 00049: val_loss did not improve from 0.36423

Epoch 00050: val_loss did not improve from 0.36423

Epoch 00051: val_loss improved from 0.36423 to 0.36243, saving model to 1_200_best_model.hdf5

Epoch 00052: val_loss improved from 0.36243 to 0.33427, saving model to 1_200_best_model.hdf5

Epoch 00053: val_loss did not improve from 0.33427

Epoch 00054: val_loss did not improve from 0.33427

Epoch 00055: val_loss did not improve from 0.33427

Epoch 00056: val_loss did not improve from 0.33427

Epoch 00057: val_loss did not improve from 0.33427

Epoch 00058: val_loss did not improve from 0.33427

Epoch 00059: val_loss did not improve from 0.33427

Epoch 00060: val_loss did not improve from 0.33427
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.952155330683215 0.9172450613988254 0.8386385137669591 0.9219327292544152 0.916721972490769 0.9169373525985992 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9337031900138696 0.8894230769230769 0.7815790204791706 0.8925905188503173 0.8889967637540452 0.8891129499571193 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9415571955719558 0.8829174664107485 0.7765216694334616 0.8906320035858359 0.8859040590405904 0.8827446770045861 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.21480, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.21480 to 1.80907, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 1.80907

Epoch 00004: val_loss did not improve from 1.80907

Epoch 00005: val_loss improved from 1.80907 to 1.29831, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 1.29831 to 0.96489, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.96489 to 0.44290, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss improved from 0.44290 to 0.41148, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss improved from 0.41148 to 0.40301, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.40301 to 0.39688, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.39688 to 0.38566, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.38566

Epoch 00013: val_loss did not improve from 0.38566

Epoch 00014: val_loss improved from 0.38566 to 0.38339, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.38339

Epoch 00016: val_loss did not improve from 0.38339

Epoch 00017: val_loss did not improve from 0.38339

Epoch 00018: val_loss improved from 0.38339 to 0.37301, saving model to 1_200_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.37301

Epoch 00020: val_loss improved from 0.37301 to 0.35077, saving model to 1_200_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.35077

Epoch 00022: val_loss did not improve from 0.35077

Epoch 00023: val_loss did not improve from 0.35077

Epoch 00024: val_loss did not improve from 0.35077

Epoch 00025: val_loss did not improve from 0.35077

Epoch 00026: val_loss did not improve from 0.35077

Epoch 00027: val_loss did not improve from 0.35077

Epoch 00028: val_loss did not improve from 0.35077
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9274718282394958 0.8889482114255206 0.7840661129105448 0.895815460871223 0.8882867966182484 0.8883332072157597 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9276930189551549 0.8701923076923077 0.7459137684719586 0.8763653483992467 0.8695792880258899 0.8695136968795744 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9320147601476015 0.8637236084452975 0.7433492169833336 0.8759438236182422 0.8674538745387455 0.8632702621783759 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_9 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.97775, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.97775

Epoch 00003: val_loss improved from 2.97775 to 2.78129, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 2.78129

Epoch 00005: val_loss did not improve from 2.78129

Epoch 00006: val_loss did not improve from 2.78129

Epoch 00007: val_loss did not improve from 2.78129

Epoch 00008: val_loss did not improve from 2.78129

Epoch 00009: val_loss did not improve from 2.78129

Epoch 00010: val_loss did not improve from 2.78129

Epoch 00011: val_loss did not improve from 2.78129
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.845557060786232 0.8211425520555259 0.686739439406855 0.8692427790788446 0.819309600862999 0.8145167941591805 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8312528895053166 0.8221153846153846 0.6883413080183071 0.869718309859155 0.8203883495145632 0.8156337589535969 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8228782287822879 0.8061420345489443 0.6684305048307337 0.8561253561253561 0.8136531365313653 0.8014609060484983 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_11 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.22263, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 3.22263 to 3.15337, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 3.15337 to 3.11389, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 3.11389 to 3.09147, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 3.09147 to 2.89663, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 2.89663

Epoch 00007: val_loss did not improve from 2.89663

Epoch 00008: val_loss did not improve from 2.89663

Epoch 00009: val_loss did not improve from 2.89663

Epoch 00010: val_loss did not improve from 2.89663

Epoch 00011: val_loss did not improve from 2.89663

Epoch 00012: val_loss did not improve from 2.89663

Epoch 00013: val_loss did not improve from 2.89663
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8467697977745393 0.8232781633742658 0.689542297402693 0.8697521148927798 0.8214779312656937 0.8169594260449805 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8061950993989828 0.8076923076923077 0.6655218381394474 0.8620689655172413 0.8058252427184466 0.7995180722891566 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8191881918819188 0.8042226487523992 0.6655142813178699 0.8551136363636364 0.8118081180811808 0.7993733011174872 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.16447, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 3.16447

Epoch 00003: val_loss improved from 3.16447 to 3.05393, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 3.05393

Epoch 00005: val_loss did not improve from 3.05393

Epoch 00006: val_loss did not improve from 3.05393

Epoch 00007: val_loss did not improve from 3.05393

Epoch 00008: val_loss did not improve from 3.05393

Epoch 00009: val_loss did not improve from 3.05393

Epoch 00010: val_loss did not improve from 3.05393

Epoch 00011: val_loss did not improve from 3.05393
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8340580106780151 0.8232781633742658 0.6901339341658019 0.870399373531715 0.8214670981661273 0.8168839527307924 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8328247803975959 0.7932692307692307 0.642866514157432 0.8547297297297297 0.7912621359223301 0.7831179223550522 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8210332103321034 0.8023032629558541 0.662601854515699 0.8541076487252124 0.8099630996309963 0.7972816252828492 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_15 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.63269, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.63269 to 2.58925, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 2.58925 to 1.88702, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 1.88702

Epoch 00005: val_loss did not improve from 1.88702

Epoch 00006: val_loss improved from 1.88702 to 1.73533, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 1.73533 to 1.69169, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss improved from 1.69169 to 1.19284, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss improved from 1.19284 to 1.07323, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 1.07323 to 0.97680, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.97680 to 0.89895, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.89895 to 0.70997, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss improved from 0.70997 to 0.60357, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.60357 to 0.59931, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.59931 to 0.59251, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss improved from 0.59251 to 0.50684, saving model to 1_200_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.50684

Epoch 00018: val_loss did not improve from 0.50684

Epoch 00019: val_loss did not improve from 0.50684

Epoch 00020: val_loss did not improve from 0.50684

Epoch 00021: val_loss did not improve from 0.50684

Epoch 00022: val_loss did not improve from 0.50684

Epoch 00023: val_loss improved from 0.50684 to 0.44613, saving model to 1_200_best_model.hdf5

Epoch 00024: val_loss improved from 0.44613 to 0.43870, saving model to 1_200_best_model.hdf5

Epoch 00025: val_loss improved from 0.43870 to 0.40689, saving model to 1_200_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.40689

Epoch 00027: val_loss improved from 0.40689 to 0.39005, saving model to 1_200_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.39005

Epoch 00029: val_loss improved from 0.39005 to 0.37474, saving model to 1_200_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.37474

Epoch 00031: val_loss did not improve from 0.37474

Epoch 00032: val_loss did not improve from 0.37474

Epoch 00033: val_loss did not improve from 0.37474

Epoch 00034: val_loss did not improve from 0.37474

Epoch 00035: val_loss did not improve from 0.37474

Epoch 00036: val_loss did not improve from 0.37474

Epoch 00037: val_loss did not improve from 0.37474
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9465551883704966 0.8942872397223706 0.7918621166999523 0.8980739482159612 0.8937997039713003 0.8939411098527746 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9222376329172446 0.8894230769230769 0.7804549457118372 0.8913690476190477 0.8890892279241793 0.8892156635713128 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9331365313653136 0.8752399232245681 0.7666843209428627 0.8877453941407429 0.8789889298892989 0.8748248879097807 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_17 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.36107, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.36107 to 2.09476, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 2.09476 to 1.62880, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 1.62880 to 0.75898, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.75898 to 0.71849, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.71849

Epoch 00007: val_loss did not improve from 0.71849

Epoch 00008: val_loss did not improve from 0.71849

Epoch 00009: val_loss improved from 0.71849 to 0.49094, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.49094 to 0.46770, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.46770

Epoch 00012: val_loss did not improve from 0.46770

Epoch 00013: val_loss improved from 0.46770 to 0.45226, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.45226

Epoch 00015: val_loss improved from 0.45226 to 0.43030, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.43030

Epoch 00017: val_loss did not improve from 0.43030

Epoch 00018: val_loss did not improve from 0.43030

Epoch 00019: val_loss did not improve from 0.43030

Epoch 00020: val_loss did not improve from 0.43030

Epoch 00021: val_loss improved from 0.43030 to 0.40892, saving model to 1_200_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.40892

Epoch 00023: val_loss improved from 0.40892 to 0.40152, saving model to 1_200_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.40152

Epoch 00025: val_loss improved from 0.40152 to 0.39462, saving model to 1_200_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.39462

Epoch 00027: val_loss improved from 0.39462 to 0.36528, saving model to 1_200_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.36528

Epoch 00029: val_loss improved from 0.36528 to 0.36403, saving model to 1_200_best_model.hdf5

Epoch 00030: val_loss improved from 0.36403 to 0.36213, saving model to 1_200_best_model.hdf5

Epoch 00031: val_loss improved from 0.36213 to 0.34783, saving model to 1_200_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.34783

Epoch 00033: val_loss did not improve from 0.34783

Epoch 00034: val_loss did not improve from 0.34783

Epoch 00035: val_loss did not improve from 0.34783

Epoch 00036: val_loss improved from 0.34783 to 0.34182, saving model to 1_200_best_model.hdf5

Epoch 00037: val_loss improved from 0.34182 to 0.33328, saving model to 1_200_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.33328

Epoch 00039: val_loss did not improve from 0.33328

Epoch 00040: val_loss did not improve from 0.33328

Epoch 00041: val_loss did not improve from 0.33328

Epoch 00042: val_loss did not improve from 0.33328

Epoch 00043: val_loss improved from 0.33328 to 0.33268, saving model to 1_200_best_model.hdf5

Epoch 00044: val_loss improved from 0.33268 to 0.31163, saving model to 1_200_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.31163

Epoch 00046: val_loss improved from 0.31163 to 0.30715, saving model to 1_200_best_model.hdf5

Epoch 00047: val_loss improved from 0.30715 to 0.30181, saving model to 1_200_best_model.hdf5

Epoch 00048: val_loss improved from 0.30181 to 0.29992, saving model to 1_200_best_model.hdf5

Epoch 00049: val_loss did not improve from 0.29992

Epoch 00050: val_loss improved from 0.29992 to 0.29201, saving model to 1_200_best_model.hdf5

Epoch 00051: val_loss improved from 0.29201 to 0.28575, saving model to 1_200_best_model.hdf5

Epoch 00052: val_loss did not improve from 0.28575

Epoch 00053: val_loss did not improve from 0.28575

Epoch 00054: val_loss improved from 0.28575 to 0.27582, saving model to 1_200_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.27582

Epoch 00056: val_loss did not improve from 0.27582

Epoch 00057: val_loss did not improve from 0.27582

Epoch 00058: val_loss did not improve from 0.27582

Epoch 00059: val_loss did not improve from 0.27582

Epoch 00060: val_loss did not improve from 0.27582

Epoch 00061: val_loss did not improve from 0.27582

Epoch 00062: val_loss did not improve from 0.27582
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.955088249850047 0.9081687132941805 0.8267304469268169 0.9194725878120038 0.9073467800607109 0.9074149434642462 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9574202496532593 0.9086538461538461 0.8256961858266963 0.9178030303030302 0.9079519186315302 0.9080395578824898 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9459483394833949 0.8771593090211133 0.7687461677217479 0.8881030487254342 0.880678966789668 0.8768285114808357 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 81,801
Trainable params: 81,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.35292, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.35292

Epoch 00003: val_loss did not improve from 2.35292

Epoch 00004: val_loss did not improve from 2.35292

Epoch 00005: val_loss did not improve from 2.35292

Epoch 00006: val_loss did not improve from 2.35292

Epoch 00007: val_loss did not improve from 2.35292

Epoch 00008: val_loss did not improve from 2.35292

Epoch 00009: val_loss did not improve from 2.35292
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8602684099974685 0.8216764548852109 0.6875876427415758 0.86953125 0.819848975188781 0.8151091171324538 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8588996763754044 0.8028846153846154 0.6579538825864518 0.8595890410958904 0.8009708737864077 0.7940842689846674 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8173431734317343 0.800383877159309 0.6596931331432826 0.8531073446327684 0.8081180811808117 0.7951858235809973 None
average testing metrics
[0.88736015 0.84357006 0.7207278  0.87262802 0.8487786  0.84111357]
std testing metrics
[0.05746039 0.03851467 0.05465207 0.01797282 0.03613447 0.04069241]
End of this run.
########################################################################################################
(2081, 408)
(2081, 407)
class labels
{0.0, 1.0}
(521, 408)
(521, 407)
(521,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_2 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.38452, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 1.38452 to 1.12354, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 1.12354 to 0.90774, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.90774 to 0.72330, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.72330

Epoch 00006: val_loss improved from 0.72330 to 0.67746, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.67746 to 0.67523, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss improved from 0.67523 to 0.66696, saving model to 2_200_best_model.hdf5

Epoch 00009: val_loss improved from 0.66696 to 0.57959, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.57959 to 0.46059, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.46059 to 0.45819, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.45819

Epoch 00013: val_loss improved from 0.45819 to 0.43274, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.43274 to 0.42676, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.42676

Epoch 00016: val_loss improved from 0.42676 to 0.38385, saving model to 2_200_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.38385

Epoch 00018: val_loss did not improve from 0.38385

Epoch 00019: val_loss did not improve from 0.38385

Epoch 00020: val_loss improved from 0.38385 to 0.37784, saving model to 2_200_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.37784

Epoch 00022: val_loss did not improve from 0.37784

Epoch 00023: val_loss improved from 0.37784 to 0.36864, saving model to 2_200_best_model.hdf5

Epoch 00024: val_loss improved from 0.36864 to 0.35852, saving model to 2_200_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.35852

Epoch 00026: val_loss did not improve from 0.35852

Epoch 00027: val_loss did not improve from 0.35852

Epoch 00028: val_loss did not improve from 0.35852

Epoch 00029: val_loss did not improve from 0.35852

Epoch 00030: val_loss did not improve from 0.35852

Epoch 00031: val_loss did not improve from 0.35852

Epoch 00032: val_loss improved from 0.35852 to 0.35142, saving model to 2_200_best_model.hdf5

Epoch 00033: val_loss improved from 0.35142 to 0.32299, saving model to 2_200_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.32299

Epoch 00035: val_loss did not improve from 0.32299

Epoch 00036: val_loss did not improve from 0.32299

Epoch 00037: val_loss did not improve from 0.32299

Epoch 00038: val_loss did not improve from 0.32299

Epoch 00039: val_loss did not improve from 0.32299

Epoch 00040: val_loss did not improve from 0.32299

Epoch 00041: val_loss did not improve from 0.32299
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9504700261981816 0.9145299145299145 0.840566586992449 0.9269500312768371 0.9137206554682282 0.9137850636767769 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9090492764242535 0.8708133971291866 0.7510243549933877 0.8814993382491965 0.8696189778347683 0.8696194635059264 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9162435424354244 0.8790786948176583 0.778477627499322 0.8952707844987671 0.8832988929889298 0.8784985840937275 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_4 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_5 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.86946, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.86946

Epoch 00003: val_loss did not improve from 2.86946

Epoch 00004: val_loss did not improve from 2.86946

Epoch 00005: val_loss did not improve from 2.86946

Epoch 00006: val_loss did not improve from 2.86946

Epoch 00007: val_loss did not improve from 2.86946

Epoch 00008: val_loss did not improve from 2.86946

Epoch 00009: val_loss improved from 2.86946 to 2.02167, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 2.02167

Epoch 00011: val_loss did not improve from 2.02167

Epoch 00012: val_loss did not improve from 2.02167

Epoch 00013: val_loss did not improve from 2.02167

Epoch 00014: val_loss did not improve from 2.02167

Epoch 00015: val_loss did not improve from 2.02167

Epoch 00016: val_loss did not improve from 2.02167

Epoch 00017: val_loss did not improve from 2.02167
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8480885851059707 0.8328884143085958 0.6762755412946907 0.8444348474271448 0.8319558191989893 0.831187649105833 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8451225150254277 0.8221153846153846 0.650525825460924 0.8291666666666666 0.8214054553860379 0.8209191390343222 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8493505535055351 0.8119001919385797 0.6749373558586699 0.8569694467382329 0.8190332103321033 0.8079197640473108 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 200)               81600     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_8 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.95317, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 2.95317

Epoch 00003: val_loss did not improve from 2.95317

Epoch 00004: val_loss improved from 2.95317 to 2.88495, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 2.88495

Epoch 00006: val_loss did not improve from 2.88495

Epoch 00007: val_loss did not improve from 2.88495

Epoch 00008: val_loss did not improve from 2.88495

Epoch 00009: val_loss did not improve from 2.88495

Epoch 00010: val_loss improved from 2.88495 to 2.73389, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 2.73389

Epoch 00012: val_loss did not improve from 2.73389

Epoch 00013: val_loss did not improve from 2.73389

Epoch 00014: val_loss did not improve from 2.73389

Epoch 00015: val_loss did not improve from 2.73389

Epoch 00016: val_loss did not improve from 2.73389

Epoch 00017: val_loss did not improve from 2.73389

Epoch 00018: val_loss did not improve from 2.73389
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8365644478198102 0.8264815803523758 0.6918183376519423 0.8684261590166437 0.8247683427182186 0.8208528490349201 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8281091077207581 0.8221153846153846 0.6883413080183071 0.869718309859155 0.8203883495145632 0.8156337589535969 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8118081180811808 0.8023032629558541 0.662601854515699 0.8541076487252124 0.8099630996309963 0.7972816252828492 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_10 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_11 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 1.54315, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 1.54315 to 1.01965, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 1.01965

Epoch 00004: val_loss improved from 1.01965 to 0.48177, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.48177 to 0.45760, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.45760 to 0.41050, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.41050 to 0.39752, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.39752

Epoch 00009: val_loss improved from 0.39752 to 0.38639, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.38639 to 0.36156, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.36156 to 0.34800, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.34800 to 0.33525, saving model to 2_200_best_model.hdf5

Epoch 00013: val_loss improved from 0.33525 to 0.32649, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.32649 to 0.31823, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.31823 to 0.30687, saving model to 2_200_best_model.hdf5

Epoch 00016: val_loss improved from 0.30687 to 0.30346, saving model to 2_200_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.30346

Epoch 00018: val_loss improved from 0.30346 to 0.29057, saving model to 2_200_best_model.hdf5

Epoch 00019: val_loss improved from 0.29057 to 0.28894, saving model to 2_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.28894

Epoch 00021: val_loss did not improve from 0.28894

Epoch 00022: val_loss did not improve from 0.28894

Epoch 00023: val_loss did not improve from 0.28894

Epoch 00024: val_loss did not improve from 0.28894

Epoch 00025: val_loss improved from 0.28894 to 0.28116, saving model to 2_200_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.28116

Epoch 00027: val_loss did not improve from 0.28116

Epoch 00028: val_loss did not improve from 0.28116

Epoch 00029: val_loss did not improve from 0.28116

Epoch 00030: val_loss did not improve from 0.28116

Epoch 00031: val_loss did not improve from 0.28116

Epoch 00032: val_loss did not improve from 0.28116

Epoch 00033: val_loss improved from 0.28116 to 0.28107, saving model to 2_200_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.28107

Epoch 00035: val_loss did not improve from 0.28107

Epoch 00036: val_loss improved from 0.28107 to 0.28015, saving model to 2_200_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.28015

Epoch 00038: val_loss did not improve from 0.28015

Epoch 00039: val_loss did not improve from 0.28015

Epoch 00040: val_loss did not improve from 0.28015

Epoch 00041: val_loss did not improve from 0.28015

Epoch 00042: val_loss did not improve from 0.28015

Epoch 00043: val_loss did not improve from 0.28015

Epoch 00044: val_loss did not improve from 0.28015
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9162316321946036 0.8937533368926855 0.7993560082698056 0.9066148456937291 0.8928595049615595 0.8927405859847684 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.9260286638927415 0.8798076923076923 0.7696008011601442 0.8906786122760199 0.8790106333795654 0.8787963545672797 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.9139483394833948 0.8349328214971209 0.6706538614414637 0.8350599781897492 0.8355940959409593 0.8348835495283018 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_14 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.02522, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 3.02522 to 2.94483, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 2.94483

Epoch 00004: val_loss did not improve from 2.94483

Epoch 00005: val_loss improved from 2.94483 to 2.81857, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 2.81857

Epoch 00007: val_loss did not improve from 2.81857

Epoch 00008: val_loss did not improve from 2.81857

Epoch 00009: val_loss did not improve from 2.81857

Epoch 00010: val_loss did not improve from 2.81857

Epoch 00011: val_loss did not improve from 2.81857

Epoch 00012: val_loss did not improve from 2.81857

Epoch 00013: val_loss did not improve from 2.81857
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8275490283279853 0.8248798718633209 0.6926827912517195 0.8712715855572999 0.8230852211434736 0.8186556149858901 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8282940360610263 0.8173076923076923 0.6807140220947664 0.8671328671328671 0.8155339805825244 0.8102918586789555 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8118081180811809 0.8023032629558541 0.662601854515699 0.8541076487252124 0.8099630996309963 0.7972816252828492 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_16 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_17 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.18767, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 3.18767 to 3.07262, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 3.07262 to 3.06679, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 3.06679 to 3.06623, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 3.06623

Epoch 00006: val_loss improved from 3.06623 to 3.06605, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 3.06605 to 3.06595, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss improved from 3.06595 to 3.06590, saving model to 2_200_best_model.hdf5

Epoch 00009: val_loss improved from 3.06590 to 3.06587, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss improved from 3.06587 to 3.06587, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss improved from 3.06587 to 3.06586, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 3.06586

Epoch 00013: val_loss did not improve from 3.06586

Epoch 00014: val_loss improved from 3.06586 to 3.06586, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss improved from 3.06586 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00016: val_loss improved from 3.06585 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00017: val_loss improved from 3.06585 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00018: val_loss improved from 3.06585 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00019: val_loss improved from 3.06585 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00020: val_loss improved from 3.06585 to 3.06585, saving model to 2_200_best_model.hdf5

Epoch 00021: val_loss did not improve from 3.06585

Epoch 00022: val_loss did not improve from 3.06585

Epoch 00023: val_loss did not improve from 3.06585

Epoch 00024: val_loss did not improve from 3.06585

Epoch 00025: val_loss improved from 3.06585 to 3.06584, saving model to 2_200_best_model.hdf5

Epoch 00026: val_loss improved from 3.06584 to 3.06584, saving model to 2_200_best_model.hdf5

Epoch 00027: val_loss improved from 3.06584 to 3.06584, saving model to 2_200_best_model.hdf5

Epoch 00028: val_loss improved from 3.06584 to 3.06584, saving model to 2_200_best_model.hdf5

Epoch 00029: val_loss improved from 3.06584 to 3.06584, saving model to 2_200_best_model.hdf5

Epoch 00030: val_loss did not improve from 3.06584

Epoch 00031: val_loss did not improve from 3.06584

Epoch 00032: val_loss did not improve from 3.06584

Epoch 00033: val_loss did not improve from 3.06584

Epoch 00034: val_loss did not improve from 3.06584

Epoch 00035: val_loss did not improve from 3.06584

Epoch 00036: val_loss did not improve from 3.06584

Epoch 00037: val_loss did not improve from 3.06584
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8212760935158767 0.8222103577148959 0.6878413052608178 0.8691689046790664 0.8203991826141295 0.8157775113575645 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8058252427184466 0.8076923076923077 0.6655218381394474 0.8620689655172413 0.8058252427184466 0.7995180722891566 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8099630996309963 0.8023032629558541 0.662601854515699 0.8541076487252124 0.8099630996309963 0.7972816252828492 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_20 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.35705, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 3.35705 to 3.29673, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 3.29673 to 3.29595, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 3.29595 to 3.29592, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 3.29592 to 3.29584, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 3.29584 to 3.29580, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 3.29580

Epoch 00008: val_loss improved from 3.29580 to 3.29579, saving model to 2_200_best_model.hdf5

Epoch 00009: val_loss improved from 3.29579 to 3.29579, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss improved from 3.29579 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 3.29578

Epoch 00012: val_loss did not improve from 3.29578

Epoch 00013: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00016: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00017: val_loss did not improve from 3.29578

Epoch 00018: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00019: val_loss did not improve from 3.29578

Epoch 00020: val_loss did not improve from 3.29578

Epoch 00021: val_loss did not improve from 3.29578

Epoch 00022: val_loss did not improve from 3.29578

Epoch 00023: val_loss did not improve from 3.29578

Epoch 00024: val_loss did not improve from 3.29578

Epoch 00025: val_loss did not improve from 3.29578

Epoch 00026: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00027: val_loss did not improve from 3.29578

Epoch 00028: val_loss did not improve from 3.29578

Epoch 00029: val_loss did not improve from 3.29578

Epoch 00030: val_loss improved from 3.29578 to 3.29578, saving model to 2_200_best_model.hdf5

Epoch 00031: val_loss improved from 3.29578 to 2.58439, saving model to 2_200_best_model.hdf5

Epoch 00032: val_loss did not improve from 2.58439

Epoch 00033: val_loss did not improve from 2.58439

Epoch 00034: val_loss did not improve from 2.58439

Epoch 00035: val_loss did not improve from 2.58439

Epoch 00036: val_loss did not improve from 2.58439

Epoch 00037: val_loss did not improve from 2.58439

Epoch 00038: val_loss did not improve from 2.58439

Epoch 00039: val_loss did not improve from 2.58439
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8324279142748322 0.8275493860117459 0.6803755998769125 0.8548411310033375 0.8261395850580768 0.8237216535308031 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8406842348589921 0.8269230769230769 0.6820131809168694 0.8572298325722982 0.8255201109570042 0.8227272727272728 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8154981549815499 0.8042226487523992 0.6655142813178699 0.8551136363636364 0.8118081180811808 0.7993733011174872 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_22 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_23 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.70931, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.70931 to 2.69094, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 2.69094

Epoch 00004: val_loss did not improve from 2.69094

Epoch 00005: val_loss improved from 2.69094 to 2.54510, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 2.54510

Epoch 00007: val_loss did not improve from 2.54510

Epoch 00008: val_loss did not improve from 2.54510

Epoch 00009: val_loss did not improve from 2.54510

Epoch 00010: val_loss did not improve from 2.54510

Epoch 00011: val_loss improved from 2.54510 to 2.16760, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 2.16760

Epoch 00013: val_loss did not improve from 2.16760

Epoch 00014: val_loss did not improve from 2.16760

Epoch 00015: val_loss did not improve from 2.16760

Epoch 00016: val_loss did not improve from 2.16760

Epoch 00017: val_loss did not improve from 2.16760

Epoch 00018: val_loss did not improve from 2.16760

Epoch 00019: val_loss did not improve from 2.16760
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8344708087878104 0.8227442605445809 0.6759428337426889 0.8556201550387597 0.8211985513295064 0.8180450899012386 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8588996763754045 0.8509615384615384 0.7346370565097153 0.8860294117647058 0.8495145631067962 0.847113218731476 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8118081180811808 0.800383877159309 0.6596931331432826 0.8531073446327684 0.8081180811808117 0.7951858235809973 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_25 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_26 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 2.53263, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 2.53263 to 2.37058, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 2.37058

Epoch 00004: val_loss did not improve from 2.37058

Epoch 00005: val_loss did not improve from 2.37058

Epoch 00006: val_loss improved from 2.37058 to 2.36093, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 2.36093 to 2.31768, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 2.31768

Epoch 00009: val_loss did not improve from 2.31768

Epoch 00010: val_loss did not improve from 2.31768

Epoch 00011: val_loss did not improve from 2.31768

Epoch 00012: val_loss did not improve from 2.31768

Epoch 00013: val_loss improved from 2.31768 to 2.30890, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 2.30890 to 2.30456, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss improved from 2.30456 to 2.30126, saving model to 2_200_best_model.hdf5

Epoch 00016: val_loss improved from 2.30126 to 2.29947, saving model to 2_200_best_model.hdf5

Epoch 00017: val_loss improved from 2.29947 to 2.29411, saving model to 2_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 2.29411

Epoch 00019: val_loss did not improve from 2.29411

Epoch 00020: val_loss did not improve from 2.29411

Epoch 00021: val_loss did not improve from 2.29411

Epoch 00022: val_loss did not improve from 2.29411

Epoch 00023: val_loss did not improve from 2.29411

Epoch 00024: val_loss did not improve from 2.29411

Epoch 00025: val_loss did not improve from 2.29411
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8131769261821192 0.8142018152696209 0.6757372263000003 0.8655332302936631 0.8122977346278317 0.8067835799658509 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8592233009708738 0.8557692307692307 0.7424557636312744 0.8888888888888888 0.854368932038835 0.8522727272727273 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8081180811808117 0.800383877159309 0.6596931331432826 0.8531073446327684 0.8081180811808117 0.7951858235809973 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 200)               81600     
_________________________________________________________________
activation_28 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_29 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 122,001
Trainable params: 122,001
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 3.19500, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 3.19500

Epoch 00003: val_loss did not improve from 3.19500

Epoch 00004: val_loss improved from 3.19500 to 3.16904, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 3.16904 to 3.14692, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 3.14692

Epoch 00007: val_loss improved from 3.14692 to 3.14558, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 3.14558

Epoch 00009: val_loss did not improve from 3.14558

Epoch 00010: val_loss did not improve from 3.14558

Epoch 00011: val_loss did not improve from 3.14558

Epoch 00012: val_loss did not improve from 3.14558

Epoch 00013: val_loss improved from 3.14558 to 3.06601, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 3.06601

Epoch 00015: val_loss did not improve from 3.06601

Epoch 00016: val_loss did not improve from 3.06601

Epoch 00017: val_loss did not improve from 3.06601

Epoch 00018: val_loss did not improve from 3.06601

Epoch 00019: val_loss did not improve from 3.06601

Epoch 00020: val_loss did not improve from 3.06601

Epoch 00021: val_loss did not improve from 3.06601
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8220064724919094 0.8227442605445809 0.6892848880473164 0.8701095461658842 0.8209277238403452 0.8162926951474301 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.8058252427184466 0.8076923076923077 0.6655218381394474 0.8620689655172413 0.8058252427184466 0.7995180722891566 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.8099630996309963 0.800383877159309 0.6596931331432826 0.8531073446327684 0.8081180811808117 0.7951858235809973 None
average testing metrics
[0.83585092 0.81381958 0.67564681 0.85640588 0.82039779 0.80980775]
standard devidation testing metrics
[0.04123384 0.02395775 0.03460686 0.01420071 0.02245472 0.02563549]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.70361, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.70361 to 0.65166, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.65166 to 0.64520, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.64520

Epoch 00005: val_loss improved from 0.64520 to 0.63143, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.63143 to 0.62124, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.62124 to 0.61072, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.61072 to 0.60955, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.60955 to 0.60595, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.60595 to 0.59653, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.59653 to 0.59119, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59119 to 0.58308, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.58308 to 0.58161, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58161

Epoch 00015: val_loss did not improve from 0.58161

Epoch 00016: val_loss did not improve from 0.58161

Epoch 00017: val_loss did not improve from 0.58161

Epoch 00018: val_loss did not improve from 0.58161

Epoch 00019: val_loss improved from 0.58161 to 0.57664, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57664

Epoch 00021: val_loss did not improve from 0.57664

Epoch 00022: val_loss improved from 0.57664 to 0.57350, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.57350

Epoch 00024: val_loss improved from 0.57350 to 0.56774, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.56774

Epoch 00026: val_loss did not improve from 0.56774

Epoch 00027: val_loss did not improve from 0.56774

Epoch 00028: val_loss did not improve from 0.56774

Epoch 00029: val_loss did not improve from 0.56774

Epoch 00030: val_loss did not improve from 0.56774

Epoch 00031: val_loss did not improve from 0.56774

Epoch 00032: val_loss did not improve from 0.56774
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8189990330591809 0.7559369387347835 0.5370841570944169 0.7818013258044202 0.755906702158333 0.7501906550900334 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7620919566809266 0.6863799283154122 0.3913648185614777 0.7054491899852725 0.6863799283154122 0.6789296999069505 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7390983937729845 0.6834170854271356 0.3727713890218141 0.6893370856785491 0.6834803097016772 0.6809700010126898 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66045, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66045 to 0.62132, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62132 to 0.60189, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60189

Epoch 00005: val_loss improved from 0.60189 to 0.59854, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59854 to 0.59399, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59399

Epoch 00008: val_loss did not improve from 0.59399

Epoch 00009: val_loss improved from 0.59399 to 0.59182, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59182

Epoch 00011: val_loss did not improve from 0.59182

Epoch 00012: val_loss did not improve from 0.59182

Epoch 00013: val_loss did not improve from 0.59182

Epoch 00014: val_loss improved from 0.59182 to 0.58554, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58554

Epoch 00016: val_loss improved from 0.58554 to 0.57990, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.57990

Epoch 00018: val_loss did not improve from 0.57990

Epoch 00019: val_loss did not improve from 0.57990

Epoch 00020: val_loss did not improve from 0.57990

Epoch 00021: val_loss did not improve from 0.57990

Epoch 00022: val_loss improved from 0.57990 to 0.57802, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.57802

Epoch 00024: val_loss did not improve from 0.57802

Epoch 00025: val_loss improved from 0.57802 to 0.57528, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.57528

Epoch 00027: val_loss did not improve from 0.57528

Epoch 00028: val_loss did not improve from 0.57528

Epoch 00029: val_loss did not improve from 0.57528

Epoch 00030: val_loss did not improve from 0.57528

Epoch 00031: val_loss improved from 0.57528 to 0.57474, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.57474

Epoch 00033: val_loss did not improve from 0.57474

Epoch 00034: val_loss improved from 0.57474 to 0.57120, saving model to 1_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.57120

Epoch 00036: val_loss did not improve from 0.57120

Epoch 00037: val_loss improved from 0.57120 to 0.55992, saving model to 1_50_best_model.hdf5

Epoch 00038: val_loss did not improve from 0.55992

Epoch 00039: val_loss did not improve from 0.55992

Epoch 00040: val_loss did not improve from 0.55992

Epoch 00041: val_loss did not improve from 0.55992

Epoch 00042: val_loss did not improve from 0.55992

Epoch 00043: val_loss did not improve from 0.55992

Epoch 00044: val_loss did not improve from 0.55992

Epoch 00045: val_loss did not improve from 0.55992
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8330522514428446 0.7639193773697864 0.5554896724239152 0.7923290054260015 0.7638882649704581 0.7580264290236702 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7503115324828817 0.6863799283154122 0.39232156618424696 0.7064549180327869 0.6863799283154122 0.6785661383498742 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7467574498260197 0.6812634601579325 0.3715800067935135 0.6903474987017484 0.6813416283250053 0.6774736552276539 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65716, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65716 to 0.63666, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63666 to 0.63387, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.63387 to 0.62579, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62579 to 0.61027, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61027

Epoch 00007: val_loss improved from 0.61027 to 0.60854, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.60854 to 0.60446, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.60446 to 0.59964, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59964

Epoch 00011: val_loss did not improve from 0.59964

Epoch 00012: val_loss did not improve from 0.59964

Epoch 00013: val_loss did not improve from 0.59964

Epoch 00014: val_loss did not improve from 0.59964

Epoch 00015: val_loss did not improve from 0.59964

Epoch 00016: val_loss did not improve from 0.59964

Epoch 00017: val_loss did not improve from 0.59964
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7633926082392278 0.6743165036918779 0.3966944780082652 0.7257524786841214 0.6742688605231676 0.6546080906481276 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7358076078159325 0.6487455197132617 0.3456024088727367 0.7007472649409643 0.6487455197132617 0.624423076923077 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7278813964610235 0.6511127063890882 0.33119504769315133 0.6812953995157385 0.6512588845462491 0.6360930142553054 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63722, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.63722 to 0.61549, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61549

Epoch 00004: val_loss improved from 0.61549 to 0.60167, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60167

Epoch 00006: val_loss did not improve from 0.60167

Epoch 00007: val_loss did not improve from 0.60167

Epoch 00008: val_loss did not improve from 0.60167

Epoch 00009: val_loss improved from 0.60167 to 0.59065, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59065

Epoch 00011: val_loss did not improve from 0.59065

Epoch 00012: val_loss did not improve from 0.59065

Epoch 00013: val_loss improved from 0.59065 to 0.58350, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58350

Epoch 00015: val_loss did not improve from 0.58350

Epoch 00016: val_loss improved from 0.58350 to 0.58099, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.58099

Epoch 00018: val_loss improved from 0.58099 to 0.58082, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.58082

Epoch 00020: val_loss improved from 0.58082 to 0.58056, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.58056 to 0.57916, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.57916

Epoch 00023: val_loss improved from 0.57916 to 0.57443, saving model to 1_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.57443

Epoch 00025: val_loss did not improve from 0.57443

Epoch 00026: val_loss did not improve from 0.57443

Epoch 00027: val_loss did not improve from 0.57443

Epoch 00028: val_loss did not improve from 0.57443

Epoch 00029: val_loss did not improve from 0.57443

Epoch 00030: val_loss did not improve from 0.57443

Epoch 00031: val_loss did not improve from 0.57443
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8006714424303827 0.7188185990820195 0.4700685304167283 0.7524936619731257 0.7187821483927596 0.709098096849067 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7437854087177709 0.6648745519713262 0.353741512071325 0.6897397989355412 0.6648745519713262 0.6535231751576389 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7302932106400171 0.6798277099784638 0.36964282721249087 0.6898669050975479 0.6799100001649103 0.6756013049507928 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_9 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66371, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66371 to 0.64603, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64603 to 0.62808, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62808 to 0.61986, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61986 to 0.61492, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.61492 to 0.61389, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61389

Epoch 00008: val_loss improved from 0.61389 to 0.60905, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.60905

Epoch 00010: val_loss improved from 0.60905 to 0.60809, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.60809 to 0.60375, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.60375

Epoch 00013: val_loss did not improve from 0.60375

Epoch 00014: val_loss did not improve from 0.60375

Epoch 00015: val_loss did not improve from 0.60375

Epoch 00016: val_loss did not improve from 0.60375

Epoch 00017: val_loss improved from 0.60375 to 0.60318, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.60318 to 0.60161, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.60161

Epoch 00020: val_loss did not improve from 0.60161

Epoch 00021: val_loss did not improve from 0.60161

Epoch 00022: val_loss improved from 0.60161 to 0.59990, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59990

Epoch 00024: val_loss did not improve from 0.59990

Epoch 00025: val_loss did not improve from 0.59990

Epoch 00026: val_loss did not improve from 0.59990

Epoch 00027: val_loss did not improve from 0.59990

Epoch 00028: val_loss did not improve from 0.59990

Epoch 00029: val_loss did not improve from 0.59990

Epoch 00030: val_loss did not improve from 0.59990
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7764242911983308 0.6871508379888268 0.4014563537745193 0.7152905187573271 0.6871508379888268 0.6765827240841591 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7273922797246075 0.6588868940754039 0.35161391217690274 0.6950049173566828 0.6584990072458163 0.6419920976428242 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7252819967347748 0.6676238334529792 0.34033174899269003 0.6726834653023966 0.6676849882089084 0.6652215777111639 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64689, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64689 to 0.62580, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.62580

Epoch 00004: val_loss improved from 0.62580 to 0.61664, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61664

Epoch 00006: val_loss improved from 0.61664 to 0.61325, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61325

Epoch 00008: val_loss did not improve from 0.61325

Epoch 00009: val_loss improved from 0.61325 to 0.60288, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60288

Epoch 00011: val_loss did not improve from 0.60288

Epoch 00012: val_loss did not improve from 0.60288

Epoch 00013: val_loss did not improve from 0.60288

Epoch 00014: val_loss did not improve from 0.60288

Epoch 00015: val_loss improved from 0.60288 to 0.60284, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.60284 to 0.60118, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.60118 to 0.60096, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60096

Epoch 00019: val_loss did not improve from 0.60096

Epoch 00020: val_loss improved from 0.60096 to 0.59887, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.59887

Epoch 00022: val_loss did not improve from 0.59887

Epoch 00023: val_loss did not improve from 0.59887

Epoch 00024: val_loss did not improve from 0.59887

Epoch 00025: val_loss did not improve from 0.59887

Epoch 00026: val_loss did not improve from 0.59887

Epoch 00027: val_loss improved from 0.59887 to 0.59773, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.59773

Epoch 00029: val_loss improved from 0.59773 to 0.59157, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.59157

Epoch 00031: val_loss did not improve from 0.59157

Epoch 00032: val_loss did not improve from 0.59157

Epoch 00033: val_loss did not improve from 0.59157

Epoch 00034: val_loss did not improve from 0.59157

Epoch 00035: val_loss did not improve from 0.59157

Epoch 00036: val_loss did not improve from 0.59157

Epoch 00037: val_loss did not improve from 0.59157
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7971933971949571 0.7237183323359266 0.4786658716793541 0.7560779697399855 0.7236828659482102 0.7146847655212218 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7354044821696599 0.6618705035971223 0.35019720358013834 0.6894077034883721 0.6618705035971223 0.6491171534071837 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7402888405151801 0.6697774587221823 0.3595080764139003 0.6901854364540931 0.669894787183166 0.6607691167439596 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64256, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64256 to 0.63014, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63014 to 0.59574, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.59574

Epoch 00005: val_loss improved from 0.59574 to 0.58838, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.58838

Epoch 00007: val_loss did not improve from 0.58838

Epoch 00008: val_loss did not improve from 0.58838

Epoch 00009: val_loss did not improve from 0.58838

Epoch 00010: val_loss improved from 0.58838 to 0.58119, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58119

Epoch 00012: val_loss improved from 0.58119 to 0.57787, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.57787 to 0.57651, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.57651

Epoch 00015: val_loss did not improve from 0.57651

Epoch 00016: val_loss did not improve from 0.57651

Epoch 00017: val_loss did not improve from 0.57651

Epoch 00018: val_loss did not improve from 0.57651

Epoch 00019: val_loss improved from 0.57651 to 0.57606, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57606

Epoch 00021: val_loss did not improve from 0.57606

Epoch 00022: val_loss did not improve from 0.57606

Epoch 00023: val_loss did not improve from 0.57606

Epoch 00024: val_loss did not improve from 0.57606

Epoch 00025: val_loss improved from 0.57606 to 0.57483, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.57483

Epoch 00027: val_loss did not improve from 0.57483

Epoch 00028: val_loss did not improve from 0.57483

Epoch 00029: val_loss improved from 0.57483 to 0.57012, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.57012

Epoch 00031: val_loss did not improve from 0.57012

Epoch 00032: val_loss did not improve from 0.57012

Epoch 00033: val_loss did not improve from 0.57012

Epoch 00034: val_loss did not improve from 0.57012

Epoch 00035: val_loss improved from 0.57012 to 0.56797, saving model to 1_50_best_model.hdf5

Epoch 00036: val_loss improved from 0.56797 to 0.56176, saving model to 1_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.56176

Epoch 00038: val_loss did not improve from 0.56176

Epoch 00039: val_loss did not improve from 0.56176

Epoch 00040: val_loss did not improve from 0.56176

Epoch 00041: val_loss did not improve from 0.56176

Epoch 00042: val_loss did not improve from 0.56176

Epoch 00043: val_loss did not improve from 0.56176

Epoch 00044: val_loss did not improve from 0.56176
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8375349500250058 0.7586275683223619 0.5430716033232472 0.7851218181837327 0.7585971570106496 0.7528725264152161 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7712592515915325 0.7194244604316546 0.45823232492715804 0.739235934766661 0.7194244604316546 0.7134929443475504 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7324762116789525 0.6805455850681982 0.3644146113387541 0.6838356877261014 0.6805933475156252 0.6791460596226161 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_15 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65030, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65030 to 0.63696, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63696 to 0.61699, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61699 to 0.61646, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61646 to 0.59674, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59674 to 0.59442, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59442

Epoch 00008: val_loss improved from 0.59442 to 0.59137, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.59137 to 0.58948, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.58948 to 0.58507, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58507

Epoch 00012: val_loss did not improve from 0.58507

Epoch 00013: val_loss did not improve from 0.58507

Epoch 00014: val_loss improved from 0.58507 to 0.58397, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58397

Epoch 00016: val_loss improved from 0.58397 to 0.58189, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.58189 to 0.57924, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.57924

Epoch 00019: val_loss did not improve from 0.57924

Epoch 00020: val_loss did not improve from 0.57924

Epoch 00021: val_loss did not improve from 0.57924

Epoch 00022: val_loss did not improve from 0.57924

Epoch 00023: val_loss did not improve from 0.57924

Epoch 00024: val_loss improved from 0.57924 to 0.56891, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.56891

Epoch 00026: val_loss improved from 0.56891 to 0.56575, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.56575 to 0.56479, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.56479

Epoch 00029: val_loss improved from 0.56479 to 0.56400, saving model to 1_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.56400

Epoch 00031: val_loss improved from 0.56400 to 0.55832, saving model to 1_50_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.55832

Epoch 00033: val_loss did not improve from 0.55832

Epoch 00034: val_loss did not improve from 0.55832

Epoch 00035: val_loss did not improve from 0.55832

Epoch 00036: val_loss did not improve from 0.55832

Epoch 00037: val_loss did not improve from 0.55832

Epoch 00038: val_loss did not improve from 0.55832

Epoch 00039: val_loss did not improve from 0.55832
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8149561912996364 0.7414721723518851 0.5094223396698694 0.7687113591995663 0.741440407401972 0.7347334010349926 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7790228249055431 0.7140287769784173 0.4542282514733226 0.7409994900560939 0.7140287769784173 0.7057975885812031 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7258901037286235 0.6676238334529792 0.35551818981994726 0.6883735896403091 0.6677427068388331 0.6583087379453461 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66851, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66851 to 0.64559, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64559 to 0.61011, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61011 to 0.59195, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59195

Epoch 00006: val_loss did not improve from 0.59195

Epoch 00007: val_loss did not improve from 0.59195

Epoch 00008: val_loss did not improve from 0.59195

Epoch 00009: val_loss improved from 0.59195 to 0.58945, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.58945 to 0.58909, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58909

Epoch 00012: val_loss improved from 0.58909 to 0.58056, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.58056 to 0.57762, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.57762 to 0.57464, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57464

Epoch 00016: val_loss did not improve from 0.57464

Epoch 00017: val_loss did not improve from 0.57464

Epoch 00018: val_loss did not improve from 0.57464

Epoch 00019: val_loss did not improve from 0.57464

Epoch 00020: val_loss improved from 0.57464 to 0.56956, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.56956 to 0.56447, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.56447 to 0.55787, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.55787

Epoch 00024: val_loss did not improve from 0.55787

Epoch 00025: val_loss improved from 0.55787 to 0.55429, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.55429

Epoch 00027: val_loss did not improve from 0.55429

Epoch 00028: val_loss did not improve from 0.55429

Epoch 00029: val_loss did not improve from 0.55429

Epoch 00030: val_loss did not improve from 0.55429

Epoch 00031: val_loss did not improve from 0.55429

Epoch 00032: val_loss did not improve from 0.55429

Epoch 00033: val_loss did not improve from 0.55429
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7974143268759685 0.725314183123878 0.46955611784241014 0.7446699218574433 0.7252861182623211 0.7197557719548195 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7784664354847057 0.6942446043165468 0.4022130182708837 0.7082108183079057 0.6942446043165468 0.6890298468179187 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7371483286333878 0.6812634601579325 0.3652473245798333 0.6839503074413351 0.6813065848711226 0.6801278470799975 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,351
Trainable params: 19,351
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65184, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65184 to 0.62606, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.62606

Epoch 00004: val_loss improved from 0.62606 to 0.60489, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.60489 to 0.60416, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60416

Epoch 00007: val_loss improved from 0.60416 to 0.59361, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.59361 to 0.59293, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59293

Epoch 00010: val_loss improved from 0.59293 to 0.59214, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.59214 to 0.58376, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58376

Epoch 00013: val_loss did not improve from 0.58376

Epoch 00014: val_loss did not improve from 0.58376

Epoch 00015: val_loss did not improve from 0.58376

Epoch 00016: val_loss improved from 0.58376 to 0.58243, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.58243 to 0.57950, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.57950 to 0.57691, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.57691

Epoch 00020: val_loss did not improve from 0.57691

Epoch 00021: val_loss improved from 0.57691 to 0.56976, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.56976

Epoch 00023: val_loss did not improve from 0.56976

Epoch 00024: val_loss did not improve from 0.56976

Epoch 00025: val_loss did not improve from 0.56976

Epoch 00026: val_loss did not improve from 0.56976

Epoch 00027: val_loss did not improve from 0.56976

Epoch 00028: val_loss improved from 0.56976 to 0.56877, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.56877

Epoch 00030: val_loss did not improve from 0.56877

Epoch 00031: val_loss did not improve from 0.56877

Epoch 00032: val_loss did not improve from 0.56877

Epoch 00033: val_loss did not improve from 0.56877

Epoch 00034: val_loss did not improve from 0.56877

Epoch 00035: val_loss did not improve from 0.56877

Epoch 00036: val_loss did not improve from 0.56877
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8184491245740976 0.7432675044883303 0.5078509147009362 0.765081540546851 0.7432388832418471 0.7378599238437513 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7697065369287304 0.7032374100719424 0.42125779940043195 0.718289208533111 0.7032374100719425 0.698031974246808 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7407145154108741 0.6812634601579325 0.3651192719662683 0.6838223922084979 0.6813055541813025 0.680182099480425 None
average testing metrics
[0.73458304 0.67437186 0.35953285 0.68536978 0.67445188 0.66938934]
std testing metrics
[0.00689323 0.0097229  0.01303124 0.00526555 0.00969503 0.01374101]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_2 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.68334, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.68334 to 0.66422, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.66422 to 0.64797, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.64797 to 0.62423, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.62423

Epoch 00006: val_loss improved from 0.62423 to 0.61211, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.61211 to 0.59861, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.59861 to 0.59813, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59813

Epoch 00010: val_loss did not improve from 0.59813

Epoch 00011: val_loss did not improve from 0.59813

Epoch 00012: val_loss did not improve from 0.59813

Epoch 00013: val_loss did not improve from 0.59813

Epoch 00014: val_loss did not improve from 0.59813

Epoch 00015: val_loss did not improve from 0.59813

Epoch 00016: val_loss did not improve from 0.59813
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7539805464888261 0.6832967471562562 0.3679652572198507 0.684679796424655 0.6832880926096729 0.6826962106121723 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7430017599979446 0.6666666666666666 0.33437449163772687 0.6677094509869824 0.6666666666666667 0.6661477097272259 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7200357855505534 0.6532663316582915 0.3065926954497277 0.6533342820373211 0.6532584227972098 0.6532205816637829 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_4 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65528, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65528 to 0.62367, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62367 to 0.60277, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.60277 to 0.60115, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.60115 to 0.59881, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59881

Epoch 00007: val_loss did not improve from 0.59881

Epoch 00008: val_loss improved from 0.59881 to 0.59342, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59342

Epoch 00010: val_loss improved from 0.59342 to 0.59329, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59329

Epoch 00012: val_loss improved from 0.59329 to 0.58864, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.58864 to 0.58779, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58779

Epoch 00015: val_loss did not improve from 0.58779

Epoch 00016: val_loss did not improve from 0.58779

Epoch 00017: val_loss did not improve from 0.58779

Epoch 00018: val_loss improved from 0.58779 to 0.58666, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.58666

Epoch 00020: val_loss did not improve from 0.58666

Epoch 00021: val_loss did not improve from 0.58666

Epoch 00022: val_loss did not improve from 0.58666

Epoch 00023: val_loss did not improve from 0.58666

Epoch 00024: val_loss improved from 0.58666 to 0.58588, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.58588

Epoch 00026: val_loss improved from 0.58588 to 0.57821, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.57821

Epoch 00028: val_loss did not improve from 0.57821

Epoch 00029: val_loss did not improve from 0.57821

Epoch 00030: val_loss did not improve from 0.57821

Epoch 00031: val_loss did not improve from 0.57821

Epoch 00032: val_loss improved from 0.57821 to 0.57811, saving model to 2_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.57811

Epoch 00034: val_loss improved from 0.57811 to 0.57645, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.57645

Epoch 00036: val_loss did not improve from 0.57645

Epoch 00037: val_loss did not improve from 0.57645

Epoch 00038: val_loss improved from 0.57645 to 0.57542, saving model to 2_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.57542

Epoch 00040: val_loss improved from 0.57542 to 0.57453, saving model to 2_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.57453

Epoch 00042: val_loss did not improve from 0.57453

Epoch 00043: val_loss did not improve from 0.57453

Epoch 00044: val_loss did not improve from 0.57453

Epoch 00045: val_loss did not improve from 0.57453

Epoch 00046: val_loss did not improve from 0.57453

Epoch 00047: val_loss did not improve from 0.57453

Epoch 00048: val_loss did not improve from 0.57453
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.805470304403165 0.7409698662941528 0.4820027917887536 0.7410313465488203 0.7409714489616139 0.740954175063524 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7437211752161458 0.6792114695340502 0.358425241366327 0.6792137718396711 0.6792114695340501 0.6792104392622116 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.725186142581507 0.6712132089016511 0.3425537852534848 0.6713510848126232 0.6712027325648511 0.6711384695320843 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_8 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62892, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.62892

Epoch 00003: val_loss improved from 0.62892 to 0.62483, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62483 to 0.61163, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61163 to 0.61101, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61101

Epoch 00007: val_loss did not improve from 0.61101

Epoch 00008: val_loss did not improve from 0.61101

Epoch 00009: val_loss did not improve from 0.61101

Epoch 00010: val_loss did not improve from 0.61101

Epoch 00011: val_loss improved from 0.61101 to 0.60358, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.60358

Epoch 00013: val_loss improved from 0.60358 to 0.59995, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.59995

Epoch 00015: val_loss did not improve from 0.59995

Epoch 00016: val_loss did not improve from 0.59995

Epoch 00017: val_loss improved from 0.59995 to 0.59476, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.59476

Epoch 00019: val_loss did not improve from 0.59476

Epoch 00020: val_loss did not improve from 0.59476

Epoch 00021: val_loss did not improve from 0.59476

Epoch 00022: val_loss did not improve from 0.59476

Epoch 00023: val_loss did not improve from 0.59476

Epoch 00024: val_loss improved from 0.59476 to 0.59327, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.59327

Epoch 00026: val_loss did not improve from 0.59327

Epoch 00027: val_loss improved from 0.59327 to 0.58475, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.58475

Epoch 00029: val_loss did not improve from 0.58475

Epoch 00030: val_loss improved from 0.58475 to 0.58324, saving model to 2_50_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.58324

Epoch 00032: val_loss did not improve from 0.58324

Epoch 00033: val_loss did not improve from 0.58324

Epoch 00034: val_loss did not improve from 0.58324

Epoch 00035: val_loss improved from 0.58324 to 0.58078, saving model to 2_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.58078

Epoch 00037: val_loss did not improve from 0.58078

Epoch 00038: val_loss did not improve from 0.58078

Epoch 00039: val_loss did not improve from 0.58078

Epoch 00040: val_loss did not improve from 0.58078

Epoch 00041: val_loss did not improve from 0.58078

Epoch 00042: val_loss did not improve from 0.58078

Epoch 00043: val_loss did not improve from 0.58078
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7649296777554229 0.6994611853921373 0.39945419016774997 0.6999985624151426 0.6994559962278157 0.6992556477992233 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7460785447257872 0.6810035842293907 0.3647255289694388 0.6837321510073678 0.6810035842293907 0.6798148339178873 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7258633057933014 0.669059583632448 0.3445478801429608 0.6754784453626945 0.6691279539570243 0.6660610236476385 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_10 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67415, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.67415 to 0.62748, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62748 to 0.61985, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61985 to 0.61802, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61802

Epoch 00006: val_loss improved from 0.61802 to 0.61729, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61729

Epoch 00008: val_loss improved from 0.61729 to 0.61415, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.61415 to 0.61198, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61198

Epoch 00011: val_loss did not improve from 0.61198

Epoch 00012: val_loss improved from 0.61198 to 0.60930, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.60930 to 0.60753, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.60753 to 0.60198, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.60198

Epoch 00016: val_loss did not improve from 0.60198

Epoch 00017: val_loss improved from 0.60198 to 0.59910, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.59910

Epoch 00019: val_loss improved from 0.59910 to 0.59785, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.59785

Epoch 00021: val_loss did not improve from 0.59785

Epoch 00022: val_loss improved from 0.59785 to 0.59694, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59694

Epoch 00024: val_loss improved from 0.59694 to 0.59129, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss improved from 0.59129 to 0.58937, saving model to 2_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.58937 to 0.58242, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.58242

Epoch 00028: val_loss did not improve from 0.58242

Epoch 00029: val_loss improved from 0.58242 to 0.57874, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss improved from 0.57874 to 0.57494, saving model to 2_50_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.57494

Epoch 00032: val_loss did not improve from 0.57494

Epoch 00033: val_loss did not improve from 0.57494

Epoch 00034: val_loss did not improve from 0.57494

Epoch 00035: val_loss did not improve from 0.57494

Epoch 00036: val_loss did not improve from 0.57494

Epoch 00037: val_loss did not improve from 0.57494

Epoch 00038: val_loss did not improve from 0.57494
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7442720305597903 0.709040111754141 0.4455014090586176 0.7373997323542334 0.7090056120799104 0.700061235468687 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.724142803920813 0.6899641577060932 0.401907470347472 0.7125790684301323 0.6899641577060931 0.6814931883345486 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.6936150827025511 0.6625987078248384 0.3589235895334174 0.6978895656315012 0.6627500453503521 0.646980480966246 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_14 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64465, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64465 to 0.61856, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.61856 to 0.61048, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61048 to 0.60940, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60940

Epoch 00006: val_loss improved from 0.60940 to 0.60878, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60878

Epoch 00008: val_loss improved from 0.60878 to 0.59842, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59842

Epoch 00010: val_loss did not improve from 0.59842

Epoch 00011: val_loss did not improve from 0.59842

Epoch 00012: val_loss improved from 0.59842 to 0.59491, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59491

Epoch 00014: val_loss did not improve from 0.59491

Epoch 00015: val_loss did not improve from 0.59491

Epoch 00016: val_loss improved from 0.59491 to 0.59297, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59297

Epoch 00018: val_loss did not improve from 0.59297

Epoch 00019: val_loss did not improve from 0.59297

Epoch 00020: val_loss did not improve from 0.59297

Epoch 00021: val_loss improved from 0.59297 to 0.59252, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.59252 to 0.58964, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.58964

Epoch 00024: val_loss did not improve from 0.58964

Epoch 00025: val_loss did not improve from 0.58964

Epoch 00026: val_loss improved from 0.58964 to 0.58860, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.58860

Epoch 00028: val_loss did not improve from 0.58860

Epoch 00029: val_loss did not improve from 0.58860

Epoch 00030: val_loss did not improve from 0.58860

Epoch 00031: val_loss did not improve from 0.58860

Epoch 00032: val_loss improved from 0.58860 to 0.58801, saving model to 2_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.58801

Epoch 00034: val_loss did not improve from 0.58801

Epoch 00035: val_loss did not improve from 0.58801

Epoch 00036: val_loss improved from 0.58801 to 0.58767, saving model to 2_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.58767

Epoch 00038: val_loss did not improve from 0.58767

Epoch 00039: val_loss did not improve from 0.58767

Epoch 00040: val_loss improved from 0.58767 to 0.58702, saving model to 2_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.58702

Epoch 00042: val_loss did not improve from 0.58702

Epoch 00043: val_loss did not improve from 0.58702

Epoch 00044: val_loss did not improve from 0.58702

Epoch 00045: val_loss did not improve from 0.58702

Epoch 00046: val_loss did not improve from 0.58702

Epoch 00047: val_loss did not improve from 0.58702

Epoch 00048: val_loss did not improve from 0.58702
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.812295104677744 0.7294493216280926 0.4935144180203219 0.765370669943307 0.7294493216280926 0.7199730037750216 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7461256801010805 0.6642728904847397 0.3686230355100629 0.7073124979610479 0.6638624584203605 0.6455549316863185 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7452175992348159 0.6733668341708543 0.36930610730581354 0.6965345725427925 0.6734898332756147 0.6635453244895306 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_16 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63931, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.63931 to 0.62421, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62421 to 0.61410, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61410 to 0.61277, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61277

Epoch 00006: val_loss improved from 0.61277 to 0.60688, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.60688 to 0.60048, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60048

Epoch 00009: val_loss improved from 0.60048 to 0.59525, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59525

Epoch 00011: val_loss did not improve from 0.59525

Epoch 00012: val_loss did not improve from 0.59525

Epoch 00013: val_loss did not improve from 0.59525

Epoch 00014: val_loss did not improve from 0.59525

Epoch 00015: val_loss did not improve from 0.59525

Epoch 00016: val_loss did not improve from 0.59525

Epoch 00017: val_loss did not improve from 0.59525
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7529637684873417 0.6826251745461799 0.3656163609229241 0.6829958881342848 0.682620665329416 0.682460960076996 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7381799596294187 0.6528776978417267 0.30663150166903314 0.653755059016436 0.6528776978417266 0.6523818008066213 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7239956958393114 0.6618808327351041 0.32850987419212907 0.666601984985367 0.6619409538415871 0.659519780300188 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_20 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62850, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.62850 to 0.61463, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.61463 to 0.60458, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60458

Epoch 00005: val_loss improved from 0.60458 to 0.59960, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59960 to 0.59529, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.59529 to 0.59225, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59225

Epoch 00009: val_loss did not improve from 0.59225

Epoch 00010: val_loss did not improve from 0.59225

Epoch 00011: val_loss improved from 0.59225 to 0.59095, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59095 to 0.58347, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.58347 to 0.58173, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58173

Epoch 00015: val_loss did not improve from 0.58173

Epoch 00016: val_loss did not improve from 0.58173

Epoch 00017: val_loss did not improve from 0.58173

Epoch 00018: val_loss did not improve from 0.58173

Epoch 00019: val_loss did not improve from 0.58173

Epoch 00020: val_loss improved from 0.58173 to 0.58055, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.58055

Epoch 00022: val_loss did not improve from 0.58055

Epoch 00023: val_loss did not improve from 0.58055

Epoch 00024: val_loss improved from 0.58055 to 0.57997, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.57997

Epoch 00026: val_loss improved from 0.57997 to 0.57361, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.57361

Epoch 00028: val_loss improved from 0.57361 to 0.57194, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.57194

Epoch 00030: val_loss did not improve from 0.57194

Epoch 00031: val_loss did not improve from 0.57194

Epoch 00032: val_loss did not improve from 0.57194

Epoch 00033: val_loss did not improve from 0.57194

Epoch 00034: val_loss did not improve from 0.57194

Epoch 00035: val_loss did not improve from 0.57194

Epoch 00036: val_loss did not improve from 0.57194
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7863161121724296 0.6868142828645522 0.42222403617355064 0.738629388975321 0.6867677923999553 0.6688040805924758 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7487578282697582 0.6636690647482014 0.36085265624030705 0.6988992845349478 0.6636690647482014 0.648085781883045 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7113965434786195 0.6554199569274947 0.3156436651535946 0.6601972678152717 0.6554816207391283 0.6528867957439386 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_22 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_23 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_23 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65221, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65221 to 0.61382, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61382

Epoch 00004: val_loss improved from 0.61382 to 0.60365, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60365

Epoch 00006: val_loss improved from 0.60365 to 0.60190, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60190

Epoch 00008: val_loss did not improve from 0.60190

Epoch 00009: val_loss did not improve from 0.60190

Epoch 00010: val_loss improved from 0.60190 to 0.59455, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59455

Epoch 00012: val_loss improved from 0.59455 to 0.59360, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59360

Epoch 00014: val_loss did not improve from 0.59360

Epoch 00015: val_loss did not improve from 0.59360

Epoch 00016: val_loss improved from 0.59360 to 0.58796, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.58796 to 0.58690, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58690

Epoch 00019: val_loss did not improve from 0.58690

Epoch 00020: val_loss improved from 0.58690 to 0.57881, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.57881

Epoch 00022: val_loss improved from 0.57881 to 0.57206, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.57206

Epoch 00024: val_loss did not improve from 0.57206

Epoch 00025: val_loss did not improve from 0.57206

Epoch 00026: val_loss did not improve from 0.57206

Epoch 00027: val_loss improved from 0.57206 to 0.56706, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.56706

Epoch 00029: val_loss improved from 0.56706 to 0.56538, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.56538

Epoch 00031: val_loss did not improve from 0.56538

Epoch 00032: val_loss did not improve from 0.56538

Epoch 00033: val_loss did not improve from 0.56538

Epoch 00034: val_loss improved from 0.56538 to 0.56240, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss improved from 0.56240 to 0.56114, saving model to 2_50_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.56114

Epoch 00037: val_loss did not improve from 0.56114

Epoch 00038: val_loss improved from 0.56114 to 0.55663, saving model to 2_50_best_model.hdf5

Epoch 00039: val_loss did not improve from 0.55663

Epoch 00040: val_loss did not improve from 0.55663

Epoch 00041: val_loss did not improve from 0.55663

Epoch 00042: val_loss did not improve from 0.55663

Epoch 00043: val_loss did not improve from 0.55663

Epoch 00044: val_loss did not improve from 0.55663

Epoch 00045: val_loss did not improve from 0.55663

Epoch 00046: val_loss did not improve from 0.55663
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7918687212914772 0.7007779772591263 0.41836524424256055 0.7179695144776679 0.700749951214015 0.6947405495620048 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7778259406863 0.7176258992805755 0.4582708724084782 0.7412536756795525 0.7176258992805755 0.7105386199418371 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.6896613565527135 0.6590093323761665 0.34450967074685973 0.6864425607959622 0.6591467537393426 0.6461050022650778 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_25 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_26 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_26 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64705, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64705 to 0.62753, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62753 to 0.60496, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60496

Epoch 00005: val_loss improved from 0.60496 to 0.59460, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59460 to 0.59412, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59412

Epoch 00008: val_loss did not improve from 0.59412

Epoch 00009: val_loss did not improve from 0.59412

Epoch 00010: val_loss did not improve from 0.59412

Epoch 00011: val_loss did not improve from 0.59412

Epoch 00012: val_loss did not improve from 0.59412

Epoch 00013: val_loss did not improve from 0.59412

Epoch 00014: val_loss did not improve from 0.59412
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7222826365506191 0.6363455016955915 0.3487283521793591 0.7230857918556752 0.6362832910627577 0.5971314763446581 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7246648724186119 0.6402877697841727 0.35975655485489344 0.730641592920354 0.6402877697841727 0.601233593918095 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.6553342320948565 0.6331658291457286 0.3433781076305818 0.7209814568179489 0.6333918765151141 0.5929194986860955 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_28 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_29 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_29 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63382, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.63382

Epoch 00003: val_loss improved from 0.63382 to 0.61050, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61050 to 0.60147, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60147

Epoch 00006: val_loss improved from 0.60147 to 0.59169, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59169

Epoch 00008: val_loss did not improve from 0.59169

Epoch 00009: val_loss improved from 0.59169 to 0.58916, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.58916 to 0.58708, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.58708 to 0.58631, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58631

Epoch 00013: val_loss improved from 0.58631 to 0.58420, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58420

Epoch 00015: val_loss did not improve from 0.58420

Epoch 00016: val_loss did not improve from 0.58420

Epoch 00017: val_loss improved from 0.58420 to 0.57863, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.57863 to 0.57801, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.57801 to 0.57161, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57161

Epoch 00021: val_loss did not improve from 0.57161

Epoch 00022: val_loss did not improve from 0.57161

Epoch 00023: val_loss did not improve from 0.57161

Epoch 00024: val_loss did not improve from 0.57161

Epoch 00025: val_loss did not improve from 0.57161

Epoch 00026: val_loss did not improve from 0.57161

Epoch 00027: val_loss did not improve from 0.57161
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.771813861331926 0.7071613804109316 0.4211450581352697 0.7140583611531827 0.7071434619935688 0.7047718340380109 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7620205993478599 0.7032374100719424 0.410968872547715 0.7077563059666945 0.7032374100719425 0.701614870468849 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.725251076040172 0.6669059583632448 0.3339355481831117 0.6670400996921757 0.666895479806725 0.6668302398752994 None
average testing metrics
[0.71155568 0.66058866 0.33879009 0.67958513 0.66066857 0.65192072]
std testing metrics
[0.02428982 0.01108321 0.0177182  0.01964336 0.01104441 0.02127542]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.70851, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.70851 to 0.65866, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.65866 to 0.64295, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.64295 to 0.62817, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.62817 to 0.62171, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.62171 to 0.60436, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60436

Epoch 00008: val_loss improved from 0.60436 to 0.59825, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59825

Epoch 00010: val_loss improved from 0.59825 to 0.58730, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58730

Epoch 00012: val_loss improved from 0.58730 to 0.57576, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.57576

Epoch 00014: val_loss did not improve from 0.57576

Epoch 00015: val_loss did not improve from 0.57576

Epoch 00016: val_loss did not improve from 0.57576

Epoch 00017: val_loss did not improve from 0.57576

Epoch 00018: val_loss did not improve from 0.57576

Epoch 00019: val_loss improved from 0.57576 to 0.57121, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57121

Epoch 00021: val_loss improved from 0.57121 to 0.56579, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.56579

Epoch 00023: val_loss did not improve from 0.56579

Epoch 00024: val_loss did not improve from 0.56579

Epoch 00025: val_loss did not improve from 0.56579

Epoch 00026: val_loss did not improve from 0.56579

Epoch 00027: val_loss did not improve from 0.56579

Epoch 00028: val_loss improved from 0.56579 to 0.55434, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.55434

Epoch 00030: val_loss did not improve from 0.55434

Epoch 00031: val_loss did not improve from 0.55434

Epoch 00032: val_loss did not improve from 0.55434

Epoch 00033: val_loss did not improve from 0.55434

Epoch 00034: val_loss did not improve from 0.55434

Epoch 00035: val_loss improved from 0.55434 to 0.55350, saving model to 1_100_best_model.hdf5

Epoch 00036: val_loss did not improve from 0.55350

Epoch 00037: val_loss did not improve from 0.55350

Epoch 00038: val_loss did not improve from 0.55350

Epoch 00039: val_loss did not improve from 0.55350

Epoch 00040: val_loss did not improve from 0.55350

Epoch 00041: val_loss did not improve from 0.55350

Epoch 00042: val_loss did not improve from 0.55350

Epoch 00043: val_loss did not improve from 0.55350
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8895321089664248 0.8056276192376771 0.6299417749867524 0.8246254286182282 0.8056034778009822 0.8027330570060098 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7869117817088681 0.7222222222222222 0.45702039065025885 0.7349760921538796 0.7222222222222223 0.7184011148046976 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7466533501541912 0.6877243359655419 0.3763363385430982 0.6885888808365255 0.68774839624664 0.6873834372112532 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_3 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66323, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.66323 to 0.62385, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62385 to 0.61438, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.61438

Epoch 00005: val_loss did not improve from 0.61438

Epoch 00006: val_loss improved from 0.61438 to 0.61248, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.61248 to 0.60677, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60677

Epoch 00009: val_loss did not improve from 0.60677

Epoch 00010: val_loss improved from 0.60677 to 0.60265, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60265

Epoch 00012: val_loss improved from 0.60265 to 0.59680, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59680

Epoch 00014: val_loss improved from 0.59680 to 0.59102, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59102

Epoch 00016: val_loss did not improve from 0.59102

Epoch 00017: val_loss improved from 0.59102 to 0.59077, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss improved from 0.59077 to 0.58622, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.58622

Epoch 00020: val_loss improved from 0.58622 to 0.58565, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.58565

Epoch 00022: val_loss improved from 0.58565 to 0.57944, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.57944

Epoch 00024: val_loss did not improve from 0.57944

Epoch 00025: val_loss did not improve from 0.57944

Epoch 00026: val_loss did not improve from 0.57944

Epoch 00027: val_loss did not improve from 0.57944

Epoch 00028: val_loss did not improve from 0.57944

Epoch 00029: val_loss did not improve from 0.57944

Epoch 00030: val_loss did not improve from 0.57944
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7875651729262941 0.7182199161843943 0.443374150646386 0.7252275012808869 0.7182023024979569 0.7160003069775747 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7511979548053083 0.6881720430107527 0.382040524641986 0.6939115929941618 0.6881720430107527 0.6858474082702387 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7428377364402448 0.6719310839913855 0.35537624705434473 0.6835418398722568 0.6720211002819967 0.6667312332443187 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64508, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64508 to 0.61633, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61633

Epoch 00004: val_loss improved from 0.61633 to 0.60446, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60446 to 0.60366, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.60366 to 0.60171, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.60171 to 0.60053, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.60053 to 0.59464, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.59464 to 0.58987, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58987

Epoch 00011: val_loss improved from 0.58987 to 0.58984, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.58984 to 0.58929, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58929

Epoch 00014: val_loss did not improve from 0.58929

Epoch 00015: val_loss did not improve from 0.58929

Epoch 00016: val_loss did not improve from 0.58929

Epoch 00017: val_loss did not improve from 0.58929

Epoch 00018: val_loss improved from 0.58929 to 0.58851, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss improved from 0.58851 to 0.58520, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.58520

Epoch 00021: val_loss improved from 0.58520 to 0.58470, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.58470

Epoch 00023: val_loss did not improve from 0.58470

Epoch 00024: val_loss did not improve from 0.58470

Epoch 00025: val_loss did not improve from 0.58470

Epoch 00026: val_loss improved from 0.58470 to 0.58302, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.58302

Epoch 00028: val_loss improved from 0.58302 to 0.58234, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.58234

Epoch 00030: val_loss did not improve from 0.58234

Epoch 00031: val_loss did not improve from 0.58234

Epoch 00032: val_loss improved from 0.58234 to 0.57812, saving model to 1_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.57812

Epoch 00034: val_loss did not improve from 0.57812

Epoch 00035: val_loss did not improve from 0.57812

Epoch 00036: val_loss did not improve from 0.57812

Epoch 00037: val_loss did not improve from 0.57812

Epoch 00038: val_loss did not improve from 0.57812

Epoch 00039: val_loss did not improve from 0.57812

Epoch 00040: val_loss did not improve from 0.57812
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8346693683662205 0.7483536220315307 0.5105036189960767 0.7623659687194426 0.7483305535776014 0.7449365398116818 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7394368006577511 0.6756272401433692 0.36393274550116284 0.6885343115622242 0.6756272401433692 0.6699789239792835 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7344283381981893 0.6697774587221823 0.359130681365751 0.6897875015543612 0.6698937564933458 0.6609313883197588 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63475, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63475 to 0.62310, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62310 to 0.59993, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.59993 to 0.59849, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.59849 to 0.59055, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59055

Epoch 00007: val_loss did not improve from 0.59055

Epoch 00008: val_loss improved from 0.59055 to 0.58179, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.58179

Epoch 00010: val_loss improved from 0.58179 to 0.57930, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.57930

Epoch 00012: val_loss improved from 0.57930 to 0.57059, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.57059

Epoch 00014: val_loss did not improve from 0.57059

Epoch 00015: val_loss improved from 0.57059 to 0.56249, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.56249

Epoch 00017: val_loss did not improve from 0.56249

Epoch 00018: val_loss did not improve from 0.56249

Epoch 00019: val_loss did not improve from 0.56249

Epoch 00020: val_loss did not improve from 0.56249

Epoch 00021: val_loss did not improve from 0.56249

Epoch 00022: val_loss did not improve from 0.56249

Epoch 00023: val_loss did not improve from 0.56249
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.786823320637257 0.7136300139692676 0.44975368750225986 0.7367503475668905 0.713598819918025 0.7064442336571279 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7664726814917588 0.6971326164874552 0.4159987018110355 0.7194651029748285 0.6971326164874552 0.6892266422359389 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.723953437556688 0.659727207465901 0.3209443476654753 0.6611864681732533 0.6597610448721121 0.6589847042490952 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_9 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65096, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65096 to 0.62635, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62635 to 0.60931, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60931 to 0.60390, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60390 to 0.60200, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.60200 to 0.60130, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60130

Epoch 00008: val_loss improved from 0.60130 to 0.59547, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.59547 to 0.59109, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.59109 to 0.58835, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58835

Epoch 00012: val_loss did not improve from 0.58835

Epoch 00013: val_loss did not improve from 0.58835

Epoch 00014: val_loss improved from 0.58835 to 0.58531, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58531

Epoch 00016: val_loss did not improve from 0.58531

Epoch 00017: val_loss did not improve from 0.58531

Epoch 00018: val_loss improved from 0.58531 to 0.58423, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.58423

Epoch 00020: val_loss did not improve from 0.58423

Epoch 00021: val_loss did not improve from 0.58423

Epoch 00022: val_loss did not improve from 0.58423

Epoch 00023: val_loss did not improve from 0.58423

Epoch 00024: val_loss improved from 0.58423 to 0.58189, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.58189

Epoch 00026: val_loss did not improve from 0.58189

Epoch 00027: val_loss did not improve from 0.58189

Epoch 00028: val_loss did not improve from 0.58189

Epoch 00029: val_loss did not improve from 0.58189

Epoch 00030: val_loss did not improve from 0.58189

Epoch 00031: val_loss did not improve from 0.58189

Epoch 00032: val_loss did not improve from 0.58189
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8203137689019617 0.7474062250598563 0.5129208833712947 0.7658460114885337 0.7474062250598563 0.7429487860905999 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7335808772336969 0.6696588868940754 0.3581731764915249 0.6893631436314362 0.6693677316211546 0.6605997986541621 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7388252609706624 0.6762383345297918 0.37458766998747295 0.6989063568010936 0.6763592737347253 0.6668370726305926 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65549, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65549 to 0.63222, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.63222 to 0.62811, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.62811 to 0.61941, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61941

Epoch 00006: val_loss improved from 0.61941 to 0.61677, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61677

Epoch 00008: val_loss did not improve from 0.61677

Epoch 00009: val_loss improved from 0.61677 to 0.61383, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61383

Epoch 00011: val_loss improved from 0.61383 to 0.61359, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.61359

Epoch 00013: val_loss did not improve from 0.61359

Epoch 00014: val_loss improved from 0.61359 to 0.61114, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.61114 to 0.60854, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.60854 to 0.60633, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.60633

Epoch 00018: val_loss did not improve from 0.60633

Epoch 00019: val_loss improved from 0.60633 to 0.59981, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.59981

Epoch 00021: val_loss did not improve from 0.59981

Epoch 00022: val_loss improved from 0.59981 to 0.59888, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59888

Epoch 00024: val_loss did not improve from 0.59888

Epoch 00025: val_loss did not improve from 0.59888

Epoch 00026: val_loss did not improve from 0.59888

Epoch 00027: val_loss did not improve from 0.59888

Epoch 00028: val_loss did not improve from 0.59888

Epoch 00029: val_loss improved from 0.59888 to 0.59364, saving model to 1_100_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.59364

Epoch 00031: val_loss did not improve from 0.59364

Epoch 00032: val_loss did not improve from 0.59364

Epoch 00033: val_loss did not improve from 0.59364

Epoch 00034: val_loss did not improve from 0.59364

Epoch 00035: val_loss did not improve from 0.59364

Epoch 00036: val_loss did not improve from 0.59364

Epoch 00037: val_loss did not improve from 0.59364
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8222090676035274 0.7546379413524835 0.5320576174321434 0.7779607766814834 0.754609042008792 0.7493667088860743 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7453030381450236 0.6654676258992805 0.34634469611367963 0.681235827664399 0.6654676258992807 0.6580294432760605 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7404784874420751 0.678391959798995 0.3630502152106121 0.6846451789035439 0.6784577582084137 0.6756963498794379 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64099, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64099 to 0.61330, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61330 to 0.60412, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60412 to 0.60126, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60126

Epoch 00006: val_loss improved from 0.60126 to 0.60018, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.60018 to 0.59293, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.59293 to 0.59098, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59098

Epoch 00010: val_loss improved from 0.59098 to 0.58939, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58939

Epoch 00012: val_loss improved from 0.58939 to 0.58006, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58006

Epoch 00014: val_loss improved from 0.58006 to 0.57373, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57373

Epoch 00016: val_loss did not improve from 0.57373

Epoch 00017: val_loss did not improve from 0.57373

Epoch 00018: val_loss did not improve from 0.57373

Epoch 00019: val_loss did not improve from 0.57373

Epoch 00020: val_loss did not improve from 0.57373

Epoch 00021: val_loss did not improve from 0.57373

Epoch 00022: val_loss improved from 0.57373 to 0.56486, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.56486

Epoch 00024: val_loss did not improve from 0.56486

Epoch 00025: val_loss did not improve from 0.56486

Epoch 00026: val_loss did not improve from 0.56486

Epoch 00027: val_loss did not improve from 0.56486

Epoch 00028: val_loss did not improve from 0.56486

Epoch 00029: val_loss improved from 0.56486 to 0.55927, saving model to 1_100_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.55927

Epoch 00031: val_loss did not improve from 0.55927

Epoch 00032: val_loss did not improve from 0.55927

Epoch 00033: val_loss improved from 0.55927 to 0.55823, saving model to 1_100_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.55823

Epoch 00035: val_loss did not improve from 0.55823

Epoch 00036: val_loss did not improve from 0.55823

Epoch 00037: val_loss did not improve from 0.55823

Epoch 00038: val_loss did not improve from 0.55823

Epoch 00039: val_loss did not improve from 0.55823

Epoch 00040: val_loss did not improve from 0.55823

Epoch 00041: val_loss did not improve from 0.55823
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.844466141253015 0.7692000797925393 0.5575105003588358 0.7886773675378835 0.7691741654890648 0.7652286686960752 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7751927954039647 0.7014388489208633 0.4132869465853778 0.7119825708061003 0.7014388489208634 0.6976795985482751 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7378254918451821 0.6898779612347452 0.38949089086763505 0.699654425306034 0.6899571645310774 0.6860910570462797 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_15 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63390, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63390 to 0.60750, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60750 to 0.59984, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.59984 to 0.59581, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.59581 to 0.59331, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59331

Epoch 00007: val_loss improved from 0.59331 to 0.58828, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.58828

Epoch 00009: val_loss did not improve from 0.58828

Epoch 00010: val_loss improved from 0.58828 to 0.58216, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58216

Epoch 00012: val_loss improved from 0.58216 to 0.58066, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58066

Epoch 00014: val_loss improved from 0.58066 to 0.57966, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57966

Epoch 00016: val_loss improved from 0.57966 to 0.57826, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.57826 to 0.57457, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.57457

Epoch 00019: val_loss improved from 0.57457 to 0.57024, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss improved from 0.57024 to 0.56455, saving model to 1_100_best_model.hdf5

Epoch 00021: val_loss improved from 0.56455 to 0.56001, saving model to 1_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.56001

Epoch 00023: val_loss did not improve from 0.56001

Epoch 00024: val_loss did not improve from 0.56001

Epoch 00025: val_loss improved from 0.56001 to 0.55668, saving model to 1_100_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.55668

Epoch 00027: val_loss did not improve from 0.55668

Epoch 00028: val_loss improved from 0.55668 to 0.55441, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.55441

Epoch 00030: val_loss improved from 0.55441 to 0.55429, saving model to 1_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.55429

Epoch 00032: val_loss did not improve from 0.55429

Epoch 00033: val_loss improved from 0.55429 to 0.54964, saving model to 1_100_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.54964

Epoch 00035: val_loss did not improve from 0.54964

Epoch 00036: val_loss did not improve from 0.54964

Epoch 00037: val_loss did not improve from 0.54964

Epoch 00038: val_loss did not improve from 0.54964

Epoch 00039: val_loss improved from 0.54964 to 0.54281, saving model to 1_100_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.54281

Epoch 00041: val_loss did not improve from 0.54281

Epoch 00042: val_loss did not improve from 0.54281

Epoch 00043: val_loss did not improve from 0.54281

Epoch 00044: val_loss did not improve from 0.54281

Epoch 00045: val_loss did not improve from 0.54281

Epoch 00046: val_loss did not improve from 0.54281

Epoch 00047: val_loss did not improve from 0.54281
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8522025797837882 0.7642130460801915 0.5391570289818206 0.7750735825417134 0.7641932198781958 0.7618533824457117 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7879509342166555 0.7320143884892086 0.47484591088026884 0.7429576033494574 0.7320143884892086 0.7289623922396165 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7421399594320487 0.674802584350323 0.3524228155377196 0.6775862068965517 0.6748472517686637 0.6735583556167368 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64147, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64147 to 0.61011, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61011 to 0.60532, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60532 to 0.59416, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59416

Epoch 00006: val_loss improved from 0.59416 to 0.58082, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.58082

Epoch 00008: val_loss did not improve from 0.58082

Epoch 00009: val_loss did not improve from 0.58082

Epoch 00010: val_loss improved from 0.58082 to 0.57339, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.57339

Epoch 00012: val_loss did not improve from 0.57339

Epoch 00013: val_loss did not improve from 0.57339

Epoch 00014: val_loss did not improve from 0.57339

Epoch 00015: val_loss improved from 0.57339 to 0.56303, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.56303 to 0.56063, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.56063

Epoch 00018: val_loss did not improve from 0.56063

Epoch 00019: val_loss did not improve from 0.56063

Epoch 00020: val_loss did not improve from 0.56063

Epoch 00021: val_loss did not improve from 0.56063

Epoch 00022: val_loss improved from 0.56063 to 0.55650, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.55650

Epoch 00024: val_loss did not improve from 0.55650

Epoch 00025: val_loss did not improve from 0.55650

Epoch 00026: val_loss did not improve from 0.55650

Epoch 00027: val_loss did not improve from 0.55650

Epoch 00028: val_loss did not improve from 0.55650

Epoch 00029: val_loss did not improve from 0.55650

Epoch 00030: val_loss did not improve from 0.55650
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8005410867129898 0.7229204069419509 0.47156202846375694 0.7494199566957997 0.7228878851904212 0.7153409840012968 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7841532529372186 0.6960431654676259 0.40987002719440463 0.7142301655755554 0.6960431654676259 0.689452201933405 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.737650274575768 0.6762383345297918 0.37182911653849593 0.6959955738020398 0.6763520589059846 0.6679562738597151 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 38,701
Trainable params: 38,701
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64466, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64466 to 0.61064, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61064 to 0.60349, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60349 to 0.60225, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60225 to 0.60032, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60032

Epoch 00007: val_loss did not improve from 0.60032

Epoch 00008: val_loss improved from 0.60032 to 0.59549, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.59549 to 0.59541, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59541

Epoch 00011: val_loss improved from 0.59541 to 0.59052, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.59052 to 0.58774, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58774

Epoch 00014: val_loss did not improve from 0.58774

Epoch 00015: val_loss did not improve from 0.58774

Epoch 00016: val_loss did not improve from 0.58774

Epoch 00017: val_loss did not improve from 0.58774

Epoch 00018: val_loss improved from 0.58774 to 0.58516, saving model to 1_100_best_model.hdf5

Epoch 00019: val_loss improved from 0.58516 to 0.57836, saving model to 1_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57836

Epoch 00021: val_loss did not improve from 0.57836

Epoch 00022: val_loss did not improve from 0.57836

Epoch 00023: val_loss did not improve from 0.57836

Epoch 00024: val_loss improved from 0.57836 to 0.57673, saving model to 1_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.57673

Epoch 00026: val_loss improved from 0.57673 to 0.57639, saving model to 1_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.57639

Epoch 00028: val_loss improved from 0.57639 to 0.57258, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.57258

Epoch 00030: val_loss did not improve from 0.57258

Epoch 00031: val_loss did not improve from 0.57258

Epoch 00032: val_loss did not improve from 0.57258

Epoch 00033: val_loss did not improve from 0.57258

Epoch 00034: val_loss did not improve from 0.57258

Epoch 00035: val_loss did not improve from 0.57258

Epoch 00036: val_loss did not improve from 0.57258
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8252793216503765 0.7454617993217634 0.5093190729175107 0.7642305484393341 0.7454352075959063 0.7408463481654776 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7664717147145593 0.6942446043165468 0.4022130182708837 0.7082108183079057 0.6942446043165468 0.6890298468179187 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7483282211118257 0.6834170854271356 0.3692680263423836 0.6858179350662909 0.6834576345256353 0.6824213630829755 None
average testing metrics
[0.73931206 0.67681263 0.36324363 0.68657104 0.67688554 0.67265912]
std testing metrics
[0.00649554 0.00840129 0.01756188 0.01079412 0.0083967  0.00958248]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_2 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67367, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.67367 to 0.65161, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.65161 to 0.63783, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.63783 to 0.62535, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.62535 to 0.62315, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.62315 to 0.61565, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.61565 to 0.61128, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.61128 to 0.60313, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.60313 to 0.59731, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59731

Epoch 00011: val_loss did not improve from 0.59731

Epoch 00012: val_loss improved from 0.59731 to 0.59160, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59160

Epoch 00014: val_loss improved from 0.59160 to 0.58882, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.58882 to 0.58289, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.58289

Epoch 00017: val_loss did not improve from 0.58289

Epoch 00018: val_loss did not improve from 0.58289

Epoch 00019: val_loss did not improve from 0.58289

Epoch 00020: val_loss did not improve from 0.58289

Epoch 00021: val_loss did not improve from 0.58289

Epoch 00022: val_loss did not improve from 0.58289

Epoch 00023: val_loss did not improve from 0.58289
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7928422484639659 0.7224106964677709 0.4578953188305681 0.735701876273656 0.7223869897873845 0.7184274793217748 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7420511041738931 0.6810035842293907 0.3700925020336071 0.6891792096888972 0.6810035842293907 0.6775194805194805 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7149926202608883 0.6604450825556353 0.33958124717977317 0.6795498029091076 0.6605618908623163 0.6512657902912765 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_4 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63779, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63779 to 0.60530, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60530 to 0.60289, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60289 to 0.58841, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.58841

Epoch 00006: val_loss did not improve from 0.58841

Epoch 00007: val_loss did not improve from 0.58841

Epoch 00008: val_loss did not improve from 0.58841

Epoch 00009: val_loss improved from 0.58841 to 0.58183, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58183

Epoch 00011: val_loss did not improve from 0.58183

Epoch 00012: val_loss did not improve from 0.58183

Epoch 00013: val_loss improved from 0.58183 to 0.57783, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.57783

Epoch 00015: val_loss did not improve from 0.57783

Epoch 00016: val_loss did not improve from 0.57783

Epoch 00017: val_loss did not improve from 0.57783

Epoch 00018: val_loss improved from 0.57783 to 0.57586, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.57586

Epoch 00020: val_loss improved from 0.57586 to 0.56472, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.56472

Epoch 00022: val_loss did not improve from 0.56472

Epoch 00023: val_loss did not improve from 0.56472

Epoch 00024: val_loss improved from 0.56472 to 0.56393, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.56393

Epoch 00026: val_loss did not improve from 0.56393

Epoch 00027: val_loss did not improve from 0.56393

Epoch 00028: val_loss did not improve from 0.56393

Epoch 00029: val_loss did not improve from 0.56393

Epoch 00030: val_loss did not improve from 0.56393

Epoch 00031: val_loss did not improve from 0.56393

Epoch 00032: val_loss did not improve from 0.56393
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7970049525848542 0.72001596487727 0.4662603314772968 0.7470631331112487 0.7199829391496337 0.7121178748597378 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7531763466553616 0.7096774193548387 0.44662670076481725 0.7378360655737706 0.7096774193548387 0.7008221136661503 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.740364080872046 0.6791098348887293 0.3753070369918589 0.6964878974845752 0.6792163459159947 0.6719353344787418 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               38600     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_8 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.60835, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.60835

Epoch 00003: val_loss improved from 0.60835 to 0.59935, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.59935

Epoch 00005: val_loss improved from 0.59935 to 0.59442, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59442

Epoch 00007: val_loss did not improve from 0.59442

Epoch 00008: val_loss improved from 0.59442 to 0.59166, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59166

Epoch 00010: val_loss did not improve from 0.59166

Epoch 00011: val_loss did not improve from 0.59166

Epoch 00012: val_loss improved from 0.59166 to 0.59053, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59053

Epoch 00014: val_loss improved from 0.59053 to 0.58030, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58030

Epoch 00016: val_loss did not improve from 0.58030

Epoch 00017: val_loss did not improve from 0.58030

Epoch 00018: val_loss did not improve from 0.58030

Epoch 00019: val_loss did not improve from 0.58030

Epoch 00020: val_loss did not improve from 0.58030

Epoch 00021: val_loss did not improve from 0.58030

Epoch 00022: val_loss did not improve from 0.58030
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7838175205853257 0.6938734783476352 0.41928922823385223 0.7267431416613559 0.6938354735062995 0.682335585411348 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7483459873331535 0.6899641577060932 0.4113845615733577 0.7227226171827932 0.6899641577060932 0.6781288031608955 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.737786325632019 0.659727207465901 0.36362303763232895 0.7067280528756463 0.659898126618183 0.639365160512276 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_10 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65446, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65446 to 0.60698, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.60698

Epoch 00004: val_loss improved from 0.60698 to 0.59264, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.59264 to 0.59197, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.59197 to 0.58720, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.58720

Epoch 00008: val_loss improved from 0.58720 to 0.58600, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.58600 to 0.58216, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58216

Epoch 00011: val_loss improved from 0.58216 to 0.58142, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58142

Epoch 00013: val_loss did not improve from 0.58142

Epoch 00014: val_loss did not improve from 0.58142

Epoch 00015: val_loss did not improve from 0.58142

Epoch 00016: val_loss improved from 0.58142 to 0.57868, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.57868

Epoch 00018: val_loss did not improve from 0.57868

Epoch 00019: val_loss did not improve from 0.57868

Epoch 00020: val_loss did not improve from 0.57868

Epoch 00021: val_loss did not improve from 0.57868

Epoch 00022: val_loss did not improve from 0.57868

Epoch 00023: val_loss did not improve from 0.57868

Epoch 00024: val_loss did not improve from 0.57868
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.772465683158822 0.7006585511873877 0.4146093308402057 0.7141977040816326 0.7006334497804072 0.6958355387431834 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7400598656235147 0.6720430107526881 0.35320862855067836 0.6812865497076024 0.6720430107526881 0.667808519982433 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7236792740645459 0.6647523330940417 0.3421926231718931 0.6775808851286834 0.6648485298240406 0.6586667492193785 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_14 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62803, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.62803 to 0.60596, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.60596

Epoch 00004: val_loss improved from 0.60596 to 0.60327, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60327 to 0.60067, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60067

Epoch 00007: val_loss improved from 0.60067 to 0.59867, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.59867 to 0.59192, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.59192 to 0.58935, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58935

Epoch 00011: val_loss improved from 0.58935 to 0.58910, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58910

Epoch 00013: val_loss did not improve from 0.58910

Epoch 00014: val_loss did not improve from 0.58910

Epoch 00015: val_loss improved from 0.58910 to 0.58566, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.58566 to 0.58258, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.58258

Epoch 00018: val_loss improved from 0.58258 to 0.57959, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.57959

Epoch 00020: val_loss improved from 0.57959 to 0.57866, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.57866

Epoch 00022: val_loss did not improve from 0.57866

Epoch 00023: val_loss did not improve from 0.57866

Epoch 00024: val_loss did not improve from 0.57866

Epoch 00025: val_loss did not improve from 0.57866

Epoch 00026: val_loss did not improve from 0.57866

Epoch 00027: val_loss did not improve from 0.57866

Epoch 00028: val_loss improved from 0.57866 to 0.57762, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.57762

Epoch 00030: val_loss did not improve from 0.57762

Epoch 00031: val_loss did not improve from 0.57762

Epoch 00032: val_loss did not improve from 0.57762

Epoch 00033: val_loss did not improve from 0.57762

Epoch 00034: val_loss improved from 0.57762 to 0.57616, saving model to 2_100_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.57616

Epoch 00036: val_loss did not improve from 0.57616

Epoch 00037: val_loss did not improve from 0.57616

Epoch 00038: val_loss did not improve from 0.57616

Epoch 00039: val_loss did not improve from 0.57616

Epoch 00040: val_loss did not improve from 0.57616

Epoch 00041: val_loss did not improve from 0.57616

Epoch 00042: val_loss did not improve from 0.57616
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8065433860570227 0.7380287310454908 0.47605780321337043 0.7380290721680018 0.7380287310454908 0.7380286371868623 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7449395322451715 0.6912028725314183 0.38397775377619286 0.6928636481915171 0.6911180732833089 0.690475575084001 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7360527053546396 0.6625987078248384 0.32680539520606255 0.6641754550978449 0.6626335774006826 0.6618163598421455 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_16 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63395, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63395 to 0.61130, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61130 to 0.60667, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60667

Epoch 00005: val_loss improved from 0.60667 to 0.60416, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60416

Epoch 00007: val_loss did not improve from 0.60416

Epoch 00008: val_loss did not improve from 0.60416

Epoch 00009: val_loss improved from 0.60416 to 0.60223, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.60223 to 0.59455, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59455

Epoch 00012: val_loss did not improve from 0.59455

Epoch 00013: val_loss did not improve from 0.59455

Epoch 00014: val_loss improved from 0.59455 to 0.59262, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59262

Epoch 00016: val_loss did not improve from 0.59262

Epoch 00017: val_loss improved from 0.59262 to 0.57796, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.57796

Epoch 00019: val_loss did not improve from 0.57796

Epoch 00020: val_loss did not improve from 0.57796

Epoch 00021: val_loss improved from 0.57796 to 0.57706, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.57706

Epoch 00023: val_loss did not improve from 0.57706

Epoch 00024: val_loss improved from 0.57706 to 0.57414, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.57414

Epoch 00026: val_loss did not improve from 0.57414

Epoch 00027: val_loss improved from 0.57414 to 0.57271, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.57271

Epoch 00029: val_loss did not improve from 0.57271

Epoch 00030: val_loss improved from 0.57271 to 0.57157, saving model to 2_100_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.57157

Epoch 00032: val_loss did not improve from 0.57157

Epoch 00033: val_loss did not improve from 0.57157

Epoch 00034: val_loss did not improve from 0.57157

Epoch 00035: val_loss did not improve from 0.57157

Epoch 00036: val_loss improved from 0.57157 to 0.56994, saving model to 2_100_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.56994

Epoch 00038: val_loss did not improve from 0.56994

Epoch 00039: val_loss did not improve from 0.56994

Epoch 00040: val_loss did not improve from 0.56994

Epoch 00041: val_loss did not improve from 0.56994

Epoch 00042: val_loss did not improve from 0.56994

Epoch 00043: val_loss did not improve from 0.56994

Epoch 00044: val_loss did not improve from 0.56994
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8218161533977808 0.7540394973070018 0.5085916687693198 0.7545569456716952 0.7540349909320144 0.7539122336737498 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7694736297293101 0.6960431654676259 0.39300528552826675 0.696963196963197 0.6960431654676259 0.6956877985588212 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7366195847556852 0.6826992103374013 0.36994221895130525 0.6872143949184468 0.6827547040683388 0.6808159668221877 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_20 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.61491, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.61491 to 0.59837, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.59837

Epoch 00004: val_loss improved from 0.59837 to 0.59096, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59096

Epoch 00006: val_loss did not improve from 0.59096

Epoch 00007: val_loss improved from 0.59096 to 0.58805, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.58805

Epoch 00009: val_loss improved from 0.58805 to 0.58419, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.58419 to 0.58097, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.58097 to 0.57936, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.57936 to 0.57734, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.57734

Epoch 00014: val_loss did not improve from 0.57734

Epoch 00015: val_loss did not improve from 0.57734

Epoch 00016: val_loss improved from 0.57734 to 0.57700, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.57700

Epoch 00018: val_loss did not improve from 0.57700

Epoch 00019: val_loss did not improve from 0.57700

Epoch 00020: val_loss did not improve from 0.57700

Epoch 00021: val_loss did not improve from 0.57700

Epoch 00022: val_loss did not improve from 0.57700

Epoch 00023: val_loss improved from 0.57700 to 0.57567, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.57567 to 0.57492, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.57492

Epoch 00026: val_loss did not improve from 0.57492

Epoch 00027: val_loss did not improve from 0.57492

Epoch 00028: val_loss improved from 0.57492 to 0.56995, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.56995

Epoch 00030: val_loss did not improve from 0.56995

Epoch 00031: val_loss did not improve from 0.56995

Epoch 00032: val_loss did not improve from 0.56995

Epoch 00033: val_loss did not improve from 0.56995

Epoch 00034: val_loss did not improve from 0.56995

Epoch 00035: val_loss did not improve from 0.56995

Epoch 00036: val_loss did not improve from 0.56995
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7976437722183154 0.7293038100937562 0.48260256662899403 0.7539609118798265 0.7292727211373995 0.7225523270148085 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7613348170384555 0.7086330935251799 0.4311582492512881 0.7227564102564102 0.7086330935251799 0.703940362087327 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7323628357987434 0.665470208183776 0.35039365813552853 0.6853637655876462 0.6655875344250399 0.6563443660927937 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_22 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_23 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.61247, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.61247 to 0.59897, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.59897

Epoch 00004: val_loss improved from 0.59897 to 0.59427, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.59427 to 0.59312, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.59312 to 0.58502, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.58502

Epoch 00008: val_loss did not improve from 0.58502

Epoch 00009: val_loss improved from 0.58502 to 0.58252, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58252

Epoch 00011: val_loss improved from 0.58252 to 0.57758, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.57758

Epoch 00013: val_loss did not improve from 0.57758

Epoch 00014: val_loss improved from 0.57758 to 0.56711, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.56711 to 0.56670, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss improved from 0.56670 to 0.56412, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss improved from 0.56412 to 0.55951, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.55951

Epoch 00019: val_loss did not improve from 0.55951

Epoch 00020: val_loss did not improve from 0.55951

Epoch 00021: val_loss did not improve from 0.55951

Epoch 00022: val_loss improved from 0.55951 to 0.55888, saving model to 2_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.55888

Epoch 00024: val_loss did not improve from 0.55888

Epoch 00025: val_loss did not improve from 0.55888

Epoch 00026: val_loss improved from 0.55888 to 0.55547, saving model to 2_100_best_model.hdf5

Epoch 00027: val_loss improved from 0.55547 to 0.55267, saving model to 2_100_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.55267

Epoch 00029: val_loss improved from 0.55267 to 0.55164, saving model to 2_100_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.55164

Epoch 00031: val_loss did not improve from 0.55164

Epoch 00032: val_loss improved from 0.55164 to 0.54826, saving model to 2_100_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.54826

Epoch 00034: val_loss did not improve from 0.54826

Epoch 00035: val_loss did not improve from 0.54826

Epoch 00036: val_loss did not improve from 0.54826

Epoch 00037: val_loss did not improve from 0.54826

Epoch 00038: val_loss did not improve from 0.54826

Epoch 00039: val_loss did not improve from 0.54826

Epoch 00040: val_loss did not improve from 0.54826
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8047188542472139 0.7328944743666467 0.48263788898383425 0.7500762362407261 0.7328683198616102 0.7282118766070897 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7764090885564929 0.710431654676259 0.4409760013821771 0.7310249307479224 0.710431654676259 0.7038316343917392 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7320515674730783 0.6647523330940417 0.3306527001380513 0.6658729664674634 0.6647815349857353 0.6642096553318952 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_25 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_26 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63893, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63893 to 0.60660, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60660 to 0.60375, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60375

Epoch 00005: val_loss did not improve from 0.60375

Epoch 00006: val_loss improved from 0.60375 to 0.57783, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.57783

Epoch 00008: val_loss did not improve from 0.57783

Epoch 00009: val_loss did not improve from 0.57783

Epoch 00010: val_loss improved from 0.57783 to 0.57622, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.57622

Epoch 00012: val_loss improved from 0.57622 to 0.56712, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.56712

Epoch 00014: val_loss did not improve from 0.56712

Epoch 00015: val_loss did not improve from 0.56712

Epoch 00016: val_loss did not improve from 0.56712

Epoch 00017: val_loss did not improve from 0.56712

Epoch 00018: val_loss improved from 0.56712 to 0.56331, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.56331

Epoch 00020: val_loss did not improve from 0.56331

Epoch 00021: val_loss did not improve from 0.56331

Epoch 00022: val_loss did not improve from 0.56331

Epoch 00023: val_loss improved from 0.56331 to 0.56140, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss improved from 0.56140 to 0.55619, saving model to 2_100_best_model.hdf5

Epoch 00025: val_loss improved from 0.55619 to 0.55391, saving model to 2_100_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.55391

Epoch 00027: val_loss did not improve from 0.55391

Epoch 00028: val_loss did not improve from 0.55391

Epoch 00029: val_loss did not improve from 0.55391

Epoch 00030: val_loss did not improve from 0.55391

Epoch 00031: val_loss did not improve from 0.55391

Epoch 00032: val_loss did not improve from 0.55391

Epoch 00033: val_loss did not improve from 0.55391
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7864783076659098 0.7149411530021943 0.4440649624246745 0.729384489877464 0.714916111981424 0.7103667533798302 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7756068526473785 0.7068345323741008 0.4208108827855323 0.7140380006159367 0.7068345323741008 0.7043469750599443 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.721763221689012 0.6633165829145728 0.3428847034834011 0.6798528591068098 0.6634251471825063 0.6554869383220071 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 100)               38600     
_________________________________________________________________
activation_28 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_29 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 48,801
Trainable params: 48,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64170, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64170 to 0.60539, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60539 to 0.59868, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.59868 to 0.59513, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59513

Epoch 00006: val_loss did not improve from 0.59513

Epoch 00007: val_loss improved from 0.59513 to 0.59217, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.59217 to 0.58664, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.58664

Epoch 00010: val_loss did not improve from 0.58664

Epoch 00011: val_loss improved from 0.58664 to 0.57835, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.57835

Epoch 00013: val_loss improved from 0.57835 to 0.56890, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.56890

Epoch 00015: val_loss did not improve from 0.56890

Epoch 00016: val_loss improved from 0.56890 to 0.56808, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.56808

Epoch 00018: val_loss did not improve from 0.56808

Epoch 00019: val_loss improved from 0.56808 to 0.56766, saving model to 2_100_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.56766

Epoch 00021: val_loss did not improve from 0.56766

Epoch 00022: val_loss did not improve from 0.56766

Epoch 00023: val_loss improved from 0.56766 to 0.56378, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.56378

Epoch 00025: val_loss improved from 0.56378 to 0.56226, saving model to 2_100_best_model.hdf5

Epoch 00026: val_loss improved from 0.56226 to 0.56166, saving model to 2_100_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.56166

Epoch 00028: val_loss improved from 0.56166 to 0.55752, saving model to 2_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.55752

Epoch 00030: val_loss did not improve from 0.55752

Epoch 00031: val_loss did not improve from 0.55752

Epoch 00032: val_loss did not improve from 0.55752

Epoch 00033: val_loss did not improve from 0.55752

Epoch 00034: val_loss did not improve from 0.55752

Epoch 00035: val_loss did not improve from 0.55752

Epoch 00036: val_loss did not improve from 0.55752
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.801946887103978 0.7143427089567126 0.44158469735663064 0.7274614936035527 0.714318742317998 0.7101488458631315 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7721132446560738 0.697841726618705 0.407329189832823 0.7096588415971917 0.697841726618705 0.6935231970601745 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7216148023549201 0.659727207465901 0.3213196829222853 0.6616377331719735 0.6596878658948861 0.6586843247937473 None
average testing metrics
[0.7297287  0.66625987 0.34627023 0.68044638 0.66633953 0.65985906]
std testing metrics
[0.00812945 0.0076274  0.01743494 0.01363196 0.00762779 0.01065787]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 200)               77200     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.97749, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.97749 to 0.67061, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.67061 to 0.63284, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.63284 to 0.61479, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.61479 to 0.60595, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.60595 to 0.59325, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59325

Epoch 00008: val_loss improved from 0.59325 to 0.58452, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.58452

Epoch 00010: val_loss did not improve from 0.58452

Epoch 00011: val_loss did not improve from 0.58452

Epoch 00012: val_loss did not improve from 0.58452

Epoch 00013: val_loss improved from 0.58452 to 0.56912, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.56912

Epoch 00015: val_loss did not improve from 0.56912

Epoch 00016: val_loss did not improve from 0.56912

Epoch 00017: val_loss did not improve from 0.56912

Epoch 00018: val_loss did not improve from 0.56912

Epoch 00019: val_loss did not improve from 0.56912

Epoch 00020: val_loss did not improve from 0.56912

Epoch 00021: val_loss improved from 0.56912 to 0.56786, saving model to 1_200_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.56786

Epoch 00023: val_loss did not improve from 0.56786

Epoch 00024: val_loss improved from 0.56786 to 0.56625, saving model to 1_200_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.56625

Epoch 00026: val_loss did not improve from 0.56625

Epoch 00027: val_loss improved from 0.56625 to 0.56489, saving model to 1_200_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.56489

Epoch 00029: val_loss did not improve from 0.56489

Epoch 00030: val_loss did not improve from 0.56489

Epoch 00031: val_loss did not improve from 0.56489

Epoch 00032: val_loss improved from 0.56489 to 0.55365, saving model to 1_200_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.55365

Epoch 00034: val_loss did not improve from 0.55365

Epoch 00035: val_loss did not improve from 0.55365

Epoch 00036: val_loss did not improve from 0.55365

Epoch 00037: val_loss did not improve from 0.55365

Epoch 00038: val_loss did not improve from 0.55365

Epoch 00039: val_loss did not improve from 0.55365

Epoch 00040: val_loss did not improve from 0.55365
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.9018295412367603 0.8227898623029335 0.6518888719038585 0.8291439777078848 0.8227759962915351 0.8219260838663824 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7825824436993358 0.7078853046594982 0.4217986610095483 0.7139570552147239 0.7078853046594982 0.7057980624605782 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7477407279143785 0.6819813352476669 0.3700509922393034 0.6880541808982734 0.6820455894721219 0.6794412471630946 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 200)               77200     
_________________________________________________________________
activation_3 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64880, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64880 to 0.62409, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.62409 to 0.60457, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60457

Epoch 00005: val_loss did not improve from 0.60457

Epoch 00006: val_loss improved from 0.60457 to 0.59633, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59633

Epoch 00008: val_loss improved from 0.59633 to 0.59477, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59477

Epoch 00010: val_loss did not improve from 0.59477

Epoch 00011: val_loss did not improve from 0.59477

Epoch 00012: val_loss improved from 0.59477 to 0.59171, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59171

Epoch 00014: val_loss did not improve from 0.59171

Epoch 00015: val_loss did not improve from 0.59171

Epoch 00016: val_loss did not improve from 0.59171

Epoch 00017: val_loss did not improve from 0.59171

Epoch 00018: val_loss did not improve from 0.59171

Epoch 00019: val_loss improved from 0.59171 to 0.57933, saving model to 1_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57933

Epoch 00021: val_loss did not improve from 0.57933

Epoch 00022: val_loss did not improve from 0.57933

Epoch 00023: val_loss improved from 0.57933 to 0.57041, saving model to 1_200_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.57041

Epoch 00025: val_loss did not improve from 0.57041

Epoch 00026: val_loss did not improve from 0.57041

Epoch 00027: val_loss did not improve from 0.57041

Epoch 00028: val_loss did not improve from 0.57041

Epoch 00029: val_loss did not improve from 0.57041

Epoch 00030: val_loss did not improve from 0.57041

Epoch 00031: val_loss did not improve from 0.57041
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8237496276401706 0.7381760127719018 0.476448970685455 0.7382709861866303 0.7381779935739057 0.7381509750785815 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7413702290566669 0.6684587813620072 0.33697167924674676 0.6685129022309036 0.6684587813620071 0.6684321591577027 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7390128465179175 0.6769562096195262 0.3560885965266015 0.679099605349887 0.6769952093537163 0.6760170434106668 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 200)               77200     
_________________________________________________________________
activation_5 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64453, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64453 to 0.60788, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60788 to 0.60682, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.60682 to 0.60383, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.60383 to 0.59520, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59520

Epoch 00007: val_loss improved from 0.59520 to 0.59116, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59116

Epoch 00009: val_loss improved from 0.59116 to 0.58561, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.58561

Epoch 00011: val_loss did not improve from 0.58561

Epoch 00012: val_loss did not improve from 0.58561

Epoch 00013: val_loss improved from 0.58561 to 0.58340, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58340

Epoch 00015: val_loss did not improve from 0.58340

Epoch 00016: val_loss did not improve from 0.58340

Epoch 00017: val_loss did not improve from 0.58340

Epoch 00018: val_loss did not improve from 0.58340

Epoch 00019: val_loss improved from 0.58340 to 0.57960, saving model to 1_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.57960

Epoch 00021: val_loss did not improve from 0.57960

Epoch 00022: val_loss did not improve from 0.57960

Epoch 00023: val_loss did not improve from 0.57960

Epoch 00024: val_loss did not improve from 0.57960

Epoch 00025: val_loss did not improve from 0.57960

Epoch 00026: val_loss did not improve from 0.57960

Epoch 00027: val_loss did not improve from 0.57960
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8178906353295006 0.7485531829974057 0.5095131256565227 0.761137789397571 0.7485312694642638 0.7454757862045946 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7529707994501613 0.6971326164874552 0.40933225729834766 0.7124875373878365 0.6971326164874552 0.6915604486179388 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7439312983393526 0.6762383345297918 0.36046868193938736 0.6842430078064416 0.6763128926928215 0.6727411857918345 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 200)               77200     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62421, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62421 to 0.60356, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60356 to 0.59667, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.59667

Epoch 00005: val_loss improved from 0.59667 to 0.58589, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.58589

Epoch 00007: val_loss did not improve from 0.58589

Epoch 00008: val_loss did not improve from 0.58589

Epoch 00009: val_loss did not improve from 0.58589

Epoch 00010: val_loss did not improve from 0.58589

Epoch 00011: val_loss improved from 0.58589 to 0.58451, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.58451 to 0.58254, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss improved from 0.58254 to 0.58044, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.58044 to 0.57887, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57887

Epoch 00016: val_loss did not improve from 0.57887

Epoch 00017: val_loss improved from 0.57887 to 0.57455, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.57455

Epoch 00019: val_loss did not improve from 0.57455

Epoch 00020: val_loss improved from 0.57455 to 0.57410, saving model to 1_200_best_model.hdf5

Epoch 00021: val_loss improved from 0.57410 to 0.57222, saving model to 1_200_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.57222

Epoch 00023: val_loss improved from 0.57222 to 0.56954, saving model to 1_200_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.56954

Epoch 00025: val_loss did not improve from 0.56954

Epoch 00026: val_loss did not improve from 0.56954

Epoch 00027: val_loss improved from 0.56954 to 0.56731, saving model to 1_200_best_model.hdf5

Epoch 00028: val_loss improved from 0.56731 to 0.56356, saving model to 1_200_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.56356

Epoch 00030: val_loss did not improve from 0.56356

Epoch 00031: val_loss did not improve from 0.56356

Epoch 00032: val_loss did not improve from 0.56356

Epoch 00033: val_loss did not improve from 0.56356

Epoch 00034: val_loss did not improve from 0.56356

Epoch 00035: val_loss did not improve from 0.56356

Epoch 00036: val_loss did not improve from 0.56356
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8231516217365746 0.7473558172021553 0.5059670423505787 0.758761187721738 0.7473348594112652 0.7445302087692559 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7639932683290297 0.7060931899641577 0.41953762454838456 0.7135099884211507 0.7060931899641577 0.7035184345234239 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7385531588581606 0.6805455850681982 0.3631386720459222 0.6825610183054915 0.6805830406174245 0.6796898615951821 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 200)               77200     
_________________________________________________________________
activation_9 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63852, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63852 to 0.60892, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60892 to 0.60758, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.60758 to 0.60206, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.60206 to 0.59875, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59875

Epoch 00007: val_loss did not improve from 0.59875

Epoch 00008: val_loss did not improve from 0.59875

Epoch 00009: val_loss improved from 0.59875 to 0.59784, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.59784 to 0.59320, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59320

Epoch 00012: val_loss did not improve from 0.59320

Epoch 00013: val_loss did not improve from 0.59320

Epoch 00014: val_loss improved from 0.59320 to 0.59270, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.59270 to 0.59258, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59258

Epoch 00017: val_loss did not improve from 0.59258

Epoch 00018: val_loss did not improve from 0.59258

Epoch 00019: val_loss did not improve from 0.59258

Epoch 00020: val_loss did not improve from 0.59258

Epoch 00021: val_loss did not improve from 0.59258

Epoch 00022: val_loss did not improve from 0.59258

Epoch 00023: val_loss did not improve from 0.59258
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7994915156537319 0.7218675179569034 0.4453618666658085 0.7234973308695206 0.7218675179569034 0.7213595344532987 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7273664939016529 0.6535008976660682 0.3083318485129832 0.6549227924901699 0.6534127536680333 0.6526230753073853 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7413648806873464 0.6791098348887293 0.3699223986965056 0.6909088713006966 0.6791988241890532 0.6741418153558729 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 200)               77200     
_________________________________________________________________
activation_11 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65805, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.65805 to 0.61994, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61994 to 0.61738, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.61738 to 0.61098, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.61098 to 0.60886, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60886

Epoch 00007: val_loss improved from 0.60886 to 0.60756, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss improved from 0.60756 to 0.60022, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss improved from 0.60022 to 0.59876, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59876

Epoch 00011: val_loss did not improve from 0.59876

Epoch 00012: val_loss improved from 0.59876 to 0.59681, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59681

Epoch 00014: val_loss improved from 0.59681 to 0.58915, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.58915 to 0.58658, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.58658

Epoch 00017: val_loss did not improve from 0.58658

Epoch 00018: val_loss did not improve from 0.58658

Epoch 00019: val_loss did not improve from 0.58658

Epoch 00020: val_loss did not improve from 0.58658

Epoch 00021: val_loss did not improve from 0.58658

Epoch 00022: val_loss did not improve from 0.58658

Epoch 00023: val_loss did not improve from 0.58658
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7988093832082618 0.7326949930181528 0.4806971035220121 0.7482805183158303 0.7326699924966678 0.7284193173203062 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.756806065938616 0.6834532374100719 0.3806394141919142 0.6974431818181819 0.6834532374100719 0.6777448462095765 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7325998944573624 0.6812634601579325 0.37451153310108576 0.6933506955891079 0.6813529659130262 0.6762703347779662 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 200)               77200     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62120, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62120 to 0.60356, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60356 to 0.59874, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.59874 to 0.59195, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59195

Epoch 00006: val_loss did not improve from 0.59195

Epoch 00007: val_loss improved from 0.59195 to 0.58594, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss improved from 0.58594 to 0.58316, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.58316

Epoch 00010: val_loss did not improve from 0.58316

Epoch 00011: val_loss did not improve from 0.58316

Epoch 00012: val_loss improved from 0.58316 to 0.57899, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.57899

Epoch 00014: val_loss did not improve from 0.57899

Epoch 00015: val_loss did not improve from 0.57899

Epoch 00016: val_loss did not improve from 0.57899

Epoch 00017: val_loss did not improve from 0.57899

Epoch 00018: val_loss did not improve from 0.57899

Epoch 00019: val_loss did not improve from 0.57899

Epoch 00020: val_loss improved from 0.57899 to 0.57446, saving model to 1_200_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.57446

Epoch 00022: val_loss did not improve from 0.57446

Epoch 00023: val_loss did not improve from 0.57446

Epoch 00024: val_loss did not improve from 0.57446

Epoch 00025: val_loss did not improve from 0.57446

Epoch 00026: val_loss did not improve from 0.57446

Epoch 00027: val_loss did not improve from 0.57446

Epoch 00028: val_loss did not improve from 0.57446
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8184682251228881 0.7356872132455615 0.4948290380133618 0.7597588256038571 0.735656840813798 0.7294020611433667 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7598726773976502 0.6960431654676259 0.4032641695540007 0.7073803364404112 0.6960431654676259 0.6918313868637078 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7330245386632366 0.6798277099784638 0.3628949384839616 0.6830337290766455 0.6798749567110276 0.678455496623482 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 200)               77200     
_________________________________________________________________
activation_15 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62276, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62276 to 0.60266, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60266 to 0.59417, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.59417 to 0.58575, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.58575 to 0.57991, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.57991

Epoch 00007: val_loss did not improve from 0.57991

Epoch 00008: val_loss improved from 0.57991 to 0.57921, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss improved from 0.57921 to 0.57134, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.57134 to 0.57027, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.57027

Epoch 00012: val_loss improved from 0.57027 to 0.56799, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss improved from 0.56799 to 0.56495, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.56495

Epoch 00015: val_loss improved from 0.56495 to 0.56381, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss improved from 0.56381 to 0.55381, saving model to 1_200_best_model.hdf5

Epoch 00017: val_loss improved from 0.55381 to 0.55155, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.55155

Epoch 00019: val_loss did not improve from 0.55155

Epoch 00020: val_loss did not improve from 0.55155

Epoch 00021: val_loss did not improve from 0.55155

Epoch 00022: val_loss did not improve from 0.55155

Epoch 00023: val_loss did not improve from 0.55155

Epoch 00024: val_loss improved from 0.55155 to 0.54250, saving model to 1_200_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.54250

Epoch 00026: val_loss did not improve from 0.54250

Epoch 00027: val_loss did not improve from 0.54250

Epoch 00028: val_loss did not improve from 0.54250

Epoch 00029: val_loss did not improve from 0.54250

Epoch 00030: val_loss improved from 0.54250 to 0.54015, saving model to 1_200_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.54015

Epoch 00032: val_loss improved from 0.54015 to 0.53576, saving model to 1_200_best_model.hdf5

Epoch 00033: val_loss improved from 0.53576 to 0.53106, saving model to 1_200_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.53106

Epoch 00035: val_loss did not improve from 0.53106

Epoch 00036: val_loss did not improve from 0.53106

Epoch 00037: val_loss did not improve from 0.53106

Epoch 00038: val_loss did not improve from 0.53106

Epoch 00039: val_loss did not improve from 0.53106

Epoch 00040: val_loss did not improve from 0.53106

Epoch 00041: val_loss did not improve from 0.53106
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8615499108481885 0.7761819269898265 0.5534312284649119 0.7772565735332891 0.7761757104051195 0.7759621788355708 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.796866104238911 0.7284172661870504 0.4597015886642004 0.7312933191829462 0.7284172661870504 0.7275703739758255 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7428026929863619 0.6913137114142139 0.3995751319790178 0.7085245850100603 0.6914166213163147 0.6848827470686767 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 200)               77200     
_________________________________________________________________
activation_17 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62520, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62520 to 0.58386, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.58386 to 0.58262, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.58262

Epoch 00005: val_loss improved from 0.58262 to 0.57302, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.57302

Epoch 00007: val_loss did not improve from 0.57302

Epoch 00008: val_loss improved from 0.57302 to 0.55804, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.55804

Epoch 00010: val_loss did not improve from 0.55804

Epoch 00011: val_loss did not improve from 0.55804

Epoch 00012: val_loss improved from 0.55804 to 0.55597, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.55597

Epoch 00014: val_loss did not improve from 0.55597

Epoch 00015: val_loss did not improve from 0.55597

Epoch 00016: val_loss did not improve from 0.55597

Epoch 00017: val_loss did not improve from 0.55597

Epoch 00018: val_loss did not improve from 0.55597

Epoch 00019: val_loss did not improve from 0.55597

Epoch 00020: val_loss did not improve from 0.55597
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7875880495506438 0.7191302613205666 0.44722741465858723 0.7282096179038541 0.7191103537389801 0.7162966221378464 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7824905543191347 0.7248201438848921 0.45413129550525067 0.7293335797156923 0.7248201438848921 0.7234595192042002 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7300468757730173 0.6712132089016511 0.3447686138624116 0.6736064360472167 0.6711707811804284 0.6700417882041416 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 200)               77200     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 77,401
Trainable params: 77,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63611, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63611 to 0.61514, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61514 to 0.59854, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.59854 to 0.59735, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59735

Epoch 00006: val_loss improved from 0.59735 to 0.59725, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.59725 to 0.58730, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.58730

Epoch 00009: val_loss did not improve from 0.58730

Epoch 00010: val_loss improved from 0.58730 to 0.58665, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58665

Epoch 00012: val_loss did not improve from 0.58665

Epoch 00013: val_loss improved from 0.58665 to 0.58475, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58475

Epoch 00015: val_loss did not improve from 0.58475

Epoch 00016: val_loss did not improve from 0.58475

Epoch 00017: val_loss improved from 0.58475 to 0.58340, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58340

Epoch 00019: val_loss did not improve from 0.58340

Epoch 00020: val_loss did not improve from 0.58340

Epoch 00021: val_loss did not improve from 0.58340

Epoch 00022: val_loss did not improve from 0.58340

Epoch 00023: val_loss did not improve from 0.58340

Epoch 00024: val_loss did not improve from 0.58340

Epoch 00025: val_loss did not improve from 0.58340
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8001711727514117 0.7237183323359266 0.46382848065286614 0.7404386856368563 0.7236920182945057 0.7188147542162064 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7546969618549764 0.6888489208633094 0.38989836912784803 0.7012465011099926 0.6888489208633094 0.6839819301848049 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7240328006728343 0.6604450825556353 0.3308930216727815 0.6705114731126292 0.6605320008575339 0.6554333302827857 None
average testing metrics
[0.73731097 0.67788945 0.36323126 0.68538936 0.67794829 0.67471149]
std testing metrics
[0.00687958 0.00757043 0.01727658 0.01025085 0.00758181 0.0075261 ]
End of this run.
########################################################################################################
(5569, 386)
(5569, 385)
class labels
{0.0, 1.0}
(1393, 386)
(1393, 385)
(1393,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_2 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66877, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66877 to 0.64715, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64715 to 0.62903, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62903 to 0.61657, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61657 to 0.61596, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.61596 to 0.61066, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.61066 to 0.60760, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.60760 to 0.60368, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.60368

Epoch 00010: val_loss improved from 0.60368 to 0.59821, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.59821 to 0.59741, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59741 to 0.59732, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.59732 to 0.58916, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.58916

Epoch 00015: val_loss did not improve from 0.58916

Epoch 00016: val_loss did not improve from 0.58916

Epoch 00017: val_loss did not improve from 0.58916

Epoch 00018: val_loss did not improve from 0.58916

Epoch 00019: val_loss did not improve from 0.58916

Epoch 00020: val_loss improved from 0.58916 to 0.58898, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.58898 to 0.58654, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.58654 to 0.58568, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.58568

Epoch 00024: val_loss improved from 0.58568 to 0.58032, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.58032

Epoch 00026: val_loss did not improve from 0.58032

Epoch 00027: val_loss did not improve from 0.58032

Epoch 00028: val_loss did not improve from 0.58032

Epoch 00029: val_loss did not improve from 0.58032

Epoch 00030: val_loss did not improve from 0.58032

Epoch 00031: val_loss did not improve from 0.58032

Epoch 00032: val_loss did not improve from 0.58032
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7892547705865206 0.7150269407303932 0.46016822052803924 0.7462363441242378 0.7149914058554878 0.7056799022336993 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7604540023894861 0.6577060931899642 0.33736538456737314 0.6804232804232804 0.6577060931899641 0.646581311367774 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7229856198156303 0.6460875807609476 0.33722431032847433 0.6943720038350911 0.646266223057768 0.6228172939140445 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_4 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65570, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65570 to 0.63695, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63695 to 0.61959, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61959 to 0.59826, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59826

Epoch 00006: val_loss did not improve from 0.59826

Epoch 00007: val_loss did not improve from 0.59826

Epoch 00008: val_loss did not improve from 0.59826

Epoch 00009: val_loss improved from 0.59826 to 0.59803, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59803

Epoch 00011: val_loss improved from 0.59803 to 0.59626, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59626 to 0.59484, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59484

Epoch 00014: val_loss did not improve from 0.59484

Epoch 00015: val_loss did not improve from 0.59484

Epoch 00016: val_loss improved from 0.59484 to 0.58759, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.58759

Epoch 00018: val_loss did not improve from 0.58759

Epoch 00019: val_loss improved from 0.58759 to 0.58696, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.58696

Epoch 00021: val_loss did not improve from 0.58696

Epoch 00022: val_loss improved from 0.58696 to 0.57779, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.57779

Epoch 00024: val_loss did not improve from 0.57779

Epoch 00025: val_loss did not improve from 0.57779

Epoch 00026: val_loss improved from 0.57779 to 0.57351, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.57351

Epoch 00028: val_loss did not improve from 0.57351

Epoch 00029: val_loss did not improve from 0.57351

Epoch 00030: val_loss did not improve from 0.57351

Epoch 00031: val_loss did not improve from 0.57351

Epoch 00032: val_loss did not improve from 0.57351

Epoch 00033: val_loss improved from 0.57351 to 0.57194, saving model to 2_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.57194

Epoch 00035: val_loss did not improve from 0.57194

Epoch 00036: val_loss did not improve from 0.57194

Epoch 00037: val_loss did not improve from 0.57194

Epoch 00038: val_loss did not improve from 0.57194

Epoch 00039: val_loss did not improve from 0.57194

Epoch 00040: val_loss did not improve from 0.57194

Epoch 00041: val_loss did not improve from 0.57194
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.766247552779517 0.7337856715226502 0.4958143613870343 0.7629190452129851 0.7337524472204833 0.7261826700117839 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7275214861062936 0.7043010752688172 0.43578796756807103 0.732391278933832 0.7043010752688172 0.6950870162772599 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.6971256122297531 0.6719310839913855 0.37445270545302634 0.7037145953016629 0.6720726347730008 0.6587272357860867 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                19300     
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_8 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67098, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.67098 to 0.63441, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63441 to 0.62800, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62800 to 0.62586, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62586 to 0.62545, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.62545 to 0.62532, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.62532

Epoch 00008: val_loss did not improve from 0.62532

Epoch 00009: val_loss improved from 0.62532 to 0.61534, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.61534 to 0.61488, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.61488

Epoch 00012: val_loss improved from 0.61488 to 0.61156, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.61156

Epoch 00014: val_loss did not improve from 0.61156

Epoch 00015: val_loss improved from 0.61156 to 0.60902, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.60902

Epoch 00017: val_loss did not improve from 0.60902

Epoch 00018: val_loss did not improve from 0.60902

Epoch 00019: val_loss did not improve from 0.60902

Epoch 00020: val_loss did not improve from 0.60902

Epoch 00021: val_loss improved from 0.60902 to 0.60814, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.60814 to 0.60241, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss improved from 0.60241 to 0.60209, saving model to 2_50_best_model.hdf5

Epoch 00024: val_loss improved from 0.60209 to 0.60054, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss improved from 0.60054 to 0.59744, saving model to 2_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.59744 to 0.59659, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.59659 to 0.59585, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.59585

Epoch 00029: val_loss did not improve from 0.59585

Epoch 00030: val_loss did not improve from 0.59585

Epoch 00031: val_loss did not improve from 0.59585

Epoch 00032: val_loss did not improve from 0.59585

Epoch 00033: val_loss did not improve from 0.59585

Epoch 00034: val_loss improved from 0.59585 to 0.59516, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss improved from 0.59516 to 0.59218, saving model to 2_50_best_model.hdf5

Epoch 00036: val_loss improved from 0.59218 to 0.59212, saving model to 2_50_best_model.hdf5

Epoch 00037: val_loss did not improve from 0.59212

Epoch 00038: val_loss did not improve from 0.59212

Epoch 00039: val_loss did not improve from 0.59212

Epoch 00040: val_loss did not improve from 0.59212

Epoch 00041: val_loss improved from 0.59212 to 0.59050, saving model to 2_50_best_model.hdf5

Epoch 00042: val_loss did not improve from 0.59050

Epoch 00043: val_loss did not improve from 0.59050

Epoch 00044: val_loss improved from 0.59050 to 0.58940, saving model to 2_50_best_model.hdf5

Epoch 00045: val_loss did not improve from 0.58940

Epoch 00046: val_loss improved from 0.58940 to 0.58663, saving model to 2_50_best_model.hdf5

Epoch 00047: val_loss did not improve from 0.58663

Epoch 00048: val_loss did not improve from 0.58663

Epoch 00049: val_loss did not improve from 0.58663

Epoch 00050: val_loss did not improve from 0.58663

Epoch 00051: val_loss did not improve from 0.58663

Epoch 00052: val_loss did not improve from 0.58663

Epoch 00053: val_loss did not improve from 0.58663

Epoch 00054: val_loss improved from 0.58663 to 0.58227, saving model to 2_50_best_model.hdf5

Epoch 00055: val_loss did not improve from 0.58227

Epoch 00056: val_loss did not improve from 0.58227

Epoch 00057: val_loss did not improve from 0.58227

Epoch 00058: val_loss did not improve from 0.58227

Epoch 00059: val_loss did not improve from 0.58227

Epoch 00060: val_loss did not improve from 0.58227

Epoch 00061: val_loss did not improve from 0.58227

Epoch 00062: val_loss did not improve from 0.58227
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7889220760394613 0.7437637198164039 0.5048977189477046 0.7614713076752451 0.7437377439852936 0.7393372601333219 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.727110391695893 0.6881720430107527 0.3937336973016059 0.7059634124049102 0.6881720430107527 0.6812893907563025 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7174240175464635 0.6798277099784638 0.37807609509789064 0.6985985029463291 0.6799378287900526 0.6721626527639994 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_10 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66164, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66164 to 0.64802, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64802 to 0.61427, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61427 to 0.59880, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59880

Epoch 00006: val_loss improved from 0.59880 to 0.59522, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.59522 to 0.58714, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.58714 to 0.58586, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.58586 to 0.57929, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.57929

Epoch 00011: val_loss did not improve from 0.57929

Epoch 00012: val_loss did not improve from 0.57929

Epoch 00013: val_loss did not improve from 0.57929

Epoch 00014: val_loss did not improve from 0.57929

Epoch 00015: val_loss did not improve from 0.57929

Epoch 00016: val_loss did not improve from 0.57929

Epoch 00017: val_loss did not improve from 0.57929
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7646107625132815 0.7022550389143883 0.40750650028195684 0.7052748588881469 0.7022429203842913 0.7011478870289342 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7521999974306599 0.6863799283154122 0.37645594372799346 0.6900943396226416 0.6863799283154122 0.6848403869056264 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7144947970777882 0.6417803302225413 0.2891087086403689 0.6474562746940193 0.6417095433631821 0.6382298370203054 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_14 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64941, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64941 to 0.62911, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62911 to 0.62090, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62090 to 0.60571, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60571

Epoch 00006: val_loss did not improve from 0.60571

Epoch 00007: val_loss improved from 0.60571 to 0.60455, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60455

Epoch 00009: val_loss improved from 0.60455 to 0.60219, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60219

Epoch 00011: val_loss improved from 0.60219 to 0.59842, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59842 to 0.59162, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59162

Epoch 00014: val_loss did not improve from 0.59162

Epoch 00015: val_loss improved from 0.59162 to 0.59027, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.59027 to 0.58907, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.58907

Epoch 00018: val_loss did not improve from 0.58907

Epoch 00019: val_loss did not improve from 0.58907

Epoch 00020: val_loss did not improve from 0.58907

Epoch 00021: val_loss did not improve from 0.58907

Epoch 00022: val_loss improved from 0.58907 to 0.58901, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.58901

Epoch 00024: val_loss did not improve from 0.58901

Epoch 00025: val_loss did not improve from 0.58901

Epoch 00026: val_loss did not improve from 0.58901

Epoch 00027: val_loss improved from 0.58901 to 0.58332, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss improved from 0.58332 to 0.58303, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.58303

Epoch 00030: val_loss improved from 0.58303 to 0.58296, saving model to 2_50_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.58296

Epoch 00032: val_loss did not improve from 0.58296

Epoch 00033: val_loss improved from 0.58296 to 0.58255, saving model to 2_50_best_model.hdf5

Epoch 00034: val_loss improved from 0.58255 to 0.58166, saving model to 2_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.58166

Epoch 00036: val_loss did not improve from 0.58166

Epoch 00037: val_loss did not improve from 0.58166

Epoch 00038: val_loss did not improve from 0.58166

Epoch 00039: val_loss did not improve from 0.58166

Epoch 00040: val_loss did not improve from 0.58166

Epoch 00041: val_loss did not improve from 0.58166

Epoch 00042: val_loss did not improve from 0.58166
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7993708953260779 0.7011173184357542 0.4380136975468537 0.738487665720287 0.7011173184357542 0.6889314254841714 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7396340991722751 0.6499102333931778 0.3349479351054519 0.6876011130524817 0.6495062014904206 0.6310293403267284 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.6918897079437326 0.6518305814788227 0.32274549654746226 0.6713781206262409 0.6519515081053447 0.6417205769974221 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_16 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65360, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65360 to 0.62671, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.62671

Epoch 00004: val_loss improved from 0.62671 to 0.61499, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61499

Epoch 00006: val_loss improved from 0.61499 to 0.61446, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.61446 to 0.61202, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61202

Epoch 00009: val_loss improved from 0.61202 to 0.60673, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60673

Epoch 00011: val_loss improved from 0.60673 to 0.60142, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.60142

Epoch 00013: val_loss did not improve from 0.60142

Epoch 00014: val_loss improved from 0.60142 to 0.59827, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.59827 to 0.59793, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.59793 to 0.59163, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59163

Epoch 00018: val_loss did not improve from 0.59163

Epoch 00019: val_loss did not improve from 0.59163

Epoch 00020: val_loss improved from 0.59163 to 0.58936, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.58936

Epoch 00022: val_loss did not improve from 0.58936

Epoch 00023: val_loss did not improve from 0.58936

Epoch 00024: val_loss did not improve from 0.58936

Epoch 00025: val_loss improved from 0.58936 to 0.58857, saving model to 2_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.58857

Epoch 00027: val_loss did not improve from 0.58857

Epoch 00028: val_loss improved from 0.58857 to 0.58334, saving model to 2_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.58334

Epoch 00030: val_loss did not improve from 0.58334

Epoch 00031: val_loss did not improve from 0.58334

Epoch 00032: val_loss did not improve from 0.58334

Epoch 00033: val_loss did not improve from 0.58334

Epoch 00034: val_loss did not improve from 0.58334

Epoch 00035: val_loss did not improve from 0.58334

Epoch 00036: val_loss did not improve from 0.58334
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7922115761422686 0.7354877318970676 0.47099451173306733 0.735505915238265 0.7354885968132008 0.7354830899880811 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7479814709383572 0.6942446043165468 0.388740791511612 0.6944962686567164 0.6942446043165468 0.6941456658771146 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.737860535299065 0.6755204594400575 0.35213652267114554 0.676589942975635 0.67554812084632 0.6750500608988255 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_20 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66327, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66327 to 0.64664, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64664 to 0.62177, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62177 to 0.59942, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.59942 to 0.59473, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59473 to 0.58360, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.58360

Epoch 00008: val_loss improved from 0.58360 to 0.58156, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.58156 to 0.57847, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.57847

Epoch 00011: val_loss did not improve from 0.57847

Epoch 00012: val_loss did not improve from 0.57847

Epoch 00013: val_loss improved from 0.57847 to 0.57247, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.57247 to 0.57147, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57147

Epoch 00016: val_loss did not improve from 0.57147

Epoch 00017: val_loss did not improve from 0.57147

Epoch 00018: val_loss did not improve from 0.57147

Epoch 00019: val_loss did not improve from 0.57147

Epoch 00020: val_loss improved from 0.57147 to 0.57056, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.57056 to 0.56932, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.56932 to 0.56779, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.56779

Epoch 00024: val_loss improved from 0.56779 to 0.56455, saving model to 2_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.56455

Epoch 00026: val_loss did not improve from 0.56455

Epoch 00027: val_loss did not improve from 0.56455

Epoch 00028: val_loss did not improve from 0.56455

Epoch 00029: val_loss did not improve from 0.56455

Epoch 00030: val_loss did not improve from 0.56455

Epoch 00031: val_loss did not improve from 0.56455

Epoch 00032: val_loss did not improve from 0.56455
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7797586550157564 0.7089567125473768 0.4341158864166626 0.7255024290383729 0.7089296816479699 0.703501074620895 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7581129341131412 0.7158273381294964 0.44136741475237473 0.7256493506493507 0.7158273381294964 0.712700966733383 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7262580599943931 0.6683417085427136 0.3368082938732361 0.6684770947323249 0.6683312307261005 0.6682663164275612 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_22 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_23 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_23 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64433, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64433 to 0.60714, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.60714 to 0.60227, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.60227 to 0.60026, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.60026 to 0.59626, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59626 to 0.58454, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.58454

Epoch 00008: val_loss did not improve from 0.58454

Epoch 00009: val_loss did not improve from 0.58454

Epoch 00010: val_loss did not improve from 0.58454

Epoch 00011: val_loss improved from 0.58454 to 0.58120, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58120

Epoch 00013: val_loss improved from 0.58120 to 0.57822, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.57822 to 0.57475, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57475

Epoch 00016: val_loss did not improve from 0.57475

Epoch 00017: val_loss improved from 0.57475 to 0.56359, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.56359

Epoch 00019: val_loss did not improve from 0.56359

Epoch 00020: val_loss did not improve from 0.56359

Epoch 00021: val_loss improved from 0.56359 to 0.56151, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.56151

Epoch 00023: val_loss did not improve from 0.56151

Epoch 00024: val_loss did not improve from 0.56151

Epoch 00025: val_loss did not improve from 0.56151

Epoch 00026: val_loss did not improve from 0.56151

Epoch 00027: val_loss did not improve from 0.56151

Epoch 00028: val_loss did not improve from 0.56151

Epoch 00029: val_loss did not improve from 0.56151
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7790637929678782 0.6886096150009974 0.40366679162382 0.7160250355566902 0.6885740676305865 0.6783808906958069 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7652295429843174 0.7014388489208633 0.43442190636561645 0.7342179695492568 0.7014388489208634 0.6906141056583535 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7314084170253468 0.6575735821966978 0.3427493939994799 0.6862185291196916 0.6577140948894276 0.6440002893169708 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_25 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_26 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_26 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66719, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66719 to 0.62763, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62763 to 0.61064, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61064 to 0.60407, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.60407 to 0.60114, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.60114 to 0.59182, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.59182 to 0.57932, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.57932

Epoch 00009: val_loss did not improve from 0.57932

Epoch 00010: val_loss did not improve from 0.57932

Epoch 00011: val_loss did not improve from 0.57932

Epoch 00012: val_loss did not improve from 0.57932

Epoch 00013: val_loss improved from 0.57932 to 0.57023, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.57023

Epoch 00015: val_loss did not improve from 0.57023

Epoch 00016: val_loss did not improve from 0.57023

Epoch 00017: val_loss did not improve from 0.57023

Epoch 00018: val_loss did not improve from 0.57023

Epoch 00019: val_loss did not improve from 0.57023

Epoch 00020: val_loss improved from 0.57023 to 0.56651, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.56651

Epoch 00022: val_loss did not improve from 0.56651

Epoch 00023: val_loss did not improve from 0.56651

Epoch 00024: val_loss did not improve from 0.56651

Epoch 00025: val_loss did not improve from 0.56651

Epoch 00026: val_loss improved from 0.56651 to 0.56504, saving model to 2_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.56504

Epoch 00028: val_loss did not improve from 0.56504

Epoch 00029: val_loss did not improve from 0.56504

Epoch 00030: val_loss did not improve from 0.56504

Epoch 00031: val_loss did not improve from 0.56504

Epoch 00032: val_loss did not improve from 0.56504

Epoch 00033: val_loss did not improve from 0.56504

Epoch 00034: val_loss did not improve from 0.56504
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7690073540296268 0.6963893875922601 0.41214697330581324 0.7162684325289761 0.6963591329751555 0.6892276859220021 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7716215516795196 0.6888489208633094 0.3957476935481076 0.7073300660558279 0.6888489208633093 0.6817569736010614 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7260735665165983 0.6575735821966978 0.3577792361344277 0.7028711558854719 0.6577429542043899 0.6374741183884247 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 50)                19300     
_________________________________________________________________
activation_28 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_29 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_29 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,901
Trainable params: 21,901
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64112, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64112 to 0.63204, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63204 to 0.61479, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61479 to 0.59743, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59743

Epoch 00006: val_loss improved from 0.59743 to 0.59273, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59273

Epoch 00008: val_loss improved from 0.59273 to 0.59072, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59072

Epoch 00010: val_loss improved from 0.59072 to 0.57783, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.57783

Epoch 00012: val_loss did not improve from 0.57783

Epoch 00013: val_loss improved from 0.57783 to 0.57287, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.57287 to 0.57237, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.57237

Epoch 00016: val_loss did not improve from 0.57237

Epoch 00017: val_loss improved from 0.57237 to 0.56792, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.56792

Epoch 00019: val_loss did not improve from 0.56792

Epoch 00020: val_loss did not improve from 0.56792

Epoch 00021: val_loss did not improve from 0.56792

Epoch 00022: val_loss did not improve from 0.56792

Epoch 00023: val_loss improved from 0.56792 to 0.56705, saving model to 2_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.56705

Epoch 00025: val_loss did not improve from 0.56705

Epoch 00026: val_loss did not improve from 0.56705

Epoch 00027: val_loss did not improve from 0.56705

Epoch 00028: val_loss did not improve from 0.56705

Epoch 00029: val_loss improved from 0.56705 to 0.56065, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.56065

Epoch 00031: val_loss did not improve from 0.56065

Epoch 00032: val_loss did not improve from 0.56065

Epoch 00033: val_loss improved from 0.56065 to 0.55589, saving model to 2_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.55589

Epoch 00035: val_loss did not improve from 0.55589

Epoch 00036: val_loss did not improve from 0.55589

Epoch 00037: val_loss did not improve from 0.55589

Epoch 00038: val_loss did not improve from 0.55589

Epoch 00039: val_loss did not improve from 0.55589

Epoch 00040: val_loss improved from 0.55589 to 0.55005, saving model to 2_50_best_model.hdf5

Epoch 00041: val_loss did not improve from 0.55005

Epoch 00042: val_loss did not improve from 0.55005

Epoch 00043: val_loss did not improve from 0.55005

Epoch 00044: val_loss did not improve from 0.55005

Epoch 00045: val_loss did not improve from 0.55005

Epoch 00046: val_loss did not improve from 0.55005

Epoch 00047: val_loss did not improve from 0.55005

Epoch 00048: val_loss did not improve from 0.55005
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8055127208063233 0.7408737283064033 0.4990636903083075 0.7585291606055293 0.7408476537045037 0.7363590676908625 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7826070079188447 0.7158273381294964 0.44136741475237473 0.7256493506493507 0.7158273381294964 0.712700966733383 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7387314681970348 0.6855707106963388 0.38493012280169653 0.6995137781321992 0.6856653721202526 0.6800488735998658 None
average testing metrics
[0.72042518 0.66360373 0.34760109 0.684919   0.66369395 0.65384973]
std testing metrics
[0.01494505 0.01404983 0.02730241 0.01758766 0.01405323 0.01849898]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.79541, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.79541 to 0.74778, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.74778 to 0.69728, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.69728 to 0.67243, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.67243 to 0.66384, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.66384 to 0.65515, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.65515 to 0.65062, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.65062 to 0.64475, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.64475 to 0.63815, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.63815 to 0.63276, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.63276

Epoch 00012: val_loss did not improve from 0.63276

Epoch 00013: val_loss improved from 0.63276 to 0.63047, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.63047

Epoch 00015: val_loss improved from 0.63047 to 0.62469, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.62469 to 0.62429, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.62429

Epoch 00018: val_loss improved from 0.62429 to 0.62169, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.62169

Epoch 00020: val_loss improved from 0.62169 to 0.62085, saving model to 1_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.62085

Epoch 00022: val_loss did not improve from 0.62085

Epoch 00023: val_loss did not improve from 0.62085

Epoch 00024: val_loss did not improve from 0.62085

Epoch 00025: val_loss did not improve from 0.62085

Epoch 00026: val_loss did not improve from 0.62085

Epoch 00027: val_loss improved from 0.62085 to 0.62077, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.62077

Epoch 00029: val_loss did not improve from 0.62077

Epoch 00030: val_loss did not improve from 0.62077

Epoch 00031: val_loss did not improve from 0.62077

Epoch 00032: val_loss did not improve from 0.62077

Epoch 00033: val_loss did not improve from 0.62077

Epoch 00034: val_loss did not improve from 0.62077

Epoch 00035: val_loss did not improve from 0.62077
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7917999913830716 0.7209347614410906 0.44309258357853987 0.7225019563365872 0.7205947319012647 0.7202285057206083 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6873410602503912 0.6503496503496503 0.30296432991758876 0.6531387445021991 0.6498435054773083 0.6482683982683983 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.704649836813338 0.6601261387526279 0.341736547030607 0.6775870637256776 0.6644036805473634 0.6549966526308129 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.68289, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.68289 to 0.66524, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.66524 to 0.64962, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.64962 to 0.64815, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.64815 to 0.62654, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.62654 to 0.62411, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.62411 to 0.61968, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.61968 to 0.61817, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.61817 to 0.60720, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60720

Epoch 00011: val_loss improved from 0.60720 to 0.60375, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.60375 to 0.60314, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.60314 to 0.59562, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.59562 to 0.59260, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss improved from 0.59260 to 0.59234, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59234

Epoch 00017: val_loss improved from 0.59234 to 0.59027, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.59027

Epoch 00019: val_loss improved from 0.59027 to 0.59020, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.59020

Epoch 00021: val_loss improved from 0.59020 to 0.58942, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.58942

Epoch 00023: val_loss improved from 0.58942 to 0.57940, saving model to 1_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.57940

Epoch 00025: val_loss did not improve from 0.57940

Epoch 00026: val_loss did not improve from 0.57940

Epoch 00027: val_loss did not improve from 0.57940

Epoch 00028: val_loss improved from 0.57940 to 0.57741, saving model to 1_50_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.57741

Epoch 00030: val_loss did not improve from 0.57741

Epoch 00031: val_loss did not improve from 0.57741

Epoch 00032: val_loss did not improve from 0.57741

Epoch 00033: val_loss did not improve from 0.57741

Epoch 00034: val_loss did not improve from 0.57741

Epoch 00035: val_loss did not improve from 0.57741

Epoch 00036: val_loss did not improve from 0.57741
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7824147455063022 0.7148977604673807 0.4420123848354166 0.72828621209188 0.7139583316898463 0.7100644167595883 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.729985817683881 0.6800699300699301 0.37501558657265033 0.6963766075283957 0.6790395148669797 0.6724934687045351 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7084188588730289 0.6587245970567625 0.3447942623899116 0.6816285200509785 0.6636349337422831 0.6516045165394722 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65220, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65220 to 0.63082, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63082 to 0.62017, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62017 to 0.61407, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61407 to 0.60695, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.60695 to 0.60633, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60633

Epoch 00008: val_loss did not improve from 0.60633

Epoch 00009: val_loss improved from 0.60633 to 0.60413, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.60413 to 0.60115, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60115

Epoch 00012: val_loss did not improve from 0.60115

Epoch 00013: val_loss did not improve from 0.60115

Epoch 00014: val_loss did not improve from 0.60115

Epoch 00015: val_loss improved from 0.60115 to 0.59778, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59778

Epoch 00017: val_loss did not improve from 0.59778

Epoch 00018: val_loss did not improve from 0.59778

Epoch 00019: val_loss did not improve from 0.59778

Epoch 00020: val_loss did not improve from 0.59778

Epoch 00021: val_loss did not improve from 0.59778

Epoch 00022: val_loss improved from 0.59778 to 0.59763, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59763

Epoch 00024: val_loss improved from 0.59763 to 0.59325, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.59325

Epoch 00026: val_loss improved from 0.59325 to 0.59173, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.59173

Epoch 00028: val_loss did not improve from 0.59173

Epoch 00029: val_loss did not improve from 0.59173

Epoch 00030: val_loss did not improve from 0.59173

Epoch 00031: val_loss did not improve from 0.59173

Epoch 00032: val_loss did not improve from 0.59173

Epoch 00033: val_loss did not improve from 0.59173

Epoch 00034: val_loss improved from 0.59173 to 0.59059, saving model to 1_50_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.59059

Epoch 00036: val_loss did not improve from 0.59059

Epoch 00037: val_loss did not improve from 0.59059

Epoch 00038: val_loss did not improve from 0.59059

Epoch 00039: val_loss did not improve from 0.59059

Epoch 00040: val_loss did not improve from 0.59059

Epoch 00041: val_loss did not improve from 0.59059

Epoch 00042: val_loss did not improve from 0.59059
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.797355595310651 0.7213785046728972 0.4583986983484184 0.7383786392414406 0.7203735277164408 0.715713740265056 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.725933696505693 0.6619964973730298 0.3324052192433171 0.6716667975601456 0.6609123478602277 0.6562226069595869 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7113807950926035 0.6510161177295024 0.3308667351037837 0.6752664680569347 0.6561519405450041 0.6429101192701487 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66488, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66488 to 0.62850, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62850 to 0.61915, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61915 to 0.61043, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61043 to 0.60756, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.60756 to 0.60603, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.60603 to 0.60073, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60073

Epoch 00009: val_loss did not improve from 0.60073

Epoch 00010: val_loss improved from 0.60073 to 0.59929, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59929

Epoch 00012: val_loss did not improve from 0.59929

Epoch 00013: val_loss did not improve from 0.59929

Epoch 00014: val_loss improved from 0.59929 to 0.59512, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59512

Epoch 00016: val_loss did not improve from 0.59512

Epoch 00017: val_loss did not improve from 0.59512

Epoch 00018: val_loss did not improve from 0.59512

Epoch 00019: val_loss did not improve from 0.59512

Epoch 00020: val_loss did not improve from 0.59512

Epoch 00021: val_loss did not improve from 0.59512

Epoch 00022: val_loss did not improve from 0.59512
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7493381747133834 0.6832165109034268 0.39512532863347655 0.7147188723222992 0.6817772509225064 0.6700760202071464 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7273262661955242 0.6777583187390543 0.3755692100368079 0.7000612745098038 0.6762612877895564 0.6673505572441742 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7068744838976053 0.6552207428170989 0.3282415760379611 0.6693082669010106 0.6590922496166096 0.6511044056961572 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_9 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65932, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65932 to 0.64189, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64189 to 0.63070, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.63070 to 0.62476, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.62476

Epoch 00006: val_loss improved from 0.62476 to 0.62223, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.62223 to 0.61669, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61669

Epoch 00009: val_loss improved from 0.61669 to 0.61558, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61558

Epoch 00011: val_loss did not improve from 0.61558

Epoch 00012: val_loss did not improve from 0.61558

Epoch 00013: val_loss did not improve from 0.61558

Epoch 00014: val_loss improved from 0.61558 to 0.61284, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.61284

Epoch 00016: val_loss did not improve from 0.61284

Epoch 00017: val_loss did not improve from 0.61284

Epoch 00018: val_loss did not improve from 0.61284

Epoch 00019: val_loss did not improve from 0.61284

Epoch 00020: val_loss did not improve from 0.61284

Epoch 00021: val_loss did not improve from 0.61284

Epoch 00022: val_loss improved from 0.61284 to 0.60938, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.60938

Epoch 00024: val_loss did not improve from 0.60938

Epoch 00025: val_loss did not improve from 0.60938

Epoch 00026: val_loss did not improve from 0.60938

Epoch 00027: val_loss did not improve from 0.60938

Epoch 00028: val_loss did not improve from 0.60938

Epoch 00029: val_loss did not improve from 0.60938

Epoch 00030: val_loss did not improve from 0.60938
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7757222452304374 0.7052180685358256 0.42990124823624254 0.7264150419584832 0.7040667016162383 0.6973911337932193 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7063334314880251 0.6409807355516638 0.29539465295663386 0.6563118403693932 0.6395575677267373 0.6305373628974986 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7195017891549683 0.6608269096005606 0.3394823728927247 0.6749778535492821 0.6646612402186308 0.6568825387993562 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65648, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65648 to 0.63751, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63751 to 0.63439, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.63439 to 0.62629, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62629 to 0.61879, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61879

Epoch 00007: val_loss improved from 0.61879 to 0.61511, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61511

Epoch 00009: val_loss improved from 0.61511 to 0.61127, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61127

Epoch 00011: val_loss did not improve from 0.61127

Epoch 00012: val_loss did not improve from 0.61127

Epoch 00013: val_loss did not improve from 0.61127

Epoch 00014: val_loss improved from 0.61127 to 0.60931, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.60931

Epoch 00016: val_loss did not improve from 0.60931

Epoch 00017: val_loss improved from 0.60931 to 0.60857, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60857

Epoch 00019: val_loss improved from 0.60857 to 0.60443, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.60443

Epoch 00021: val_loss did not improve from 0.60443

Epoch 00022: val_loss did not improve from 0.60443

Epoch 00023: val_loss did not improve from 0.60443

Epoch 00024: val_loss did not improve from 0.60443

Epoch 00025: val_loss did not improve from 0.60443

Epoch 00026: val_loss did not improve from 0.60443

Epoch 00027: val_loss did not improve from 0.60443
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7633893462478543 0.6945688144831613 0.40897292640599153 0.7162714117603171 0.6933436938933533 0.685845703425779 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7084251609805345 0.6614035087719298 0.33828182827215486 0.678479381443299 0.660291057731375 0.6521433924319606 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7154309700758916 0.6566222845129642 0.33318944970375725 0.6726533628972653 0.6607486925406001 0.6518541753798968 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67856, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.67856 to 0.66111, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.66111 to 0.64665, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.64665 to 0.64658, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.64658 to 0.63388, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.63388 to 0.63002, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.63002 to 0.62892, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.62892 to 0.62451, saving model to 1_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.62451 to 0.62056, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.62056

Epoch 00011: val_loss improved from 0.62056 to 0.61719, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.61719 to 0.61535, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.61535 to 0.61294, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.61294 to 0.61113, saving model to 1_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.61113

Epoch 00016: val_loss improved from 0.61113 to 0.60923, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.60923 to 0.60805, saving model to 1_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.60805 to 0.60773, saving model to 1_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.60773 to 0.60594, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.60594

Epoch 00021: val_loss improved from 0.60594 to 0.60546, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.60546 to 0.60411, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.60411

Epoch 00024: val_loss improved from 0.60411 to 0.60387, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss improved from 0.60387 to 0.60132, saving model to 1_50_best_model.hdf5

Epoch 00026: val_loss improved from 0.60132 to 0.60121, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss improved from 0.60121 to 0.60067, saving model to 1_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.60067

Epoch 00029: val_loss did not improve from 0.60067

Epoch 00030: val_loss did not improve from 0.60067

Epoch 00031: val_loss did not improve from 0.60067

Epoch 00032: val_loss improved from 0.60067 to 0.60058, saving model to 1_50_best_model.hdf5

Epoch 00033: val_loss did not improve from 0.60058

Epoch 00034: val_loss did not improve from 0.60058

Epoch 00035: val_loss did not improve from 0.60058

Epoch 00036: val_loss did not improve from 0.60058

Epoch 00037: val_loss did not improve from 0.60058

Epoch 00038: val_loss did not improve from 0.60058

Epoch 00039: val_loss did not improve from 0.60058

Epoch 00040: val_loss did not improve from 0.60058
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7796018743599181 0.7078061125170333 0.4294814348895124 0.7229921819474059 0.7067945850207646 0.7020829481692268 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7077110599475505 0.6631578947368421 0.34081026689528987 0.6791551557545488 0.6620824663572229 0.6545454545454545 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7027486138964256 0.644709180098108 0.32857934001574063 0.6789473070373913 0.6508326451968071 0.6323146235296808 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_15 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63908, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.63908 to 0.61687, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.61687 to 0.60733, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60733

Epoch 00005: val_loss improved from 0.60733 to 0.59579, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.59579 to 0.59229, saving model to 1_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59229

Epoch 00008: val_loss did not improve from 0.59229

Epoch 00009: val_loss improved from 0.59229 to 0.59216, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.59216 to 0.59082, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.59082 to 0.59019, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.59019 to 0.58605, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58605

Epoch 00014: val_loss did not improve from 0.58605

Epoch 00015: val_loss did not improve from 0.58605

Epoch 00016: val_loss did not improve from 0.58605

Epoch 00017: val_loss did not improve from 0.58605

Epoch 00018: val_loss did not improve from 0.58605

Epoch 00019: val_loss improved from 0.58605 to 0.58521, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.58521

Epoch 00021: val_loss improved from 0.58521 to 0.58282, saving model to 1_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.58282

Epoch 00023: val_loss did not improve from 0.58282

Epoch 00024: val_loss improved from 0.58282 to 0.58230, saving model to 1_50_best_model.hdf5

Epoch 00025: val_loss did not improve from 0.58230

Epoch 00026: val_loss improved from 0.58230 to 0.58150, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.58150

Epoch 00028: val_loss did not improve from 0.58150

Epoch 00029: val_loss did not improve from 0.58150

Epoch 00030: val_loss did not improve from 0.58150

Epoch 00031: val_loss did not improve from 0.58150

Epoch 00032: val_loss did not improve from 0.58150

Epoch 00033: val_loss did not improve from 0.58150

Epoch 00034: val_loss did not improve from 0.58150
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7778766470834699 0.7076114463694764 0.4384341690035279 0.7328963685676918 0.7063412599904317 0.6986261229591438 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7429482522992822 0.6824561403508772 0.37777957502459797 0.6965886055691881 0.6814924711589367 0.6759115282764601 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7135366285242422 0.6615276804484933 0.3431862495092836 0.6777629840945634 0.6656374110337777 0.6568845758082174 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64770, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64770 to 0.62879, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62879 to 0.62205, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62205 to 0.61941, saving model to 1_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.61941 to 0.60789, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60789

Epoch 00007: val_loss improved from 0.60789 to 0.60458, saving model to 1_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60458

Epoch 00009: val_loss improved from 0.60458 to 0.60035, saving model to 1_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.60035 to 0.59720, saving model to 1_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59720

Epoch 00012: val_loss did not improve from 0.59720

Epoch 00013: val_loss did not improve from 0.59720

Epoch 00014: val_loss did not improve from 0.59720

Epoch 00015: val_loss improved from 0.59720 to 0.59544, saving model to 1_50_best_model.hdf5

Epoch 00016: val_loss improved from 0.59544 to 0.59205, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59205

Epoch 00018: val_loss did not improve from 0.59205

Epoch 00019: val_loss improved from 0.59205 to 0.59183, saving model to 1_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.59183

Epoch 00021: val_loss did not improve from 0.59183

Epoch 00022: val_loss improved from 0.59183 to 0.59165, saving model to 1_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59165

Epoch 00024: val_loss did not improve from 0.59165

Epoch 00025: val_loss did not improve from 0.59165

Epoch 00026: val_loss improved from 0.59165 to 0.58807, saving model to 1_50_best_model.hdf5

Epoch 00027: val_loss did not improve from 0.58807

Epoch 00028: val_loss did not improve from 0.58807

Epoch 00029: val_loss did not improve from 0.58807

Epoch 00030: val_loss did not improve from 0.58807

Epoch 00031: val_loss did not improve from 0.58807

Epoch 00032: val_loss did not improve from 0.58807

Epoch 00033: val_loss did not improve from 0.58807

Epoch 00034: val_loss did not improve from 0.58807
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7771166587739653 0.7091687755499319 0.42910980849370467 0.7210314024420654 0.7082681755975462 0.7046269483893315 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7370507627337757 0.6736842105263158 0.3533431769905035 0.6804433541824533 0.6729786631536179 0.6700280112044819 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7081593330974008 0.6566222845129642 0.3298360130778797 0.6696415569285818 0.6603259801030239 0.6529393662642948 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 5,651
Trainable params: 5,651
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65571, saving model to 1_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65571 to 0.63220, saving model to 1_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63220 to 0.62399, saving model to 1_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62399

Epoch 00005: val_loss improved from 0.62399 to 0.61737, saving model to 1_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61737

Epoch 00007: val_loss did not improve from 0.61737

Epoch 00008: val_loss did not improve from 0.61737

Epoch 00009: val_loss did not improve from 0.61737

Epoch 00010: val_loss did not improve from 0.61737

Epoch 00011: val_loss improved from 0.61737 to 0.61171, saving model to 1_50_best_model.hdf5

Epoch 00012: val_loss improved from 0.61171 to 0.61068, saving model to 1_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.61068 to 0.60912, saving model to 1_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.60912

Epoch 00015: val_loss did not improve from 0.60912

Epoch 00016: val_loss improved from 0.60912 to 0.60904, saving model to 1_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.60904

Epoch 00018: val_loss did not improve from 0.60904

Epoch 00019: val_loss did not improve from 0.60904

Epoch 00020: val_loss did not improve from 0.60904

Epoch 00021: val_loss did not improve from 0.60904

Epoch 00022: val_loss did not improve from 0.60904

Epoch 00023: val_loss did not improve from 0.60904

Epoch 00024: val_loss did not improve from 0.60904
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7490816776345908 0.6751021997274674 0.38839459063710546 0.7174852177880868 0.6734030013285205 0.657133329064989 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7175976656283473 0.6333333333333333 0.30286344707019514 0.6742468701095461 0.6316038955442558 0.6087055059763312 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7105943533482757 0.6433076384022425 0.3107242052209038 0.6630519992377256 0.6480348786913609 0.6364491346720302 None
average testing metrics
[0.71012957 0.65487036 0.33306368 0.67408254 0.65935237 0.64879401]
std testing metrics
[0.00480877 0.00616718 0.0095612  0.0052428  0.00570457 0.00817145]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_2 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67695, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.67695 to 0.67429, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.67429 to 0.65892, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.65892 to 0.64432, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.64432 to 0.63513, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.63513 to 0.62663, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.62663 to 0.62484, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.62484 to 0.62058, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.62058 to 0.61869, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61869

Epoch 00011: val_loss did not improve from 0.61869

Epoch 00012: val_loss improved from 0.61869 to 0.61453, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss improved from 0.61453 to 0.60716, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.60716

Epoch 00015: val_loss did not improve from 0.60716

Epoch 00016: val_loss did not improve from 0.60716

Epoch 00017: val_loss did not improve from 0.60716

Epoch 00018: val_loss did not improve from 0.60716

Epoch 00019: val_loss did not improve from 0.60716

Epoch 00020: val_loss did not improve from 0.60716

Epoch 00021: val_loss did not improve from 0.60716
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7406502534408549 0.6839337877312561 0.38317199257167767 0.7007858415879858 0.6828076804745864 0.6763112578761229 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7088101525821595 0.6625874125874126 0.3414661163925887 0.6805405553201088 0.6614583333333333 0.6530162591660145 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7040206834178757 0.6461107217939733 0.3305839776880071 0.6795680361609608 0.6521509181707366 0.6341517896804949 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_4 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_5 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65815, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65815 to 0.63777, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63777 to 0.62211, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62211

Epoch 00005: val_loss improved from 0.62211 to 0.62176, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.62176 to 0.61393, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61393

Epoch 00008: val_loss did not improve from 0.61393

Epoch 00009: val_loss improved from 0.61393 to 0.60850, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.60850 to 0.60773, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60773

Epoch 00012: val_loss did not improve from 0.60773

Epoch 00013: val_loss improved from 0.60773 to 0.60519, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.60519

Epoch 00015: val_loss did not improve from 0.60519

Epoch 00016: val_loss improved from 0.60519 to 0.60261, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.60261

Epoch 00018: val_loss did not improve from 0.60261

Epoch 00019: val_loss improved from 0.60261 to 0.60182, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.60182

Epoch 00021: val_loss did not improve from 0.60182

Epoch 00022: val_loss did not improve from 0.60182

Epoch 00023: val_loss improved from 0.60182 to 0.59780, saving model to 2_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.59780

Epoch 00025: val_loss did not improve from 0.59780

Epoch 00026: val_loss did not improve from 0.59780

Epoch 00027: val_loss did not improve from 0.59780

Epoch 00028: val_loss did not improve from 0.59780

Epoch 00029: val_loss improved from 0.59780 to 0.59383, saving model to 2_50_best_model.hdf5

Epoch 00030: val_loss did not improve from 0.59383

Epoch 00031: val_loss did not improve from 0.59383

Epoch 00032: val_loss did not improve from 0.59383

Epoch 00033: val_loss did not improve from 0.59383

Epoch 00034: val_loss did not improve from 0.59383

Epoch 00035: val_loss did not improve from 0.59383

Epoch 00036: val_loss did not improve from 0.59383

Epoch 00037: val_loss did not improve from 0.59383
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7759581933335317 0.7034079844206427 0.4261143160908858 0.7244708324689006 0.7022238350307266 0.6954906234136903 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7136761541471048 0.6608391608391608 0.33817527240235307 0.6790296052631579 0.6596977699530516 0.6510089065566347 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7083598757422044 0.6489138051857043 0.32329494371893147 0.6699719577409677 0.653730683024655 0.6418791692150942 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 50)                5600      
_________________________________________________________________
activation_7 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 50)                2550      
_________________________________________________________________
activation_8 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64501, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64501 to 0.62315, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62315 to 0.61384, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61384 to 0.60907, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.60907 to 0.60836, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.60836 to 0.60675, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.60675 to 0.60466, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.60466 to 0.60233, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.60233 to 0.59966, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.59966 to 0.59961, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss improved from 0.59961 to 0.59695, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59695

Epoch 00013: val_loss did not improve from 0.59695

Epoch 00014: val_loss did not improve from 0.59695

Epoch 00015: val_loss did not improve from 0.59695

Epoch 00016: val_loss did not improve from 0.59695

Epoch 00017: val_loss improved from 0.59695 to 0.59597, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss improved from 0.59597 to 0.59394, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.59394 to 0.59182, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.59182

Epoch 00021: val_loss did not improve from 0.59182

Epoch 00022: val_loss did not improve from 0.59182

Epoch 00023: val_loss did not improve from 0.59182

Epoch 00024: val_loss did not improve from 0.59182

Epoch 00025: val_loss did not improve from 0.59182

Epoch 00026: val_loss did not improve from 0.59182

Epoch 00027: val_loss improved from 0.59182 to 0.58952, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.58952

Epoch 00029: val_loss did not improve from 0.58952

Epoch 00030: val_loss did not improve from 0.58952

Epoch 00031: val_loss improved from 0.58952 to 0.58943, saving model to 2_50_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.58943

Epoch 00033: val_loss improved from 0.58943 to 0.58495, saving model to 2_50_best_model.hdf5

Epoch 00034: val_loss did not improve from 0.58495

Epoch 00035: val_loss did not improve from 0.58495

Epoch 00036: val_loss did not improve from 0.58495

Epoch 00037: val_loss did not improve from 0.58495

Epoch 00038: val_loss did not improve from 0.58495

Epoch 00039: val_loss did not improve from 0.58495

Epoch 00040: val_loss did not improve from 0.58495

Epoch 00041: val_loss did not improve from 0.58495
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7772417478647728 0.7073598130841121 0.4260940936566237 0.7198465992363874 0.7064577952077434 0.7025515520196892 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7226393796623478 0.6847635726795096 0.3773181464378902 0.6936586942469295 0.6837885257165293 0.6803627407075683 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7204061971609453 0.6608269096005606 0.33722415639083914 0.6729685385726285 0.6643653415123274 0.6575779570532193 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_10 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_11 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63922, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.63922 to 0.62347, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62347 to 0.61490, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61490 to 0.61475, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61475

Epoch 00006: val_loss did not improve from 0.61475

Epoch 00007: val_loss improved from 0.61475 to 0.61138, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.61138 to 0.60730, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.60730

Epoch 00010: val_loss did not improve from 0.60730

Epoch 00011: val_loss did not improve from 0.60730

Epoch 00012: val_loss did not improve from 0.60730

Epoch 00013: val_loss did not improve from 0.60730

Epoch 00014: val_loss did not improve from 0.60730

Epoch 00015: val_loss did not improve from 0.60730

Epoch 00016: val_loss did not improve from 0.60730
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7252545129000769 0.6645249221183801 0.36462389841385434 0.7040729193822123 0.6628714232356216 0.6460632222283416 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.720479976442874 0.658493870402802 0.3358262119602974 0.6796427367711493 0.6569493521790342 0.6467761123007376 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7181795839723172 0.6391030133146461 0.3234216411513751 0.6793937458261956 0.6457709095198774 0.6237787225764506 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_13 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_14 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65773, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65773 to 0.62772, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62772 to 0.62735, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62735 to 0.62512, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62512 to 0.62371, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.62371 to 0.61889, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss improved from 0.61889 to 0.61710, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61710

Epoch 00009: val_loss did not improve from 0.61710

Epoch 00010: val_loss improved from 0.61710 to 0.61393, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.61393

Epoch 00012: val_loss did not improve from 0.61393

Epoch 00013: val_loss improved from 0.61393 to 0.61120, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.61120

Epoch 00015: val_loss did not improve from 0.61120

Epoch 00016: val_loss did not improve from 0.61120

Epoch 00017: val_loss did not improve from 0.61120

Epoch 00018: val_loss did not improve from 0.61120

Epoch 00019: val_loss did not improve from 0.61120

Epoch 00020: val_loss improved from 0.61120 to 0.60988, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss improved from 0.60988 to 0.60936, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.60936

Epoch 00023: val_loss did not improve from 0.60936

Epoch 00024: val_loss did not improve from 0.60936

Epoch 00025: val_loss did not improve from 0.60936

Epoch 00026: val_loss did not improve from 0.60936

Epoch 00027: val_loss did not improve from 0.60936

Epoch 00028: val_loss did not improve from 0.60936

Epoch 00029: val_loss did not improve from 0.60936
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7425170940255188 0.6890576323987538 0.39855729526493605 0.7114229678106534 0.6878319078265456 0.6797190652935701 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7062107381232823 0.6567425569176882 0.32688422235003206 0.671903417573767 0.6553972811150373 0.6477970795568984 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7258424757186112 0.6748423265592152 0.36633699008750853 0.6880267508639335 0.6784357673705321 0.6716364617386612 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_16 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_17 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66514, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.66514 to 0.62908, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.62908 to 0.61906, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.61906 to 0.61346, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61346

Epoch 00006: val_loss did not improve from 0.61346

Epoch 00007: val_loss improved from 0.61346 to 0.61211, saving model to 2_50_best_model.hdf5

Epoch 00008: val_loss improved from 0.61211 to 0.61091, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.61091 to 0.61001, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss improved from 0.61001 to 0.60813, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60813

Epoch 00012: val_loss improved from 0.60813 to 0.60750, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.60750

Epoch 00014: val_loss did not improve from 0.60750

Epoch 00015: val_loss did not improve from 0.60750

Epoch 00016: val_loss did not improve from 0.60750

Epoch 00017: val_loss improved from 0.60750 to 0.60596, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60596

Epoch 00019: val_loss did not improve from 0.60596

Epoch 00020: val_loss did not improve from 0.60596

Epoch 00021: val_loss did not improve from 0.60596

Epoch 00022: val_loss did not improve from 0.60596

Epoch 00023: val_loss did not improve from 0.60596

Epoch 00024: val_loss did not improve from 0.60596

Epoch 00025: val_loss improved from 0.60596 to 0.60479, saving model to 2_50_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.60479

Epoch 00027: val_loss did not improve from 0.60479

Epoch 00028: val_loss did not improve from 0.60479

Epoch 00029: val_loss did not improve from 0.60479

Epoch 00030: val_loss did not improve from 0.60479

Epoch 00031: val_loss did not improve from 0.60479

Epoch 00032: val_loss did not improve from 0.60479

Epoch 00033: val_loss did not improve from 0.60479
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7770405614105722 0.7103367724352735 0.43317536180314536 0.7240465598228418 0.7093771203423714 0.7052168802380522 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7037465680058114 0.6596491228070176 0.3306291534011005 0.6722352155028399 0.6586720183203851 0.6524565020617519 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7274517321379418 0.662228451296426 0.3352604722215865 0.6702512776831346 0.6650495458298926 0.6603897488969558 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_19 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_20 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65876, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65876 to 0.63945, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.63945 to 0.62946, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.62946 to 0.62775, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.62775 to 0.61998, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61998

Epoch 00007: val_loss did not improve from 0.61998

Epoch 00008: val_loss did not improve from 0.61998

Epoch 00009: val_loss did not improve from 0.61998

Epoch 00010: val_loss did not improve from 0.61998

Epoch 00011: val_loss improved from 0.61998 to 0.61455, saving model to 2_50_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.61455

Epoch 00013: val_loss improved from 0.61455 to 0.61283, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.61283 to 0.60882, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.60882

Epoch 00016: val_loss improved from 0.60882 to 0.60422, saving model to 2_50_best_model.hdf5

Epoch 00017: val_loss improved from 0.60422 to 0.60261, saving model to 2_50_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60261

Epoch 00019: val_loss did not improve from 0.60261

Epoch 00020: val_loss improved from 0.60261 to 0.59990, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.59990

Epoch 00022: val_loss did not improve from 0.59990

Epoch 00023: val_loss improved from 0.59990 to 0.59972, saving model to 2_50_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.59972

Epoch 00025: val_loss did not improve from 0.59972

Epoch 00026: val_loss did not improve from 0.59972

Epoch 00027: val_loss improved from 0.59972 to 0.59031, saving model to 2_50_best_model.hdf5

Epoch 00028: val_loss did not improve from 0.59031

Epoch 00029: val_loss did not improve from 0.59031

Epoch 00030: val_loss did not improve from 0.59031

Epoch 00031: val_loss improved from 0.59031 to 0.58903, saving model to 2_50_best_model.hdf5

Epoch 00032: val_loss did not improve from 0.58903

Epoch 00033: val_loss did not improve from 0.58903

Epoch 00034: val_loss did not improve from 0.58903

Epoch 00035: val_loss did not improve from 0.58903

Epoch 00036: val_loss did not improve from 0.58903

Epoch 00037: val_loss did not improve from 0.58903

Epoch 00038: val_loss did not improve from 0.58903

Epoch 00039: val_loss improved from 0.58903 to 0.58392, saving model to 2_50_best_model.hdf5

Epoch 00040: val_loss did not improve from 0.58392

Epoch 00041: val_loss did not improve from 0.58392

Epoch 00042: val_loss did not improve from 0.58392

Epoch 00043: val_loss did not improve from 0.58392

Epoch 00044: val_loss did not improve from 0.58392

Epoch 00045: val_loss did not improve from 0.58392

Epoch 00046: val_loss did not improve from 0.58392

Epoch 00047: val_loss did not improve from 0.58392
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7987774246105543 0.7270780611251704 0.46085373821705733 0.7345435376406096 0.7263824556467579 0.7244782738699134 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7359118947070339 0.6754385964912281 0.3571703412543904 0.6825349866227619 0.6747208234323635 0.6716784098586769 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7100644882230348 0.6510161177295024 0.32792285361036666 0.6724883370759134 0.6558560418387008 0.6439520864480082 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_22 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_23 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_23 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62859, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.62859 to 0.61308, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61308

Epoch 00004: val_loss did not improve from 0.61308

Epoch 00005: val_loss improved from 0.61308 to 0.61034, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss improved from 0.61034 to 0.60847, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60847

Epoch 00008: val_loss improved from 0.60847 to 0.60380, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss improved from 0.60380 to 0.60339, saving model to 2_50_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60339

Epoch 00011: val_loss did not improve from 0.60339

Epoch 00012: val_loss did not improve from 0.60339

Epoch 00013: val_loss improved from 0.60339 to 0.59703, saving model to 2_50_best_model.hdf5

Epoch 00014: val_loss improved from 0.59703 to 0.59618, saving model to 2_50_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59618

Epoch 00016: val_loss did not improve from 0.59618

Epoch 00017: val_loss did not improve from 0.59618

Epoch 00018: val_loss improved from 0.59618 to 0.59271, saving model to 2_50_best_model.hdf5

Epoch 00019: val_loss improved from 0.59271 to 0.59264, saving model to 2_50_best_model.hdf5

Epoch 00020: val_loss improved from 0.59264 to 0.59178, saving model to 2_50_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.59178

Epoch 00022: val_loss did not improve from 0.59178

Epoch 00023: val_loss did not improve from 0.59178

Epoch 00024: val_loss did not improve from 0.59178

Epoch 00025: val_loss did not improve from 0.59178

Epoch 00026: val_loss did not improve from 0.59178

Epoch 00027: val_loss did not improve from 0.59178

Epoch 00028: val_loss did not improve from 0.59178
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7562372552075155 0.6875608331711115 0.39771458011495575 0.7123285516873328 0.6862407174859615 0.6772075056937749 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7368537693453663 0.6684210526315789 0.34925865476313006 0.682135969141755 0.6674320680612157 0.6612381332721196 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7319226534544454 0.6531184302733006 0.3382739675861553 0.6804526085866724 0.6585309268215956 0.6440311538568142 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_25 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_26 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_26 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64644, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.64644 to 0.61899, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.61899 to 0.60973, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss improved from 0.60973 to 0.59715, saving model to 2_50_best_model.hdf5

Epoch 00005: val_loss improved from 0.59715 to 0.59383, saving model to 2_50_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59383

Epoch 00007: val_loss did not improve from 0.59383

Epoch 00008: val_loss did not improve from 0.59383

Epoch 00009: val_loss did not improve from 0.59383

Epoch 00010: val_loss improved from 0.59383 to 0.58799, saving model to 2_50_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.58799

Epoch 00012: val_loss did not improve from 0.58799

Epoch 00013: val_loss did not improve from 0.58799

Epoch 00014: val_loss did not improve from 0.58799

Epoch 00015: val_loss improved from 0.58799 to 0.58660, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.58660

Epoch 00017: val_loss did not improve from 0.58660

Epoch 00018: val_loss did not improve from 0.58660

Epoch 00019: val_loss did not improve from 0.58660

Epoch 00020: val_loss did not improve from 0.58660

Epoch 00021: val_loss improved from 0.58660 to 0.58546, saving model to 2_50_best_model.hdf5

Epoch 00022: val_loss improved from 0.58546 to 0.58411, saving model to 2_50_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.58411

Epoch 00024: val_loss did not improve from 0.58411

Epoch 00025: val_loss did not improve from 0.58411

Epoch 00026: val_loss did not improve from 0.58411

Epoch 00027: val_loss did not improve from 0.58411

Epoch 00028: val_loss did not improve from 0.58411

Epoch 00029: val_loss did not improve from 0.58411

Epoch 00030: val_loss did not improve from 0.58411
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7504463519651614 0.6889234962040102 0.39395089046158843 0.7066121539906655 0.6877882073947235 0.6812902282990427 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7418155403159281 0.6789473684210526 0.3727758908628998 0.6952702702702702 0.6779096539072407 0.671289599818486 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7129487633203571 0.6510161177295024 0.34427048969392804 0.6883776948941822 0.6572932641264598 0.6381580555283997 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 50)                5600      
_________________________________________________________________
activation_28 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_29 (Dense)             (None, 50)                2550      
_________________________________________________________________
activation_29 (Activation)   (None, 50)                0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 50)                0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 51        
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 8,201
Trainable params: 8,201
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65155, saving model to 2_50_best_model.hdf5

Epoch 00002: val_loss improved from 0.65155 to 0.64053, saving model to 2_50_best_model.hdf5

Epoch 00003: val_loss improved from 0.64053 to 0.63253, saving model to 2_50_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.63253

Epoch 00005: val_loss did not improve from 0.63253

Epoch 00006: val_loss improved from 0.63253 to 0.62698, saving model to 2_50_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.62698

Epoch 00008: val_loss improved from 0.62698 to 0.62502, saving model to 2_50_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.62502

Epoch 00010: val_loss did not improve from 0.62502

Epoch 00011: val_loss did not improve from 0.62502

Epoch 00012: val_loss improved from 0.62502 to 0.62157, saving model to 2_50_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.62157

Epoch 00014: val_loss did not improve from 0.62157

Epoch 00015: val_loss improved from 0.62157 to 0.61953, saving model to 2_50_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.61953

Epoch 00017: val_loss did not improve from 0.61953

Epoch 00018: val_loss did not improve from 0.61953

Epoch 00019: val_loss did not improve from 0.61953

Epoch 00020: val_loss did not improve from 0.61953

Epoch 00021: val_loss did not improve from 0.61953

Epoch 00022: val_loss did not improve from 0.61953

Epoch 00023: val_loss did not improve from 0.61953
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.742711100452764 0.6840568425150866 0.39057857863429185 0.708714472465349 0.6827276569348952 0.6734457984560358 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7115647431083094 0.6421052631578947 0.3070439603705959 0.6675020885547202 0.6407086837148028 0.6266423498285406 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7213577916715819 0.6552207428170989 0.34543538952515607 0.6854406625236276 0.6608676418544297 0.6452702293038428 None
average testing metrics
[0.71805542 0.65423966 0.33720249 0.67869396 0.6592051  0.64608254]
std testing metrics
[0.00859411 0.00937148 0.01218493 0.0067036  0.00841963 0.01311304]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.73673, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.73673 to 0.70746, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.70746 to 0.68051, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.68051 to 0.66207, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.66207 to 0.64501, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.64501 to 0.63960, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.63960 to 0.63570, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.63570

Epoch 00009: val_loss improved from 0.63570 to 0.63467, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.63467 to 0.62932, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.62932

Epoch 00012: val_loss did not improve from 0.62932

Epoch 00013: val_loss did not improve from 0.62932

Epoch 00014: val_loss improved from 0.62932 to 0.62724, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.62724 to 0.62620, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.62620

Epoch 00017: val_loss did not improve from 0.62620

Epoch 00018: val_loss did not improve from 0.62620

Epoch 00019: val_loss did not improve from 0.62620

Epoch 00020: val_loss did not improve from 0.62620

Epoch 00021: val_loss did not improve from 0.62620

Epoch 00022: val_loss did not improve from 0.62620

Epoch 00023: val_loss did not improve from 0.62620
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7706493765773682 0.6999026290165531 0.4013896237252635 0.7018975259527471 0.6994992624030671 0.6988748288744769 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.674662558685446 0.6363636363636364 0.2735092621938768 0.6375098892405063 0.6360035211267605 0.6352219769438313 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7207522315284496 0.6664330763840224 0.3440728205226378 0.6748167773108391 0.6693002634579843 0.6645470348860179 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_3 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67383, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.67383 to 0.62609, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62609 to 0.62239, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.62239 to 0.61373, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.61373 to 0.61084, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.61084 to 0.60596, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.60596 to 0.60365, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60365

Epoch 00009: val_loss did not improve from 0.60365

Epoch 00010: val_loss improved from 0.60365 to 0.60031, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.60031 to 0.59794, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59794

Epoch 00013: val_loss improved from 0.59794 to 0.59541, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss improved from 0.59541 to 0.59162, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.59162 to 0.59117, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59117

Epoch 00017: val_loss did not improve from 0.59117

Epoch 00018: val_loss did not improve from 0.59117

Epoch 00019: val_loss did not improve from 0.59117

Epoch 00020: val_loss did not improve from 0.59117

Epoch 00021: val_loss did not improve from 0.59117

Epoch 00022: val_loss improved from 0.59117 to 0.59024, saving model to 1_100_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.59024

Epoch 00024: val_loss did not improve from 0.59024

Epoch 00025: val_loss did not improve from 0.59024

Epoch 00026: val_loss did not improve from 0.59024

Epoch 00027: val_loss did not improve from 0.59024

Epoch 00028: val_loss improved from 0.59024 to 0.58779, saving model to 1_100_best_model.hdf5

Epoch 00029: val_loss did not improve from 0.58779

Epoch 00030: val_loss did not improve from 0.58779

Epoch 00031: val_loss did not improve from 0.58779

Epoch 00032: val_loss did not improve from 0.58779

Epoch 00033: val_loss did not improve from 0.58779

Epoch 00034: val_loss did not improve from 0.58779

Epoch 00035: val_loss did not improve from 0.58779

Epoch 00036: val_loss did not improve from 0.58779
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.817119196999367 0.7394352482960078 0.48834334388853134 0.7498261777982754 0.7386451488210282 0.7362649232727974 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7187744522691705 0.6608391608391608 0.32895126145666015 0.6690340909090909 0.6600401017214398 0.6559771825396825 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7081337737407101 0.6629292221443588 0.3407679821023176 0.6745012394256984 0.6663638865951005 0.6599305480206087 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64711, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64711 to 0.61813, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61813 to 0.61024, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.61024 to 0.60605, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60605

Epoch 00006: val_loss did not improve from 0.60605

Epoch 00007: val_loss improved from 0.60605 to 0.60224, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.60224 to 0.59686, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59686

Epoch 00010: val_loss improved from 0.59686 to 0.59285, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59285

Epoch 00012: val_loss did not improve from 0.59285

Epoch 00013: val_loss did not improve from 0.59285

Epoch 00014: val_loss did not improve from 0.59285

Epoch 00015: val_loss did not improve from 0.59285

Epoch 00016: val_loss did not improve from 0.59285

Epoch 00017: val_loss did not improve from 0.59285

Epoch 00018: val_loss did not improve from 0.59285
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7523521582320876 0.6890576323987538 0.3973626591814821 0.7101219730625293 0.6878636020431699 0.6801949010879084 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7236945425991363 0.6637478108581436 0.34484416890717545 0.6831975955012604 0.6622803788771103 0.6533265874019731 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7101549290236325 0.649614576033637 0.3241718938944474 0.6701890146096154 0.6543686838897409 0.6428070807801674 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64689, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64689 to 0.61808, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61808 to 0.60820, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60820 to 0.60641, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60641 to 0.59879, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59879

Epoch 00007: val_loss improved from 0.59879 to 0.59830, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59830

Epoch 00009: val_loss did not improve from 0.59830

Epoch 00010: val_loss did not improve from 0.59830

Epoch 00011: val_loss did not improve from 0.59830

Epoch 00012: val_loss improved from 0.59830 to 0.59476, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59476

Epoch 00014: val_loss did not improve from 0.59476

Epoch 00015: val_loss did not improve from 0.59476

Epoch 00016: val_loss did not improve from 0.59476

Epoch 00017: val_loss did not improve from 0.59476

Epoch 00018: val_loss did not improve from 0.59476

Epoch 00019: val_loss did not improve from 0.59476

Epoch 00020: val_loss did not improve from 0.59476
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7618475332269885 0.692367601246106 0.3987054856470455 0.7077016578205344 0.6913394264074696 0.6858459729774762 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7350436788378483 0.658493870402802 0.32463387283541006 0.6673448095983308 0.6574401256380056 0.652976247985863 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7208839605206245 0.6636299929922915 0.3532091507946805 0.6852588650180653 0.6683545672604302 0.6572293304722404 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_9 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.70605, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.70605 to 0.63729, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.63729 to 0.63400, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.63400 to 0.63008, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.63008 to 0.62241, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.62241 to 0.61850, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.61850 to 0.61747, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.61747 to 0.61732, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.61732 to 0.61074, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61074

Epoch 00011: val_loss did not improve from 0.61074

Epoch 00012: val_loss improved from 0.61074 to 0.60553, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.60553

Epoch 00014: val_loss improved from 0.60553 to 0.60398, saving model to 1_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.60398 to 0.60367, saving model to 1_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.60367

Epoch 00017: val_loss improved from 0.60367 to 0.60058, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60058

Epoch 00019: val_loss did not improve from 0.60058

Epoch 00020: val_loss did not improve from 0.60058

Epoch 00021: val_loss did not improve from 0.60058

Epoch 00022: val_loss did not improve from 0.60058

Epoch 00023: val_loss improved from 0.60058 to 0.59272, saving model to 1_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.59272

Epoch 00025: val_loss did not improve from 0.59272

Epoch 00026: val_loss did not improve from 0.59272

Epoch 00027: val_loss did not improve from 0.59272

Epoch 00028: val_loss did not improve from 0.59272

Epoch 00029: val_loss did not improve from 0.59272

Epoch 00030: val_loss did not improve from 0.59272

Epoch 00031: val_loss did not improve from 0.59272
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7968025388129044 0.7069704049844237 0.44054308685323107 0.7359253919123542 0.7056563409739648 0.6968369529087501 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7318536513545348 0.658493870402802 0.33409532020122196 0.6777262374312538 0.6570106988614055 0.6476881164152752 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7161141913412764 0.6706377014716188 0.36079282717412514 0.6863769721847968 0.6746077621800165 0.6664972690855714 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65511, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65511 to 0.63096, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.63096 to 0.62088, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.62088 to 0.61762, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.61762 to 0.61241, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61241

Epoch 00007: val_loss improved from 0.61241 to 0.61207, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61207

Epoch 00009: val_loss did not improve from 0.61207

Epoch 00010: val_loss improved from 0.61207 to 0.61117, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.61117

Epoch 00012: val_loss improved from 0.61117 to 0.60622, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.60622

Epoch 00014: val_loss did not improve from 0.60622

Epoch 00015: val_loss did not improve from 0.60622

Epoch 00016: val_loss did not improve from 0.60622

Epoch 00017: val_loss did not improve from 0.60622

Epoch 00018: val_loss did not improve from 0.60622

Epoch 00019: val_loss did not improve from 0.60622

Epoch 00020: val_loss did not improve from 0.60622
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7500138703361563 0.6784115242359354 0.38495052209987324 0.7093901034434505 0.6769268246540905 0.6649139881341595 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6934659755481957 0.6614035087719298 0.3486046605647332 0.6898591796190254 0.660020191822312 0.6470361755033287 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7100369627619834 0.644709180098108 0.3291085206725541 0.6794738663897542 0.6508749164405647 0.6321179396460854 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66424, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.66424 to 0.64075, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.64075 to 0.64020, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.64020 to 0.62359, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.62359 to 0.61856, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.61856 to 0.61118, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.61118 to 0.60932, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60932

Epoch 00009: val_loss improved from 0.60932 to 0.60297, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.60297 to 0.59777, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59777

Epoch 00012: val_loss did not improve from 0.59777

Epoch 00013: val_loss improved from 0.59777 to 0.59652, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.59652

Epoch 00015: val_loss did not improve from 0.59652

Epoch 00016: val_loss improved from 0.59652 to 0.59125, saving model to 1_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59125

Epoch 00018: val_loss did not improve from 0.59125

Epoch 00019: val_loss did not improve from 0.59125

Epoch 00020: val_loss did not improve from 0.59125

Epoch 00021: val_loss did not improve from 0.59125

Epoch 00022: val_loss did not improve from 0.59125

Epoch 00023: val_loss did not improve from 0.59125

Epoch 00024: val_loss did not improve from 0.59125
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7841683225169978 0.7138407630912984 0.4368848452894705 0.7240119422362552 0.7130113757978854 0.7100286431285522 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7229657354625035 0.6719298245614035 0.35153232552852803 0.6805194805194805 0.6711380061806675 0.6673335185121609 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7084444182297196 0.6405045550105115 0.314503122502989 0.669136813374275 0.6462014863748968 0.6298594625751794 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_15 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65298, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65298 to 0.61799, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61799 to 0.61538, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.61538 to 0.59809, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.59809

Epoch 00006: val_loss improved from 0.59809 to 0.59408, saving model to 1_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.59408 to 0.59356, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59356

Epoch 00009: val_loss did not improve from 0.59356

Epoch 00010: val_loss improved from 0.59356 to 0.59163, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59163

Epoch 00012: val_loss improved from 0.59163 to 0.58408, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.58408

Epoch 00014: val_loss did not improve from 0.58408

Epoch 00015: val_loss did not improve from 0.58408

Epoch 00016: val_loss did not improve from 0.58408

Epoch 00017: val_loss improved from 0.58408 to 0.58310, saving model to 1_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58310

Epoch 00019: val_loss did not improve from 0.58310

Epoch 00020: val_loss did not improve from 0.58310

Epoch 00021: val_loss did not improve from 0.58310

Epoch 00022: val_loss did not improve from 0.58310

Epoch 00023: val_loss did not improve from 0.58310

Epoch 00024: val_loss did not improve from 0.58310

Epoch 00025: val_loss did not improve from 0.58310
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7808749893130197 0.7089741094023749 0.4274475064841483 0.7194759950840469 0.7081222717882516 0.7048943717351472 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7489442385589933 0.6771929824561403 0.3575986423815872 0.6809645726393321 0.6766599770995186 0.6750768315653812 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7083500452204003 0.6524176594253679 0.33795713364317115 0.6807941266497417 0.6579351972002674 0.6428972170087386 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63515, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63515 to 0.61516, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61516 to 0.60807, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.60807 to 0.60271, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60271

Epoch 00006: val_loss did not improve from 0.60271

Epoch 00007: val_loss improved from 0.60271 to 0.60223, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.60223 to 0.59522, saving model to 1_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.59522

Epoch 00010: val_loss did not improve from 0.59522

Epoch 00011: val_loss did not improve from 0.59522

Epoch 00012: val_loss did not improve from 0.59522

Epoch 00013: val_loss did not improve from 0.59522

Epoch 00014: val_loss did not improve from 0.59522

Epoch 00015: val_loss did not improve from 0.59522

Epoch 00016: val_loss did not improve from 0.59522
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7500788259541125 0.6834728440724158 0.3733555468306714 0.6907382033937359 0.6827037817661015 0.6798427416943789 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7362135408330357 0.6912280701754386 0.3897225309586845 0.6993236714975846 0.690498762635279 0.6875311472141932 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7124012032558689 0.6559215136650315 0.3376331025923133 0.6773403022768398 0.6607024890881208 0.6491671778181135 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 11,301
Trainable params: 11,301
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65177, saving model to 1_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65177 to 0.64455, saving model to 1_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.64455 to 0.62336, saving model to 1_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.62336 to 0.62239, saving model to 1_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.62239 to 0.61473, saving model to 1_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61473

Epoch 00007: val_loss improved from 0.61473 to 0.61461, saving model to 1_100_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61461

Epoch 00009: val_loss improved from 0.61461 to 0.61409, saving model to 1_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.61409 to 0.61021, saving model to 1_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.61021 to 0.60916, saving model to 1_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.60916 to 0.60894, saving model to 1_100_best_model.hdf5

Epoch 00013: val_loss improved from 0.60894 to 0.60866, saving model to 1_100_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.60866

Epoch 00015: val_loss did not improve from 0.60866

Epoch 00016: val_loss did not improve from 0.60866

Epoch 00017: val_loss did not improve from 0.60866

Epoch 00018: val_loss did not improve from 0.60866

Epoch 00019: val_loss did not improve from 0.60866

Epoch 00020: val_loss did not improve from 0.60866

Epoch 00021: val_loss did not improve from 0.60866
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7654519334490659 0.6967101421062877 0.40168129771236816 0.7059240628410284 0.6958827233518251 0.6926975679805869 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7020475000307803 0.6596491228070176 0.3265580699700008 0.6678374897552979 0.6588443875352433 0.6547352908116749 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7184450080610278 0.6475122634898388 0.2981121169292585 0.6493779989337125 0.6487348118438127 0.6473564049642606 None
average testing metrics
[0.71337167 0.65543097 0.33403287 0.6747266  0.65974441 0.64924095]
std testing metrics
[0.00493464 0.00958828 0.01746868 0.01003638 0.0092009  0.0121003 ]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_2 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66696, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.66696 to 0.66266, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.66266 to 0.64782, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.64782 to 0.63714, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.63714 to 0.63392, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.63392 to 0.63033, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss improved from 0.63033 to 0.62732, saving model to 2_100_best_model.hdf5

Epoch 00008: val_loss improved from 0.62732 to 0.62423, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.62423 to 0.62335, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss improved from 0.62335 to 0.62175, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss improved from 0.62175 to 0.62101, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss improved from 0.62101 to 0.61395, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.61395

Epoch 00014: val_loss did not improve from 0.61395

Epoch 00015: val_loss improved from 0.61395 to 0.61203, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.61203

Epoch 00017: val_loss improved from 0.61203 to 0.61096, saving model to 2_100_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.61096

Epoch 00019: val_loss did not improve from 0.61096

Epoch 00020: val_loss did not improve from 0.61096

Epoch 00021: val_loss improved from 0.61096 to 0.60585, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.60585

Epoch 00023: val_loss improved from 0.60585 to 0.60294, saving model to 2_100_best_model.hdf5

Epoch 00024: val_loss did not improve from 0.60294

Epoch 00025: val_loss did not improve from 0.60294

Epoch 00026: val_loss did not improve from 0.60294

Epoch 00027: val_loss did not improve from 0.60294

Epoch 00028: val_loss did not improve from 0.60294

Epoch 00029: val_loss did not improve from 0.60294

Epoch 00030: val_loss did not improve from 0.60294

Epoch 00031: val_loss did not improve from 0.60294
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7963006676905843 0.71587147030185 0.4421660149361511 0.7273395398737281 0.7149986589146675 0.7116955968454302 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7046654929577465 0.6608391608391608 0.3330238526990832 0.6734309512440979 0.6598689358372457 0.6537227735130751 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7194624670677519 0.6657323055360898 0.3604682887231022 0.6902634023645302 0.6707335535370218 0.658476266453929 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_4 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_5 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64164, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64164 to 0.63088, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.63088 to 0.62977, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.62977 to 0.61620, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.61620 to 0.60516, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.60516 to 0.60400, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60400

Epoch 00008: val_loss improved from 0.60400 to 0.60268, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss improved from 0.60268 to 0.59382, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59382

Epoch 00011: val_loss improved from 0.59382 to 0.59247, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59247

Epoch 00013: val_loss did not improve from 0.59247

Epoch 00014: val_loss did not improve from 0.59247

Epoch 00015: val_loss did not improve from 0.59247

Epoch 00016: val_loss did not improve from 0.59247

Epoch 00017: val_loss did not improve from 0.59247

Epoch 00018: val_loss did not improve from 0.59247

Epoch 00019: val_loss did not improve from 0.59247
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7387559704087396 0.6669912366114897 0.34941912299570843 0.6840939999993263 0.6658035073325812 0.6580796904043863 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7147642801251957 0.6608391608391608 0.3407490068623115 0.6818485709510279 0.65962441314554 0.6497001073300083 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7093222838268256 0.6552207428170989 0.32993300021765265 0.670830697870546 0.6593036058353978 0.6505487023070982 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 100)               11200     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_8 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64064, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64064 to 0.62451, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62451 to 0.61549, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss improved from 0.61549 to 0.60912, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.60912 to 0.60381, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60381

Epoch 00007: val_loss did not improve from 0.60381

Epoch 00008: val_loss improved from 0.60381 to 0.60293, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.60293

Epoch 00010: val_loss did not improve from 0.60293

Epoch 00011: val_loss improved from 0.60293 to 0.60098, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.60098

Epoch 00013: val_loss did not improve from 0.60098

Epoch 00014: val_loss did not improve from 0.60098

Epoch 00015: val_loss did not improve from 0.60098

Epoch 00016: val_loss improved from 0.60098 to 0.59995, saving model to 2_100_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59995

Epoch 00018: val_loss did not improve from 0.59995

Epoch 00019: val_loss did not improve from 0.59995

Epoch 00020: val_loss improved from 0.59995 to 0.59931, saving model to 2_100_best_model.hdf5

Epoch 00021: val_loss did not improve from 0.59931

Epoch 00022: val_loss did not improve from 0.59931

Epoch 00023: val_loss did not improve from 0.59931

Epoch 00024: val_loss did not improve from 0.59931

Epoch 00025: val_loss did not improve from 0.59931

Epoch 00026: val_loss did not improve from 0.59931

Epoch 00027: val_loss did not improve from 0.59931

Epoch 00028: val_loss did not improve from 0.59931
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7734752162599521 0.7038551401869159 0.4148166025021134 0.7117900947215026 0.7031171641167482 0.7005572107455638 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7148728896741263 0.6532399299474606 0.3101705933018851 0.6577697640754756 0.6524465056929721 0.6499925700274909 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7224391490700326 0.6636299929922915 0.33837087224880275 0.6719197271453803 0.6664946325350949 0.6617281024060686 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_10 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_11 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62837, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.62837 to 0.60469, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.60469

Epoch 00004: val_loss improved from 0.60469 to 0.60020, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60020

Epoch 00006: val_loss did not improve from 0.60020

Epoch 00007: val_loss did not improve from 0.60020

Epoch 00008: val_loss did not improve from 0.60020

Epoch 00009: val_loss improved from 0.60020 to 0.59940, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59940

Epoch 00011: val_loss did not improve from 0.59940

Epoch 00012: val_loss did not improve from 0.59940

Epoch 00013: val_loss did not improve from 0.59940

Epoch 00014: val_loss did not improve from 0.59940

Epoch 00015: val_loss did not improve from 0.59940

Epoch 00016: val_loss did not improve from 0.59940

Epoch 00017: val_loss did not improve from 0.59940
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7410623446471577 0.6773753894080997 0.3711953616949144 0.6954700329083927 0.6762239388996163 0.66883046459374 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7148483510011779 0.660245183887916 0.3357774930380891 0.6774542862625764 0.6588388299960738 0.6505728417493124 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7113837442491447 0.6475122634898388 0.31549297515391583 0.663949309988914 0.6517783413943612 0.6421924046872141 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_14 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64489, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.64489

Epoch 00003: val_loss did not improve from 0.64489

Epoch 00004: val_loss did not improve from 0.64489

Epoch 00005: val_loss did not improve from 0.64489

Epoch 00006: val_loss did not improve from 0.64489

Epoch 00007: val_loss did not improve from 0.64489

Epoch 00008: val_loss improved from 0.64489 to 0.64145, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.64145

Epoch 00010: val_loss did not improve from 0.64145

Epoch 00011: val_loss did not improve from 0.64145

Epoch 00012: val_loss did not improve from 0.64145

Epoch 00013: val_loss did not improve from 0.64145

Epoch 00014: val_loss improved from 0.64145 to 0.63577, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.63577

Epoch 00016: val_loss did not improve from 0.63577

Epoch 00017: val_loss did not improve from 0.63577

Epoch 00018: val_loss did not improve from 0.63577

Epoch 00019: val_loss did not improve from 0.63577

Epoch 00020: val_loss did not improve from 0.63577

Epoch 00021: val_loss did not improve from 0.63577

Epoch 00022: val_loss did not improve from 0.63577
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7500487924124348 0.6919781931464174 0.3993513598623953 0.7088505155024002 0.6909038963110813 0.6848580153865534 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6984319787985867 0.6444833625218914 0.2939934462834672 0.6505249073692878 0.6435512367491166 0.6399602416561836 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7240316936022966 0.6699369306236861 0.3613789354092986 0.6874865053661015 0.6741388462899611 0.6651851696871969 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_16 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_17 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62951, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.62951 to 0.61839, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61839

Epoch 00004: val_loss improved from 0.61839 to 0.61196, saving model to 2_100_best_model.hdf5

Epoch 00005: val_loss improved from 0.61196 to 0.60702, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.60702 to 0.60490, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60490

Epoch 00008: val_loss did not improve from 0.60490

Epoch 00009: val_loss improved from 0.60490 to 0.60247, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.60247

Epoch 00011: val_loss improved from 0.60247 to 0.60090, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.60090

Epoch 00013: val_loss improved from 0.60090 to 0.60047, saving model to 2_100_best_model.hdf5

Epoch 00014: val_loss improved from 0.60047 to 0.59919, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss improved from 0.59919 to 0.59674, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59674

Epoch 00017: val_loss did not improve from 0.59674

Epoch 00018: val_loss improved from 0.59674 to 0.59505, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.59505

Epoch 00020: val_loss did not improve from 0.59505

Epoch 00021: val_loss improved from 0.59505 to 0.59427, saving model to 2_100_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.59427

Epoch 00023: val_loss did not improve from 0.59427

Epoch 00024: val_loss did not improve from 0.59427

Epoch 00025: val_loss did not improve from 0.59427

Epoch 00026: val_loss did not improve from 0.59427

Epoch 00027: val_loss did not improve from 0.59427

Epoch 00028: val_loss did not improve from 0.59427

Epoch 00029: val_loss did not improve from 0.59427
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7797001794199987 0.7070274479268055 0.42777361597759456 0.7220552669579547 0.7060188315204374 0.7013218519425533 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.727939818519841 0.6877192982456141 0.3891226137118286 0.7027063147343802 0.6867435761687248 0.6811198833350095 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7140340529275294 0.6517168885774351 0.31927201612199874 0.6640373931890087 0.655352719122331 0.6481338246362236 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_20 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64481, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.64481 to 0.62459, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.62459 to 0.62292, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62292

Epoch 00005: val_loss did not improve from 0.62292

Epoch 00006: val_loss improved from 0.62292 to 0.61538, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61538

Epoch 00008: val_loss did not improve from 0.61538

Epoch 00009: val_loss improved from 0.61538 to 0.61365, saving model to 2_100_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.61365

Epoch 00011: val_loss improved from 0.61365 to 0.59796, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59796

Epoch 00013: val_loss did not improve from 0.59796

Epoch 00014: val_loss improved from 0.59796 to 0.59368, saving model to 2_100_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59368

Epoch 00016: val_loss did not improve from 0.59368

Epoch 00017: val_loss did not improve from 0.59368

Epoch 00018: val_loss did not improve from 0.59368

Epoch 00019: val_loss did not improve from 0.59368

Epoch 00020: val_loss did not improve from 0.59368

Epoch 00021: val_loss did not improve from 0.59368

Epoch 00022: val_loss did not improve from 0.59368
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7535155617592255 0.6895074946466809 0.3905872066512054 0.7023026139212853 0.6885274280970869 0.6838027375721119 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7281491239950258 0.6684210526315789 0.3507189090851988 0.6837162162162163 0.6673828197141134 0.6605122096486005 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7099347253352208 0.6580238262088297 0.34528043867632996 0.6827118733648688 0.66312374660847 0.6502310443203279 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_22 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_23 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63267, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.63267 to 0.61481, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.61481 to 0.60471, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60471

Epoch 00005: val_loss improved from 0.60471 to 0.60164, saving model to 2_100_best_model.hdf5

Epoch 00006: val_loss improved from 0.60164 to 0.60094, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60094

Epoch 00008: val_loss did not improve from 0.60094

Epoch 00009: val_loss did not improve from 0.60094

Epoch 00010: val_loss did not improve from 0.60094

Epoch 00011: val_loss improved from 0.60094 to 0.59868, saving model to 2_100_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59868

Epoch 00013: val_loss did not improve from 0.59868

Epoch 00014: val_loss did not improve from 0.59868

Epoch 00015: val_loss did not improve from 0.59868

Epoch 00016: val_loss did not improve from 0.59868

Epoch 00017: val_loss did not improve from 0.59868

Epoch 00018: val_loss did not improve from 0.59868

Epoch 00019: val_loss did not improve from 0.59868
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7371506115378155 0.6762701966128091 0.38156037271133997 0.7082721648948144 0.6747572918555205 0.6621553381402373 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.712857512219746 0.6719298245614035 0.36507476590400084 0.695201621986934 0.6706947710567465 0.6608557037904363 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7229758955605363 0.6440084092501752 0.3083754179011954 0.6603173422322358 0.6482924383626283 0.6385727904017742 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_25 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_26 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.60256, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.60256 to 0.60036, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.60036 to 0.59740, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.59740

Epoch 00005: val_loss did not improve from 0.59740

Epoch 00006: val_loss did not improve from 0.59740

Epoch 00007: val_loss did not improve from 0.59740

Epoch 00008: val_loss did not improve from 0.59740

Epoch 00009: val_loss did not improve from 0.59740

Epoch 00010: val_loss did not improve from 0.59740

Epoch 00011: val_loss did not improve from 0.59740
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7121718035924018 0.6425929530854584 0.33364142164556976 0.6979927911306991 0.6405563778382649 0.6137840719792829 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7239014540574481 0.6666666666666666 0.38964031786236386 0.7303040209218699 0.6648034375346278 0.6404191457713557 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7179210412488696 0.6489138051857043 0.33310119574672975 0.6793546165912738 0.6546606503873226 0.6383399779339565 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 100)               11200     
_________________________________________________________________
activation_28 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_29 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 21,401
Trainable params: 21,401
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65181, saving model to 2_100_best_model.hdf5

Epoch 00002: val_loss improved from 0.65181 to 0.63522, saving model to 2_100_best_model.hdf5

Epoch 00003: val_loss improved from 0.63522 to 0.61996, saving model to 2_100_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.61996

Epoch 00005: val_loss did not improve from 0.61996

Epoch 00006: val_loss improved from 0.61996 to 0.61842, saving model to 2_100_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.61842

Epoch 00008: val_loss improved from 0.61842 to 0.61494, saving model to 2_100_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.61494

Epoch 00010: val_loss improved from 0.61494 to 0.60974, saving model to 2_100_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60974

Epoch 00012: val_loss improved from 0.60974 to 0.60781, saving model to 2_100_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.60781

Epoch 00014: val_loss did not improve from 0.60781

Epoch 00015: val_loss improved from 0.60781 to 0.60778, saving model to 2_100_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.60778

Epoch 00017: val_loss did not improve from 0.60778

Epoch 00018: val_loss improved from 0.60778 to 0.60776, saving model to 2_100_best_model.hdf5

Epoch 00019: val_loss did not improve from 0.60776

Epoch 00020: val_loss did not improve from 0.60776

Epoch 00021: val_loss did not improve from 0.60776

Epoch 00022: val_loss did not improve from 0.60776

Epoch 00023: val_loss did not improve from 0.60776

Epoch 00024: val_loss did not improve from 0.60776

Epoch 00025: val_loss did not improve from 0.60776

Epoch 00026: val_loss did not improve from 0.60776
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7637014667084645 0.7031341249756667 0.4197778559862371 0.7179539613013917 0.7021223281791265 0.6973194510047108 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.710444343211731 0.6333333333333333 0.27606303993300135 0.6439649630343941 0.6323426207507911 0.6253903166871586 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7068823483150486 0.6475122634898388 0.32584820314870583 0.6736310531322434 0.6528773937320593 0.638443563616325 None
average testing metrics
[0.71583874 0.65522074 0.33375213 0.67445019 0.65967559 0.64918518]
std testing metrics
[0.00599782 0.00838    0.01701693 0.00975151 0.00819748 0.0094775 ]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.73420, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.73420 to 0.68961, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.68961 to 0.66724, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.66724 to 0.64559, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.64559 to 0.63005, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.63005

Epoch 00007: val_loss did not improve from 0.63005

Epoch 00008: val_loss improved from 0.63005 to 0.62624, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.62624

Epoch 00010: val_loss improved from 0.62624 to 0.62167, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.62167 to 0.62079, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.62079

Epoch 00013: val_loss did not improve from 0.62079

Epoch 00014: val_loss improved from 0.62079 to 0.62006, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.62006

Epoch 00016: val_loss did not improve from 0.62006

Epoch 00017: val_loss did not improve from 0.62006

Epoch 00018: val_loss did not improve from 0.62006

Epoch 00019: val_loss improved from 0.62006 to 0.61104, saving model to 1_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.61104

Epoch 00021: val_loss did not improve from 0.61104

Epoch 00022: val_loss did not improve from 0.61104

Epoch 00023: val_loss did not improve from 0.61104

Epoch 00024: val_loss did not improve from 0.61104

Epoch 00025: val_loss did not improve from 0.61104

Epoch 00026: val_loss did not improve from 0.61104

Epoch 00027: val_loss did not improve from 0.61104
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8174221548510576 0.7378773125608569 0.4822577203572521 0.7451141027678938 0.7372084125494032 0.735557027805631 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6933074139280125 0.6346153846153846 0.27760494357284715 0.6441206321589097 0.6336805555555556 0.6275101809355556 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7132338484526758 0.6580238262088297 0.31973950092395464 0.6603369853261085 0.6594038771577995 0.6577937649880096 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_3 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64631, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64631 to 0.62505, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.62505 to 0.62068, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.62068 to 0.61827, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.61827 to 0.60390, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.60390 to 0.59995, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.59995 to 0.59081, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59081

Epoch 00009: val_loss improved from 0.59081 to 0.58863, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss improved from 0.58863 to 0.58711, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.58711 to 0.58599, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58599

Epoch 00013: val_loss did not improve from 0.58599

Epoch 00014: val_loss did not improve from 0.58599

Epoch 00015: val_loss did not improve from 0.58599

Epoch 00016: val_loss did not improve from 0.58599

Epoch 00017: val_loss improved from 0.58599 to 0.58004, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58004

Epoch 00019: val_loss did not improve from 0.58004

Epoch 00020: val_loss did not improve from 0.58004

Epoch 00021: val_loss did not improve from 0.58004

Epoch 00022: val_loss did not improve from 0.58004

Epoch 00023: val_loss did not improve from 0.58004

Epoch 00024: val_loss did not improve from 0.58004

Epoch 00025: val_loss did not improve from 0.58004
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7904249237978324 0.7133398247322298 0.43771321958178705 0.7254683411826268 0.7124387636770982 0.7088595932526568 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7368446791862284 0.666083916083916 0.34646793806532195 0.6818475756800086 0.6650283646322379 0.6577993691721246 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7080020447485353 0.6580238262088297 0.33681476165650487 0.6748134636651371 0.66223605048956 0.6530416204969588 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_5 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64067, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64067 to 0.61648, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61648 to 0.61613, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.61613 to 0.61304, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.61304 to 0.61072, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.61072 to 0.60480, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.60480 to 0.60024, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.60024

Epoch 00009: val_loss did not improve from 0.60024

Epoch 00010: val_loss improved from 0.60024 to 0.59476, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.59476

Epoch 00012: val_loss did not improve from 0.59476

Epoch 00013: val_loss did not improve from 0.59476

Epoch 00014: val_loss did not improve from 0.59476

Epoch 00015: val_loss did not improve from 0.59476

Epoch 00016: val_loss did not improve from 0.59476

Epoch 00017: val_loss did not improve from 0.59476

Epoch 00018: val_loss did not improve from 0.59476
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7686339625823235 0.6952881619937694 0.40690374931232975 0.7131496564172182 0.6941953179604756 0.6879995556292378 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7152041617589321 0.6742556917688266 0.3645488311987009 0.6921781232951445 0.6728810855908913 0.6653790895800776 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7128209665369037 0.6720392431674842 0.36369147125511625 0.6878743426050677 0.6760105776414612 0.6679164296426539 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63027, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63027 to 0.61162, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61162 to 0.60376, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.60376 to 0.60239, saving model to 1_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.60239 to 0.60145, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.60145 to 0.59904, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59904

Epoch 00008: val_loss did not improve from 0.59904

Epoch 00009: val_loss improved from 0.59904 to 0.59562, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59562

Epoch 00011: val_loss did not improve from 0.59562

Epoch 00012: val_loss improved from 0.59562 to 0.59444, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59444

Epoch 00014: val_loss improved from 0.59444 to 0.59360, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59360

Epoch 00016: val_loss improved from 0.59360 to 0.59139, saving model to 1_200_best_model.hdf5

Epoch 00017: val_loss did not improve from 0.59139

Epoch 00018: val_loss did not improve from 0.59139

Epoch 00019: val_loss did not improve from 0.59139

Epoch 00020: val_loss did not improve from 0.59139

Epoch 00021: val_loss improved from 0.59139 to 0.58860, saving model to 1_200_best_model.hdf5

Epoch 00022: val_loss did not improve from 0.58860

Epoch 00023: val_loss did not improve from 0.58860

Epoch 00024: val_loss did not improve from 0.58860

Epoch 00025: val_loss did not improve from 0.58860

Epoch 00026: val_loss did not improve from 0.58860

Epoch 00027: val_loss did not improve from 0.58860

Epoch 00028: val_loss did not improve from 0.58860

Epoch 00029: val_loss did not improve from 0.58860
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8073774885836371 0.7279984423676013 0.4637779362833062 0.7365953621771739 0.7272761944738935 0.7250819247198754 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7472148606203377 0.6865148861646234 0.3764600267552765 0.6906596173212487 0.6858313702394974 0.6842838476911814 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7176516849514372 0.6517168885774351 0.33717522654630616 0.6806884293638318 0.6572971963351815 0.6419230619705922 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_9 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_10 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.66108, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.66108 to 0.63111, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.63111 to 0.62098, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62098

Epoch 00005: val_loss improved from 0.62098 to 0.61079, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.61079 to 0.60664, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60664

Epoch 00008: val_loss did not improve from 0.60664

Epoch 00009: val_loss did not improve from 0.60664

Epoch 00010: val_loss improved from 0.60664 to 0.60370, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60370

Epoch 00012: val_loss did not improve from 0.60370

Epoch 00013: val_loss did not improve from 0.60370

Epoch 00014: val_loss improved from 0.60370 to 0.60195, saving model to 1_200_best_model.hdf5

Epoch 00015: val_loss improved from 0.60195 to 0.59755, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59755

Epoch 00017: val_loss did not improve from 0.59755

Epoch 00018: val_loss did not improve from 0.59755

Epoch 00019: val_loss did not improve from 0.59755

Epoch 00020: val_loss did not improve from 0.59755

Epoch 00021: val_loss did not improve from 0.59755

Epoch 00022: val_loss did not improve from 0.59755

Epoch 00023: val_loss did not improve from 0.59755
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7817763713700834 0.7067757009345794 0.4352540833367276 0.7303883854027252 0.705572556023319 0.6982765897788734 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7140876521397723 0.6742556917688266 0.36372660736481005 0.6912782648823258 0.672911758932077 0.6657666163141994 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.712099406236483 0.6503153468815698 0.30996387131867975 0.6570558638011936 0.6529353938107034 0.6487255520535855 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_11 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64101, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64101 to 0.61344, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61344 to 0.60366, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60366

Epoch 00005: val_loss improved from 0.60366 to 0.60349, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.60349

Epoch 00007: val_loss did not improve from 0.60349

Epoch 00008: val_loss did not improve from 0.60349

Epoch 00009: val_loss did not improve from 0.60349

Epoch 00010: val_loss improved from 0.60349 to 0.60348, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.60348 to 0.60310, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.60310 to 0.60281, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.60281

Epoch 00014: val_loss did not improve from 0.60281

Epoch 00015: val_loss did not improve from 0.60281

Epoch 00016: val_loss did not improve from 0.60281

Epoch 00017: val_loss improved from 0.60281 to 0.60126, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.60126

Epoch 00019: val_loss improved from 0.60126 to 0.60100, saving model to 1_200_best_model.hdf5

Epoch 00020: val_loss did not improve from 0.60100

Epoch 00021: val_loss did not improve from 0.60100

Epoch 00022: val_loss did not improve from 0.60100

Epoch 00023: val_loss did not improve from 0.60100

Epoch 00024: val_loss did not improve from 0.60100

Epoch 00025: val_loss did not improve from 0.60100

Epoch 00026: val_loss did not improve from 0.60100

Epoch 00027: val_loss did not improve from 0.60100
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7805523334604654 0.7041074557134515 0.4246849285024174 0.7221088063050736 0.7030055578361184 0.6972522453360133 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7125497100503565 0.6491228070175439 0.30995317562700614 0.6621769202766654 0.6480959357801555 0.6409494053618223 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.71701073492981 0.6559215136650315 0.3199593156929268 0.6616842587237324 0.6582930281939365 0.6547251158419789 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67667, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.67667 to 0.63697, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.63697 to 0.61739, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.61739

Epoch 00005: val_loss improved from 0.61739 to 0.61465, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.61465

Epoch 00007: val_loss did not improve from 0.61465

Epoch 00008: val_loss improved from 0.61465 to 0.60673, saving model to 1_200_best_model.hdf5

Epoch 00009: val_loss did not improve from 0.60673

Epoch 00010: val_loss improved from 0.60673 to 0.60252, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss improved from 0.60252 to 0.59990, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss improved from 0.59990 to 0.59813, saving model to 1_200_best_model.hdf5

Epoch 00013: val_loss did not improve from 0.59813

Epoch 00014: val_loss did not improve from 0.59813

Epoch 00015: val_loss improved from 0.59813 to 0.59631, saving model to 1_200_best_model.hdf5

Epoch 00016: val_loss did not improve from 0.59631

Epoch 00017: val_loss improved from 0.59631 to 0.58944, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58944

Epoch 00019: val_loss did not improve from 0.58944

Epoch 00020: val_loss did not improve from 0.58944

Epoch 00021: val_loss improved from 0.58944 to 0.58941, saving model to 1_200_best_model.hdf5

Epoch 00022: val_loss improved from 0.58941 to 0.58936, saving model to 1_200_best_model.hdf5

Epoch 00023: val_loss did not improve from 0.58936

Epoch 00024: val_loss did not improve from 0.58936

Epoch 00025: val_loss did not improve from 0.58936

Epoch 00026: val_loss did not improve from 0.58936

Epoch 00027: val_loss did not improve from 0.58936

Epoch 00028: val_loss did not improve from 0.58936

Epoch 00029: val_loss improved from 0.58936 to 0.58556, saving model to 1_200_best_model.hdf5

Epoch 00030: val_loss improved from 0.58556 to 0.58224, saving model to 1_200_best_model.hdf5

Epoch 00031: val_loss did not improve from 0.58224

Epoch 00032: val_loss did not improve from 0.58224

Epoch 00033: val_loss improved from 0.58224 to 0.58183, saving model to 1_200_best_model.hdf5

Epoch 00034: val_loss improved from 0.58183 to 0.57970, saving model to 1_200_best_model.hdf5

Epoch 00035: val_loss did not improve from 0.57970

Epoch 00036: val_loss did not improve from 0.57970

Epoch 00037: val_loss did not improve from 0.57970

Epoch 00038: val_loss did not improve from 0.57970

Epoch 00039: val_loss did not improve from 0.57970

Epoch 00040: val_loss did not improve from 0.57970

Epoch 00041: val_loss did not improve from 0.57970

Epoch 00042: val_loss improved from 0.57970 to 0.57222, saving model to 1_200_best_model.hdf5

Epoch 00043: val_loss did not improve from 0.57222

Epoch 00044: val_loss did not improve from 0.57222

Epoch 00045: val_loss did not improve from 0.57222

Epoch 00046: val_loss did not improve from 0.57222

Epoch 00047: val_loss did not improve from 0.57222

Epoch 00048: val_loss did not improve from 0.57222

Epoch 00049: val_loss did not improve from 0.57222

Epoch 00050: val_loss did not improve from 0.57222
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8788943053098981 0.7917072221140744 0.5866440045395613 0.7953829161209394 0.7912754676046551 0.7908804600744774 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7586830991984832 0.7157894736842105 0.4357302759228128 0.720503474630781 0.7152583691409857 0.7139263408347378 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.708886791710904 0.657323055360897 0.32110689143182425 0.6617581904396972 0.6593576737053203 0.6565431497190782 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_15 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_16 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63628, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63628 to 0.60700, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.60700 to 0.60239, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60239

Epoch 00005: val_loss did not improve from 0.60239

Epoch 00006: val_loss did not improve from 0.60239

Epoch 00007: val_loss improved from 0.60239 to 0.59604, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59604

Epoch 00009: val_loss improved from 0.59604 to 0.59436, saving model to 1_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59436

Epoch 00011: val_loss improved from 0.59436 to 0.59325, saving model to 1_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59325

Epoch 00013: val_loss improved from 0.59325 to 0.59091, saving model to 1_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.59091

Epoch 00015: val_loss did not improve from 0.59091

Epoch 00016: val_loss did not improve from 0.59091

Epoch 00017: val_loss improved from 0.59091 to 0.58848, saving model to 1_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.58848

Epoch 00019: val_loss did not improve from 0.58848

Epoch 00020: val_loss did not improve from 0.58848

Epoch 00021: val_loss did not improve from 0.58848

Epoch 00022: val_loss did not improve from 0.58848

Epoch 00023: val_loss did not improve from 0.58848

Epoch 00024: val_loss did not improve from 0.58848

Epoch 00025: val_loss improved from 0.58848 to 0.58660, saving model to 1_200_best_model.hdf5

Epoch 00026: val_loss did not improve from 0.58660

Epoch 00027: val_loss did not improve from 0.58660

Epoch 00028: val_loss did not improve from 0.58660

Epoch 00029: val_loss did not improve from 0.58660

Epoch 00030: val_loss did not improve from 0.58660

Epoch 00031: val_loss did not improve from 0.58660

Epoch 00032: val_loss did not improve from 0.58660

Epoch 00033: val_loss did not improve from 0.58660
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.8261234365933119 0.7307767179287522 0.48649797646975584 0.7577845982237861 0.7295329926030938 0.7228266499021199 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7484517550879698 0.6842105263157895 0.38422277394021437 0.7014994108006338 0.6831607589170289 0.6764998927972354 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7109512012897645 0.6692361597757533 0.35481680663176185 0.6821138817757668 0.6728245055247533 0.6659750214238105 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_17 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_17 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.71225, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.71225 to 0.62197, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.62197 to 0.60069, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60069

Epoch 00005: val_loss improved from 0.60069 to 0.59961, saving model to 1_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59961

Epoch 00007: val_loss did not improve from 0.59961

Epoch 00008: val_loss did not improve from 0.59961

Epoch 00009: val_loss did not improve from 0.59961

Epoch 00010: val_loss did not improve from 0.59961

Epoch 00011: val_loss did not improve from 0.59961

Epoch 00012: val_loss did not improve from 0.59961

Epoch 00013: val_loss did not improve from 0.59961
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.74068246904717 0.6752968658750244 0.36776680027547465 0.6942344915023182 0.6740839363013529 0.6662227478403948 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7213528520949015 0.6736842105263158 0.35782722181553334 0.6852631717910467 0.6727816697652085 0.6677780423910454 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7007569501789155 0.6461107217939733 0.3162280952680391 0.6657847752689985 0.6507982383704927 0.6394468785351227 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 22,601
Trainable params: 22,601
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.65062, saving model to 1_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.65062 to 0.64871, saving model to 1_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.64871 to 0.62078, saving model to 1_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62078

Epoch 00005: val_loss did not improve from 0.62078

Epoch 00006: val_loss improved from 0.62078 to 0.61270, saving model to 1_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.61270 to 0.61168, saving model to 1_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61168

Epoch 00009: val_loss did not improve from 0.61168

Epoch 00010: val_loss improved from 0.61168 to 0.60666, saving model to 1_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60666

Epoch 00012: val_loss did not improve from 0.60666

Epoch 00013: val_loss did not improve from 0.60666

Epoch 00014: val_loss did not improve from 0.60666

Epoch 00015: val_loss did not improve from 0.60666

Epoch 00016: val_loss did not improve from 0.60666

Epoch 00017: val_loss did not improve from 0.60666

Epoch 00018: val_loss did not improve from 0.60666
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7650631092715694 0.6889234962040102 0.3786136242178843 0.6900092087359292 0.6886070119930657 0.6882373145737779 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7018381945555954 0.612280701754386 0.22526956852057498 0.6133947289607666 0.6118799325297645 0.61081331582606 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7197731115567614 0.6482130343377716 0.3253527357283622 0.6725265369305617 0.6533885808658724 0.6398855844443103 None
average testing metrics
[0.71211867 0.65669236 0.33048487 0.67046367 0.66025451 0.65259762]
std testing metrics
[0.00522224 0.00804178 0.01656639 0.01011759 0.00783861 0.00961451]
End of this run.
########################################################################################################
(5707, 112)
(5707, 111)
class labels
{0.0, 1.0}
(1427, 112)
(1427, 111)
(1427,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_2 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.67132, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.67132 to 0.64388, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.64388 to 0.62910, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.62910

Epoch 00005: val_loss improved from 0.62910 to 0.62556, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.62556 to 0.61921, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.61921 to 0.61488, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61488

Epoch 00009: val_loss did not improve from 0.61488

Epoch 00010: val_loss did not improve from 0.61488

Epoch 00011: val_loss improved from 0.61488 to 0.61421, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.61421

Epoch 00013: val_loss improved from 0.61421 to 0.61419, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.61419 to 0.61402, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.61402

Epoch 00016: val_loss did not improve from 0.61402

Epoch 00017: val_loss did not improve from 0.61402

Epoch 00018: val_loss did not improve from 0.61402

Epoch 00019: val_loss did not improve from 0.61402

Epoch 00020: val_loss did not improve from 0.61402

Epoch 00021: val_loss did not improve from 0.61402

Epoch 00022: val_loss did not improve from 0.61402
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7892168850532096 0.7127555988315482 0.4454685022524072 0.7344755844352351 0.7115808635011793 0.7052014045632933 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6974765258215962 0.6416083916083916 0.3008957989842267 0.6612653995813842 0.6403560250391236 0.6291106689988266 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7041298022099012 0.649614576033637 0.3189941482399029 0.665430041117447 0.6537768864771343 0.6446302560853645 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_4 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_5 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_6 (Activation)    (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62208, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.62208

Epoch 00003: val_loss improved from 0.62208 to 0.61277, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.61277 to 0.60529, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.60529 to 0.60408, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.60408 to 0.59699, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59699

Epoch 00008: val_loss did not improve from 0.59699

Epoch 00009: val_loss improved from 0.59699 to 0.59367, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59367

Epoch 00011: val_loss improved from 0.59367 to 0.58879, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.58879

Epoch 00013: val_loss did not improve from 0.58879

Epoch 00014: val_loss did not improve from 0.58879

Epoch 00015: val_loss did not improve from 0.58879

Epoch 00016: val_loss did not improve from 0.58879

Epoch 00017: val_loss did not improve from 0.58879

Epoch 00018: val_loss did not improve from 0.58879

Epoch 00019: val_loss did not improve from 0.58879
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7644600553789355 0.7010710808179162 0.4249775222028459 0.725995597279429 0.6997891734969983 0.691727154327455 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7256210876369328 0.6643356643356644 0.35423263606333577 0.6924854155836655 0.6629743740219092 0.6504513221383376 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7153847666234123 0.6489138051857043 0.3078274101037162 0.6562015268412207 0.6516593920805316 0.6471108259190246 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 200)               22400     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_8 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_9 (Activation)    (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62467, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62467 to 0.61292, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.61292 to 0.60673, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss did not improve from 0.60673

Epoch 00005: val_loss improved from 0.60673 to 0.59831, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59831

Epoch 00007: val_loss improved from 0.59831 to 0.59433, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59433

Epoch 00009: val_loss did not improve from 0.59433

Epoch 00010: val_loss did not improve from 0.59433

Epoch 00011: val_loss did not improve from 0.59433

Epoch 00012: val_loss did not improve from 0.59433

Epoch 00013: val_loss improved from 0.59433 to 0.59093, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss improved from 0.59093 to 0.59047, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.59047

Epoch 00016: val_loss did not improve from 0.59047

Epoch 00017: val_loss did not improve from 0.59047

Epoch 00018: val_loss did not improve from 0.59047

Epoch 00019: val_loss did not improve from 0.59047

Epoch 00020: val_loss did not improve from 0.59047

Epoch 00021: val_loss did not improve from 0.59047

Epoch 00022: val_loss did not improve from 0.59047
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7786351560439734 0.7093068535825545 0.4247859644324051 0.7162301369001776 0.7086239205200036 0.7065142295501348 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.730565371024735 0.6760070052539404 0.35713826629285506 0.6820349356113732 0.6751693168433451 0.6726292856323817 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.720398332743502 0.662228451296426 0.32396235475131796 0.6619563422802963 0.6620060162793442 0.6619759702143888 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_10 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_11 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_12 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.61660, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.61660

Epoch 00003: val_loss improved from 0.61660 to 0.60881, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.60881 to 0.60136, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.60136 to 0.59483, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss did not improve from 0.59483

Epoch 00007: val_loss did not improve from 0.59483

Epoch 00008: val_loss did not improve from 0.59483

Epoch 00009: val_loss did not improve from 0.59483

Epoch 00010: val_loss did not improve from 0.59483

Epoch 00011: val_loss did not improve from 0.59483

Epoch 00012: val_loss did not improve from 0.59483

Epoch 00013: val_loss did not improve from 0.59483
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7261835780586853 0.6713395638629284 0.3599319800115179 0.6903559603702375 0.6701431228933392 0.6619492656875836 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7366141539065567 0.6830122591943958 0.3785733882583536 0.6970740789998671 0.6818070278759325 0.6763373074405684 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7256340686563643 0.6713384723195515 0.36625534911285446 0.6908117742486339 0.6757530179701938 0.6660245946837439 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_13 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_14 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_15 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.64834, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.64834 to 0.62779, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.62779

Epoch 00004: val_loss improved from 0.62779 to 0.62466, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.62466

Epoch 00006: val_loss improved from 0.62466 to 0.62307, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.62307 to 0.61963, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.61963

Epoch 00009: val_loss did not improve from 0.61963

Epoch 00010: val_loss improved from 0.61963 to 0.61930, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.61930

Epoch 00012: val_loss did not improve from 0.61930

Epoch 00013: val_loss improved from 0.61930 to 0.61636, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.61636

Epoch 00015: val_loss did not improve from 0.61636

Epoch 00016: val_loss did not improve from 0.61636

Epoch 00017: val_loss improved from 0.61636 to 0.61238, saving model to 2_200_best_model.hdf5

Epoch 00018: val_loss did not improve from 0.61238

Epoch 00019: val_loss did not improve from 0.61238

Epoch 00020: val_loss did not improve from 0.61238

Epoch 00021: val_loss did not improve from 0.61238

Epoch 00022: val_loss did not improve from 0.61238

Epoch 00023: val_loss did not improve from 0.61238

Epoch 00024: val_loss did not improve from 0.61238

Epoch 00025: val_loss did not improve from 0.61238
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7919264063322922 0.7091121495327103 0.4519677545327141 0.7459196491666 0.7076642226735573 0.6968735067240084 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.6999779151943463 0.6514886164623468 0.3254115503924994 0.6767349952227917 0.6497901943462898 0.6370202367071827 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7071369588297747 0.6454099509460406 0.3127121695178122 0.6631290368144638 0.6498643387991034 0.6394809370693615 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_16 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_17 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_18 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.62051, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.62051 to 0.61735, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.61735

Epoch 00004: val_loss did not improve from 0.61735

Epoch 00005: val_loss improved from 0.61735 to 0.61550, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.61550 to 0.60635, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60635

Epoch 00008: val_loss did not improve from 0.60635

Epoch 00009: val_loss did not improve from 0.60635

Epoch 00010: val_loss did not improve from 0.60635

Epoch 00011: val_loss did not improve from 0.60635

Epoch 00012: val_loss did not improve from 0.60635

Epoch 00013: val_loss did not improve from 0.60635

Epoch 00014: val_loss did not improve from 0.60635
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7260250860567196 0.6643955616118357 0.3353580257727704 0.6718920502462643 0.6635692361704411 0.659986061874466 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7018997549894732 0.6350877192982456 0.2774075897512358 0.6433502978656251 0.6342079018972926 0.6288318974153476 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7211080964177579 0.6657323055360898 0.3522737044263355 0.6826154125772447 0.6698881286618694 0.6610341590703673 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_19 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_20 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_21 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63426, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63426 to 0.62114, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.62114

Epoch 00004: val_loss improved from 0.62114 to 0.61954, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.61954

Epoch 00006: val_loss improved from 0.61954 to 0.59988, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59988

Epoch 00008: val_loss did not improve from 0.59988

Epoch 00009: val_loss improved from 0.59988 to 0.59847, saving model to 2_200_best_model.hdf5

Epoch 00010: val_loss did not improve from 0.59847

Epoch 00011: val_loss improved from 0.59847 to 0.59713, saving model to 2_200_best_model.hdf5

Epoch 00012: val_loss did not improve from 0.59713

Epoch 00013: val_loss did not improve from 0.59713

Epoch 00014: val_loss improved from 0.59713 to 0.58612, saving model to 2_200_best_model.hdf5

Epoch 00015: val_loss did not improve from 0.58612

Epoch 00016: val_loss did not improve from 0.58612

Epoch 00017: val_loss did not improve from 0.58612

Epoch 00018: val_loss did not improve from 0.58612

Epoch 00019: val_loss did not improve from 0.58612

Epoch 00020: val_loss did not improve from 0.58612

Epoch 00021: val_loss did not improve from 0.58612

Epoch 00022: val_loss did not improve from 0.58612
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7739494470965672 0.7044967880085653 0.4254994534362363 0.7225348001386532 0.7033949125729215 0.6976505976447818 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.744117900542963 0.6736842105263158 0.36932900841288574 0.6977591392383615 0.6724369313354921 0.6624469887036588 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7223506743737957 0.6503153468815698 0.32240500681095413 0.6679666154371584 0.6547107860485235 0.6446615623607423 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_22 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_23 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_24 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.60860, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss did not improve from 0.60860

Epoch 00003: val_loss did not improve from 0.60860

Epoch 00004: val_loss did not improve from 0.60860

Epoch 00005: val_loss improved from 0.60860 to 0.60517, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.60517 to 0.60087, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss improved from 0.60087 to 0.59512, saving model to 2_200_best_model.hdf5

Epoch 00008: val_loss did not improve from 0.59512

Epoch 00009: val_loss did not improve from 0.59512

Epoch 00010: val_loss did not improve from 0.59512

Epoch 00011: val_loss did not improve from 0.59512

Epoch 00012: val_loss did not improve from 0.59512

Epoch 00013: val_loss did not improve from 0.59512

Epoch 00014: val_loss did not improve from 0.59512

Epoch 00015: val_loss did not improve from 0.59512
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7324874499985751 0.6723768736616702 0.394335898072961 0.7280344993574357 0.670479467961191 0.6495891465978003 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7484025067408675 0.6666666666666666 0.37873996011959044 0.7174036511156187 0.6649511825759348 0.6446104168854353 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7124483897605285 0.665031534688157 0.3605906674520688 0.6910118062451727 0.6701800951594511 0.6572510783356046 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_25 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_26 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_27 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.61857, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.61857 to 0.60657, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss did not improve from 0.60657

Epoch 00004: val_loss improved from 0.60657 to 0.60135, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss did not improve from 0.60135

Epoch 00006: val_loss improved from 0.60135 to 0.59559, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.59559

Epoch 00008: val_loss did not improve from 0.59559

Epoch 00009: val_loss did not improve from 0.59559

Epoch 00010: val_loss did not improve from 0.59559

Epoch 00011: val_loss did not improve from 0.59559

Epoch 00012: val_loss did not improve from 0.59559

Epoch 00013: val_loss improved from 0.59559 to 0.59513, saving model to 2_200_best_model.hdf5

Epoch 00014: val_loss did not improve from 0.59513

Epoch 00015: val_loss did not improve from 0.59513

Epoch 00016: val_loss did not improve from 0.59513

Epoch 00017: val_loss did not improve from 0.59513

Epoch 00018: val_loss did not improve from 0.59513

Epoch 00019: val_loss did not improve from 0.59513

Epoch 00020: val_loss did not improve from 0.59513

Epoch 00021: val_loss did not improve from 0.59513
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7585641367375635 0.6914541561222504 0.4092872013818815 0.7203492271266321 0.6900574095487335 0.6799972567190242 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7363243496140162 0.6754385964912281 0.37685259224358425 0.7039253576372866 0.6741052190935841 0.6626452832723888 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.713526798002438 0.6461107217939733 0.34464219231289683 0.6938724721645687 0.6531654280209194 0.6290535869537801 None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 200)               22400     
_________________________________________________________________
activation_28 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_29 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_30 (Activation)   (None, 1)                 0         
=================================================================
Total params: 62,801
Trainable params: 62,801
Non-trainable params: 0
_________________________________________________________________
None

Epoch 00001: val_loss improved from inf to 0.63068, saving model to 2_200_best_model.hdf5

Epoch 00002: val_loss improved from 0.63068 to 0.62644, saving model to 2_200_best_model.hdf5

Epoch 00003: val_loss improved from 0.62644 to 0.61916, saving model to 2_200_best_model.hdf5

Epoch 00004: val_loss improved from 0.61916 to 0.61338, saving model to 2_200_best_model.hdf5

Epoch 00005: val_loss improved from 0.61338 to 0.61285, saving model to 2_200_best_model.hdf5

Epoch 00006: val_loss improved from 0.61285 to 0.60714, saving model to 2_200_best_model.hdf5

Epoch 00007: val_loss did not improve from 0.60714

Epoch 00008: val_loss did not improve from 0.60714

Epoch 00009: val_loss did not improve from 0.60714

Epoch 00010: val_loss improved from 0.60714 to 0.60383, saving model to 2_200_best_model.hdf5

Epoch 00011: val_loss did not improve from 0.60383

Epoch 00012: val_loss did not improve from 0.60383

Epoch 00013: val_loss did not improve from 0.60383

Epoch 00014: val_loss did not improve from 0.60383

Epoch 00015: val_loss did not improve from 0.60383

Epoch 00016: val_loss did not improve from 0.60383

Epoch 00017: val_loss did not improve from 0.60383

Epoch 00018: val_loss did not improve from 0.60383
training performance
auc,acc,mcc,precision,recall,fscore,support: 0.7470149217531136 0.6881448316137824 0.38424346681904964 0.6970560139572416 0.687311007195597 0.6839617583878762 None
validation performance
auc,acc,mcc,precision,recall,fscore,support: 0.7100996047820145 0.6421052631578947 0.2929543566104997 0.6519768320322337 0.6411765430122751 0.6352755194218609 None
testing accuracy
auc,acc,mcc,precision,recall,fscore,support: 0.7117356769297314 0.657323055360897 0.33517839647442965 0.6738934400203214 0.6615135071369589 0.6523896984650516 None
average testing metrics
[0.71538536 0.65620182 0.33448414 0.67468885 0.66025176 0.65036127]
standard devidation testing metrics
[0.00656929 0.00885969 0.0194737  0.01313889 0.0086079  0.01092717]
End of this run.
########################################################################################################
